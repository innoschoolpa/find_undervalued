# DB ìºì‹œ ì‹œìŠ¤í…œ í†µí•© ê°€ì´ë“œ

**ë²„ì „**: v1.0  
**ë‚ ì§œ**: 2025-10-12  
**ìƒíƒœ**: âœ… êµ¬í˜„ ì™„ë£Œ

---

## ğŸ“‹ êµ¬í˜„ëœ ì»´í¬ë„ŒíŠ¸

### 1. ë°ì´í„°ë² ì´ìŠ¤
```
âœ… db_schema.sql          - SQLite ìŠ¤í‚¤ë§ˆ
âœ… cache/stock_data.db    - ì‹¤ì œ DB íŒŒì¼
```

### 2. í•µì‹¬ ëª¨ë“ˆ
```
âœ… db_cache_manager.py        - DB ìºì‹œ ë§¤ë‹ˆì €
âœ… daily_price_collector.py   - ì¼ë³„ ìë™ ìˆ˜ì§‘
âœ… test_db_cache.py           - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```

### 3. ë¬¸ì„œ
```
âœ… DB_CACHE_PROPOSAL.md           - ì„¤ê³„ ë¬¸ì„œ
âœ… DAILY_PRICE_TRACKING.md        - í™œìš© ê°€ì´ë“œ
âœ… DB_CACHE_INTEGRATION_GUIDE.md  - í†µí•© ê°€ì´ë“œ (ë³¸ ë¬¸ì„œ)
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### Step 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install apscheduler
# ë˜ëŠ”
pip install -r requirements.txt
```

### Step 2: DB ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸
```bash
python test_db_cache.py
```

ì˜ˆìƒ ê²°ê³¼:
```
âœ… DB ìŠ¤í‚¤ë§ˆ ì ìš© ì™„ë£Œ
âœ… ìŠ¤ëƒ…ìƒ· ì €ì¥: 38ê°œ
âœ… ì„¹í„° í†µê³„ ê³„ì‚° ì™„ë£Œ: 1ê°œ ì„¹í„°
```

### Step 3: ì¦‰ì‹œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
```bash
python daily_price_collector.py --now
```

### Step 4: ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
```bash
# Windows
start /b python daily_price_collector.py

# Linux/Mac
nohup python daily_price_collector.py &
```

---

## ğŸ“Š ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•©

### ì˜µì…˜ 1: ê¸°ì¡´ pickle ìºì‹œ ë³‘í–‰ ìš´ì˜ (ê¶Œì¥)

ê¸°ì¡´ `sector_cache_manager.py`ì™€ ë³‘í–‰í•˜ì—¬ ì ì§„ì  ì „í™˜:

```python
# value_stock_finder.py ìˆ˜ì •

from sector_cache_manager import SectorCacheManager  # ê¸°ì¡´
from db_cache_manager import get_db_cache           # ì‹ ê·œ

class ValueStockFinder:
    def __init__(self, data_provider):
        self.data_provider = data_provider
        
        # ê¸°ì¡´ pickle ìºì‹œ
        self.sector_cache = SectorCacheManager()
        
        # ì‹ ê·œ DB ìºì‹œ
        self.db_cache = get_db_cache()
    
    def _cached_sector_data(self, sector_name: str):
        """ì„¹í„° ë°ì´í„° ì¡°íšŒ (DB ìš°ì„ , pickle í´ë°±)"""
        
        # 1ìˆœìœ„: DB ìºì‹œ
        try:
            db_stats = self.db_cache.get_sector_stats()
            if db_stats and sector_name in db_stats:
                logger.debug(f"âœ… DB ìºì‹œ íˆíŠ¸: {sector_name}")
                return db_stats[sector_name], get_sector_benchmarks(...)
        except Exception as e:
            logger.debug(f"âš ï¸ DB ìºì‹œ ì‹¤íŒ¨: {e}")
        
        # 2ìˆœìœ„: pickle ìºì‹œ (ê¸°ì¡´)
        pickle_stats = _load_sector_cache()
        if pickle_stats and sector_name in pickle_stats:
            logger.debug(f"âœ… pickle ìºì‹œ íˆíŠ¸: {sector_name}")
            return pickle_stats[sector_name], get_sector_benchmarks(...)
        
        # 3ìˆœìœ„: data_provider (ì‹¤ì‹œê°„)
        return self.data_provider.get_sector_data(sector_name), ...
```

### ì˜µì…˜ 2: ì™„ì „ ì „í™˜

pickle ìºì‹œë¥¼ DBë¡œ ì™„ì „ ëŒ€ì²´:

```python
# sector_cache_manager.py â†’ db_cache_manager.pyë¡œ êµì²´

# Before
from sector_cache_manager import get_cache_manager
cache = get_cache_manager()
stats = cache.load_cache()

# After
from db_cache_manager import get_db_cache
db = get_db_cache()
stats = db.get_sector_stats()
```

**í˜¸í™˜ì„±**: ê¸°ì¡´ pickle ìºì‹œ í˜•ì‹ê³¼ 100% í˜¸í™˜ë©ë‹ˆë‹¤!

```python
# ê¸°ì¡´ í˜•ì‹
{
    'ì „ê¸°ì „ì': {
        'sample_size': 339,
        'per_percentiles': {'p10': 5.2, 'p50': 12.5, ...},
        'pbr_percentiles': {...},
        'roe_percentiles': {...}
    }
}

# DBì—ì„œ ë°˜í™˜í•˜ëŠ” í˜•ì‹ (ë™ì¼!)
{
    'ì „ê¸°ì „ì': {
        'sample_size': 339,
        'per_percentiles': {'p10': 5.2, 'p50': 12.5, ...},
        'pbr_percentiles': {...},
        'roe_percentiles': {...}
    }
}
```

---

## ğŸ”„ ì¼ë³„ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤

### ìë™ ì‹¤í–‰ (ê¶Œì¥)
```python
# daily_price_collector.pyê°€ ë§¤ì¼ 15:40ì— ìë™ ì‹¤í–‰

1. ì „ì²´ ì¢…ëª© ì¡°íšŒ (1000ê°œ)
2. DB ì €ì¥ (ì¦ë¶„ ì—…ë°ì´íŠ¸)
3. ì„¹í„° í†µê³„ ì¬ê³„ì‚°
4. ë¡œê·¸ ê¸°ë¡
```

### ìˆ˜ë™ ì‹¤í–‰
```python
from daily_price_collector import DailyPriceCollector

collector = DailyPriceCollector()

# ì „ì²´ ìˆ˜ì§‘
results = collector.collect_all_stocks(max_stocks=1000)

# ì¦ë¶„ ìˆ˜ì§‘ (ë³€ê²½ëœ ê²ƒë§Œ)
results = collector.collect_stale_stocks(max_age_days=1)
```

---

## ğŸ“ˆ í™œìš© ì˜ˆì‹œ

### 1. ì¢…ëª©ë³„ ê°€ê²© ì´ë ¥ ì¡°íšŒ
```python
from db_cache_manager import get_db_cache

db = get_db_cache()

# ì‚¼ì„±ì „ì ìµœê·¼ 90ì¼ ì‹œì„¸
history = db.get_stock_history('005930', days=90)
print(history.head())

#        date    price  per  pbr   roe
# 0  2025-10-12  75000 12.5  1.2  9.6
# 1  2025-10-11  74500 12.4  1.2  9.6
# 2  2025-10-10  74000 12.3  1.2  9.6
```

### 2. ì„¹í„° í†µê³„ ì¡°íšŒ
```python
# ìµœì‹  ì„¹í„° í†µê³„
stats = db.get_sector_stats()

# íŠ¹ì • ë‚ ì§œ
from datetime import date
stats = db.get_sector_stats(snapshot_date=date(2025, 10, 1))

print(stats['ì „ê¸°ì „ì']['per_percentiles']['p50'])
# â†’ 12.5
```

### 3. ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¡°íšŒ
```python
# 2024ë…„ 1ì›” 1ì¼ ìŠ¤ëƒ…ìƒ·
snapshot_20240101 = db.get_snapshot_by_date(date(2024, 1, 1))

# ê°€ì¹˜ì£¼ ìŠ¤í¬ë¦¬ë‹ (ê³¼ê±° ë°ì´í„°)
value_stocks = snapshot_20240101[
    (snapshot_20240101['per'] < 10) & 
    (snapshot_20240101['pbr'] < 1.0) &
    (snapshot_20240101['roe'] > 10)
]

print(f"2024-01-01 ê°€ì¹˜ì£¼: {len(value_stocks)}ê°œ")
```

### 4. Streamlit í†µí•©
```python
# value_stock_finder.py

import streamlit as st
from db_cache_manager import get_db_cache

@st.cache_resource
def load_db_cache():
    return get_db_cache()

db = load_db_cache()

# UIì—ì„œ ì„¹í„° í†µê³„ í‘œì‹œ
stats = db.get_sector_stats()
st.write(f"âœ… ì„¹í„° í†µê³„: {len(stats)}ê°œ (DB)")
```

---

## ğŸ¯ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### Phase 1: ë³‘í–‰ ìš´ì˜ (í˜„ì¬)
```
pickle ìºì‹œ (primary) + DB ìºì‹œ (secondary)
â†’ ì•ˆì •ì„± í™•ë³´
```

### Phase 2: DB ìš°ì„  (1ì£¼ì¼ í›„)
```
DB ìºì‹œ (primary) + pickle ìºì‹œ (fallback)
â†’ ì„±ëŠ¥ í–¥ìƒ ì²´ê°
```

### Phase 3: ì™„ì „ ì „í™˜ (2ì£¼ì¼ í›„)
```
DB ìºì‹œ (only)
â†’ pickle ìºì‹œ ì œê±°
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### API í˜¸ì¶œ íšŸìˆ˜
```
Before (pickle):
  ë§¤ì¼ 1000ë²ˆ Ã— 30ì¼ = 30,000ë²ˆ/ì›”

After (DB):
  ìµœì´ˆ 1000ë²ˆ (1íšŒ) + 50~100ë²ˆ/ì¼ Ã— 30ì¼ = 2,500~4,000ë²ˆ/ì›”
  
ì ˆê°: 26,000~27,500ë²ˆ/ì›” (87~92% â†“)
```

### ì¡°íšŒ ì†ë„
```
pickle: ~100ms (íŒŒì¼ I/O + unpickle)
DB:     ~10ms (ì¸ë±ìŠ¤ ì¿¼ë¦¬)

â†’ 10ë°° ë¹ ë¦„! âš¡
```

### ì €ì¥ ê³µê°„
```
pickle: 1~2 MB (í˜„ì¬)
DB:     0.12 MB (í˜„ì¬) â†’ 375 MB (5ë…„ì¹˜ ì˜ˆìƒ)

â†’ íš¨ìœ¨ì !
```

---

## ğŸ” ëª¨ë‹ˆí„°ë§

### DB í†µê³„ í™•ì¸
```python
db = get_db_cache()
stats = db.get_stats()

print(f"ì´ ìŠ¤ëƒ…ìƒ·: {stats['total_snapshots']:,}ê°œ")
print(f"ì¢…ëª© ìˆ˜: {stats['unique_stocks']:,}ê°œ")
print(f"ë‚ ì§œ ë²”ìœ„: {stats['date_range']}")
print(f"DB í¬ê¸°: {stats['db_size_mb']:.2f} MB")
```

### ë¡œê·¸ í™•ì¸
```bash
tail -f logs/daily_collector.log
```

### ìˆ˜ì§‘ ì´ë ¥ ì¡°íšŒ
```sql
-- SQLite CLI
sqlite3 cache/stock_data.db

SELECT * FROM collection_log
ORDER BY collection_date DESC
LIMIT 10;
```

---

## ğŸ› ï¸ ìœ ì§€ë³´ìˆ˜

### ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
```python
# 1ë…„ ì´ìƒ ê²½ê³¼í•œ ë°ì´í„° ì‚­ì œ
db.cleanup_old_data(keep_days=365)
```

### DB ë°±ì—…
```bash
# ìë™ ë°±ì—… (cron)
0 2 * * * cp cache/stock_data.db backups/stock_data_$(date +\%Y\%m\%d).db
```

### DB ìµœì í™”
```python
import sqlite3
conn = sqlite3.connect('cache/stock_data.db')
conn.execute('VACUUM')  # DB ì••ì¶•
conn.close()
```

---

## ğŸš¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: DB íŒŒì¼ì´ ì—†ìŒ
```bash
# í•´ê²°: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ìœ¼ë¡œ ìë™ ìƒì„±
python test_db_cache.py
```

### ë¬¸ì œ 2: ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ ì•ˆ ë¨
```bash
# 1. ì¦‰ì‹œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
python daily_price_collector.py --now

# 2. ë¡œê·¸ í™•ì¸
cat logs/daily_collector.log

# 3. ìˆ˜ë™ ì‹¤í–‰
python -c "from daily_price_collector import run_daily_collection; run_daily_collection()"
```

### ë¬¸ì œ 3: ì„¹í„° í†µê³„ê°€ ë¹„ì–´ìˆìŒ
```python
# ì„¹í„° í†µê³„ ì¬ê³„ì‚°
from db_cache_manager import get_db_cache
db = get_db_cache()
stats = db.compute_sector_stats()
print(f"ê³„ì‚° ì™„ë£Œ: {len(stats)}ê°œ ì„¹í„°")
```

---

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- **ì„¤ê³„ ë¬¸ì„œ**: `DB_CACHE_PROPOSAL.md`
- **í™œìš© ê°€ì´ë“œ**: `DAILY_PRICE_TRACKING.md`
- **í…ŒìŠ¤íŠ¸**: `test_db_cache.py`
- **ìŠ¤ì¼€ì¤„ëŸ¬**: `daily_price_collector.py`

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì„¤ì¹˜ ì™„ë£Œ
- [x] `apscheduler` íŒ¨í‚¤ì§€ ì„¤ì¹˜
- [x] DB ìŠ¤í‚¤ë§ˆ ì ìš©
- [x] í…ŒìŠ¤íŠ¸ ì„±ê³µ

### í†µí•© ì™„ë£Œ
- [ ] `value_stock_finder.py` ìˆ˜ì • (DB ìºì‹œ ìš°ì„ )
- [ ] ìŠ¤ì¼€ì¤„ëŸ¬ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì •

### ê²€ì¦ ì™„ë£Œ
- [ ] ì¼ë³„ ìˆ˜ì§‘ ì •ìƒ ì‘ë™ (1ì¼ ëŒ€ê¸°)
- [ ] ì„¹í„° í†µê³„ ì •í™•ì„± í™•ì¸
- [ ] ì„±ëŠ¥ ê°œì„  ì²´ê°

---

## ğŸ‰ ë‹¤ìŒ ë‹¨ê³„

1. âœ… **ì¦‰ì‹œ**: í…ŒìŠ¤íŠ¸ ì‹¤í–‰
2. â° **ì˜¤ëŠ˜**: ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
3. ğŸ“… **ë‚´ì¼**: ìë™ ìˆ˜ì§‘ í™•ì¸
4. ğŸ“Š **1ì£¼ì¼ í›„**: pickle â†’ DB ì „í™˜ ê²°ì •

---

**ì‘ì„±**: 2025-10-12  
**ë¬¸ì˜**: db_cache_manager.py ì£¼ì„ ì°¸ì¡°  
**ì—…ë°ì´íŠ¸**: í•„ìš” ì‹œ ìˆ˜ì‹œ

