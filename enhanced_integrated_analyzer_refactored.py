# enhanced_integrated_analyzer_refactored.py
from __future__ import annotations

# íƒ€ì… íŒíŠ¸ ê°•í™” ì ìš©
"""
ë¦¬íŒ©í† ë§ëœ í–¥ìƒëœ í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ
- ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì ìš©
- í´ë˜ìŠ¤ ë¶„ë¦¬ ë° ëª¨ë“ˆí™”
- ì„±ëŠ¥ ìµœì í™”
- ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
- ìŠ¤ë ˆë“œ ì•ˆì „ì„± ê°•í™”
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
- í‘œì¤€í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬
- ê°•í™”ëœ ì…ë ¥ ê²€ì¦
"""

import logging

# ê°œì„ ëœ ëª¨ë“ˆë“¤ import
try:
    from thread_safe_rate_limiter import ThreadSafeTPSRateLimiter, get_default_rate_limiter
    from memory_safe_cache import MemorySafeCache, get_global_cache
    from standardized_exception_handler import (
        StandardizedExceptionHandler, get_global_handler,
        handle_errors, retry_on_failure, circuit_breaker,
        ErrorCategory, ErrorSeverity, RetryConfig
    )
    from enhanced_input_validator import EnhancedInputValidator, get_global_validator
    from performance_optimizer import (
        LRUCache, PerformanceMonitor, timed_operation, 
        memoize_with_ttl, BatchProcessor, MemoryOptimizer
    )
    from type_definitions import (
        Symbol, Name, Price, Score, Percentage, MarketCap, Volume,
        AnalysisStatus, Grade, SectorType, CompanySize,
        PriceData, FinancialData, SectorAnalysis, AnalysisResult, AnalysisConfig,
        Result, validate_symbol, validate_price, validate_percentage, validate_score
    )
    from enhanced_error_handler import (
        EnhancedErrorHandler, retry_on_failure, handle_errors, circuit_breaker,
        ErrorSeverity, ErrorCategory, RetryConfig, CircuitBreakerConfig
    )
    from code_optimizer import (
        CodeOptimizer, DataProcessor, MemoryOptimizer, CodeQualityImprover,
        memoize, measure_performance, monitor_memory, get_performance_stats,
        optimize_memory, get_memory_usage
    )
    from performance_monitor import (
        PerformanceMonitor, PerformanceProfiler, record_metric, record_request,
        get_performance_stats as get_monitor_stats, export_performance_report,
        profile_function
    )
    from price_display_enhancer import (
        PriceDisplayEnhancer, format_price, format_market_cap, 
        calculate_price_position, display_detailed_price_info, create_price_summary
    )
    from value_investing_philosophy import (
        ValueInvestingPhilosophy, analyze_business_model, calculate_intrinsic_value,
        calculate_margin_of_safety, add_to_watchlist, get_buy_signals, generate_investment_report
    )
    IMPROVED_MODULES_AVAILABLE = True
except ImportError as e:
    logging.warning(f"ê°œì„ ëœ ëª¨ë“ˆë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    IMPROVED_MODULES_AVAILABLE = False
    
    # Fallback implementations for missing decorators
    def measure_performance(func):
        """Fallback performance measurement decorator"""
        return func
    
    def monitor_memory(func):
        """Fallback memory monitoring decorator"""
        return func
    
    def profile_function(name):
        """Fallback profiling decorator"""
        def decorator(func):
            return func
        return decorator
    
    def timed_operation(name):
        """Fallback timed operation decorator"""
        def decorator(func):
            return func
        return decorator
    
    def handle_errors(severity=None, category=None):
        """Fallback error handling decorator"""
        def decorator(func):
            return func
        return decorator
    
    def retry_on_failure(max_attempts=3, base_delay=1.0, max_delay=60.0, strategy=None):
        """Fallback retry decorator"""
        def decorator(func):
            return func
        return decorator
    
    # Fallback enums and classes
    class ErrorSeverity:
        LOW = "low"
        MEDIUM = "medium"
        HIGH = "high"
        CRITICAL = "critical"
    
    class ErrorCategory:
        API = "api"
        DATA = "data"
        NETWORK = "network"
        VALIDATION = "validation"
        SYSTEM = "system"
        BUSINESS = "business"
    
    class RetryConfig:
        def __init__(self, max_attempts=3, base_delay=1.0, max_delay=60.0, backoff_multiplier=2.0, jitter=True, strategy=None):
            self.max_attempts = max_attempts
            self.base_delay = base_delay
            self.max_delay = max_delay
            self.backoff_multiplier = backoff_multiplier
            self.jitter = jitter
            self.strategy = strategy

# Public API surface
__all__ = [
    # Main classes
    'EnhancedIntegratedAnalyzer',
    'AnalysisResult',
    'AnalysisStatus',
    'AnalysisConfig',
    
    # Data classes
    'PriceData',
    'FinancialData',
    'SectorAnalysis',
    'ErrorType',
    
    # Utilities
    'normalize_market_cap_ekwon',
    'serialize_for_json',
    'fmt',
    'fmt_pct',
    
    # Configuration
    'ConfigManager',
    'MetricsCollector',
]

"""
ìŠ¤ë ˆë“œ ì•ˆì „ì„± (Thread Safety):
- ë‚´ë¶€ ìºì‹œ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì€ RLockìœ¼ë¡œ ë³´í˜¸ë¨
- ì™¸ë¶€ ë°ì´í„° í”„ë¡œë°”ì´ë”(KISDataProvider, EnhancedPriceProvider)ëŠ” 
  ìŠ¤ë ˆë“œ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ. ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ì£¼ì˜ í•„ìš”.
- ë ˆì´íŠ¸ë¦¬ë¯¸í„°ëŠ” ìŠ¤ë ˆë“œ ì•ˆì „í•˜ê²Œ êµ¬í˜„ë¨
- ê¶Œì¥ì‚¬í•­: í”„ë¡œë°”ì´ë” ë‚´ë¶€ì—ì„œ ìš”ì²­ ë‹¨ìœ„ ì„¸ì…˜ ìƒì„± ë˜ëŠ” ë½/í ë„ì…

í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Environment Variables):
- KIS_MAX_TPS: API TPS ì œí•œ (ê¸°ë³¸ê°’: 8, ë‹¨ìœ„: ìš”ì²­/ì´ˆ)
- MAX_WORKERS: ì›Œì»¤ ìˆ˜ ê°•ì œ ì„¤ì • (ê¸°ë³¸ê°’: 0=ìë™, ë‹¨ìœ„: ê°œ)
- EPS_MIN: EPS ìµœì†Œì¹˜ (ê¸°ë³¸ê°’: 0.1, ë‹¨ìœ„: ì›)
- BPS_MIN: BPS ìµœì†Œì¹˜ (ê¸°ë³¸ê°’: 100.0, ë‹¨ìœ„: ì›)
- POS_TINY_BAND_THRESHOLD: 52ì£¼ ë°´ë“œ ì„ê³„ì¹˜ (ê¸°ë³¸ê°’: 0.001, ë‹¨ìœ„: 0.1%)
- KIS_CACHE_TTL_PRICE: ê°€ê²© ìºì‹œ TTL (ê¸°ë³¸ê°’: 5.0, ë‹¨ìœ„: ì´ˆ)
- KIS_CACHE_TTL_FINANCIAL: ì¬ë¬´ ìºì‹œ TTL (ê¸°ë³¸ê°’: 900.0, ë‹¨ìœ„: ì´ˆ)
- KIS_CACHE_MAX_KEYS: ìºì‹œ ìµœëŒ€ ì—”íŠ¸ë¦¬ ìˆ˜ (ê¸°ë³¸ê°’: 2000, ë‹¨ìœ„: ê°œ)
- PREFERRED_STOCK_INCLUDE_WOORI: "ìš°ë¦¬" ì‹œì‘ ì¢…ëª© ìš°ì„ ì£¼ ê°„ì£¼ (ê¸°ë³¸ê°’: false)
- PER_MAX_DEFAULT: PER ìƒí•œ í´ë¨í”„ (ê¸°ë³¸ê°’: 500.0, ë‹¨ìœ„: ë°°)
- PBR_MAX_DEFAULT: PBR ìƒí•œ í´ë¨í”„ (ê¸°ë³¸ê°’: 100.0, ë‹¨ìœ„: ë°°)
- SECTOR_TARGET_GOOD: ì„¹í„° í”¼ì–´ ëª©í‘œ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ê°’: 60, ë‹¨ìœ„: ê°œ)
- RATE_LIMITER_DEFAULT_TIMEOUT: ë ˆì´íŠ¸ë¦¬ë¯¸í„° íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ê°’: 2.0, ë‹¨ìœ„: ì´ˆ)
- RATE_LIMITER_NOTIFY_ALL: ë ˆì´íŠ¸ë¦¬ë¯¸í„° ê³µì •í•œ ì›¨ì´í¬ì—… (ê¸°ë³¸ê°’: false)
- MARKET_CAP_STRICT_MODE: ì‹œì´ ë‹¨ìœ„ ì¶”ì • ì—„ê²© ëª¨ë“œ (ê¸°ë³¸ê°’: true; true=ì• ë§¤ ê°’ ë¬´ì‹œ, false=ì™„í™” ë³€í™˜ í—ˆìš©)
- MARKET_CAP_ASSUME_EOKWON_MAX: ì–µì› ë‹¨ìœ„ë¡œ ê°„ì£¼í•  ìµœëŒ€ê°’ (ê¸°ë³¸ê°’: 2,000,000, ë‹¨ìœ„: ì–µì›)
- MARKET_CAP_ASSUME_EOKWON_MIN: ì–µì› ë‹¨ìœ„ë¡œ ê°„ì£¼í•  ìµœì†Œê°’ (ê¸°ë³¸ê°’: 1.0, ë‹¨ìœ„: ì–µì›)
- ENABLE_FAKE_PROVIDERS: ì™¸ë¶€ ëª¨ë“ˆ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ êµ¬í˜„ ì‚¬ìš© (ê¸°ë³¸ê°’: false; true=ìš´ì˜ ì¤‘ ì¼ì‹œ ì¥ì•  ì‹œ ì§„ë‹¨ ê³„ì†)
"""

import pandas as pd
import numpy as np
import json
import time
import os
import yaml
import math
import random
import signal
import atexit
import enum
import weakref
import sys
import psutil
import typer
import io
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple, Union, TypedDict, Set
from decimal import Decimal
from threading import RLock, Condition
from collections import deque, OrderedDict
# rich import ì œê±° (ë¯¸ì‚¬ìš©)

# monotonic time ë³„ì¹­ (ì‹œìŠ¤í…œ ì‹œê°„ ë³€ê²½ì— ì•ˆì „)
_monotonic = time.monotonic

# âœ… ëª¨ë“ˆ ë ˆë²¨ í™˜ê²½ë³€ìˆ˜ ìºì‹œ (í•«íŒ¨ìŠ¤ ìµœì í™”)
_ENV_CACHE = {
    'current_ratio_ambiguous_strategy': os.getenv("CURRENT_RATIO_AMBIGUOUS_STRATEGY", "as_is"),
    'current_ratio_force_percent': os.getenv("CURRENT_RATIO_FORCE_PERCENT", "false"),
    'market_cap_strict_mode': os.getenv("MARKET_CAP_STRICT_MODE", "true"),
}

# âœ… ëª¨ë“ˆ ë ˆë²¨ ë¡œê¹… ì œì–´ (í•œ ë²ˆë§Œ ê²½ê³ ) - ìŠ¤ë ˆë“œ ì•ˆì „
_market_cap_ambiguous_logged = False
_market_cap_ambiguous_counter = 0
_market_cap_last_agg_ts = 0.0
_market_cap_ambiguous_lock = RLock()

def _is_indexed_by_code(df: pd.DataFrame) -> bool:
    """DataFrameì´ 'ë‹¨ì¶•ì½”ë“œ'ë¡œ ì¸ë±ì‹±ë˜ì–´ ìˆëŠ”ì§€ ì•ˆì „í•˜ê²Œ í™•ì¸"""
    return df.index.names and ('ë‹¨ì¶•ì½”ë“œ' in df.index.names)

def _refresh_env_cache():
    """í™˜ê²½ë³€ìˆ˜ ìºì‹œ hot-reload (ëŸ°íƒ€ì„ ì„¤ì • ë³€ê²½ ì§€ì›)"""
    _ENV_CACHE['current_ratio_ambiguous_strategy'] = os.getenv("CURRENT_RATIO_AMBIGUOUS_STRATEGY", "as_is")
    _ENV_CACHE['current_ratio_force_percent'] = os.getenv("CURRENT_RATIO_FORCE_PERCENT", "false")
    _ENV_CACHE['market_cap_strict_mode'] = os.getenv("MARKET_CAP_STRICT_MODE", "true")

# --- í™˜ê²½ë³€ìˆ˜ ìºì‹œ í•«ë¦¬ë¡œë“œ: SIGHUP ì§€ì› ------------------------------------
def _handle_sighup(signum, frame):
    try:
        _refresh_env_cache()
        _reload_all_analyzer_env_cache()  # Analyzer ì¸ìŠ¤í„´ìŠ¤ env_cacheë„ ì¬ì ìš©
        logging.info("[env] SIGHUP received â†’ environment cache reloaded")
    except Exception as e:
        logging.debug(f"[env] SIGHUP handler error: {e}")

# Analyzer ì¸ìŠ¤í„´ìŠ¤ë³„ env_cache ì¬ì ìš©ì„ ìœ„í•œ ì½œë°± ë“±ë¡ (WeakSetìœ¼ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
_analyzer_instances = weakref.WeakSet()

def _register_analyzer_for_env_reload(analyzer):
    """Analyzer ì¸ìŠ¤í„´ìŠ¤ë¥¼ í™˜ê²½ë³€ìˆ˜ ë¦¬ë¡œë“œ ëŒ€ìƒìœ¼ë¡œ ë“±ë¡"""
    _analyzer_instances.add(analyzer)

def _unregister_analyzer_for_env_reload(analyzer):
    """Analyzer ì¸ìŠ¤í„´ìŠ¤ë¥¼ í™˜ê²½ë³€ìˆ˜ ë¦¬ë¡œë“œ ëŒ€ìƒì—ì„œ ì œê±°"""
    _analyzer_instances.discard(analyzer)

def _reload_all_analyzer_env_cache():
    """ëª¨ë“  ë“±ë¡ëœ Analyzer ì¸ìŠ¤í„´ìŠ¤ì˜ env_cache ì¬ì ìš©"""
    for analyzer in list(_analyzer_instances):
        try:
            analyzer.env_cache = {
                'current_ratio_ambiguous_strategy': os.getenv("CURRENT_RATIO_AMBIGUOUS_STRATEGY", "as_is"),
                'current_ratio_force_percent': os.getenv("CURRENT_RATIO_FORCE_PERCENT", "false"),
                'market_cap_strict_mode': os.getenv("MARKET_CAP_STRICT_MODE", "true"),
                'max_sector_peers_base': safe_env_int("MAX_SECTOR_PEERS_BASE", 40, min_val=5),
                'max_sector_peers_full': safe_env_int("MAX_SECTOR_PEERS_FULL", 200, min_val=10),
                'sector_target_good': safe_env_int("SECTOR_TARGET_GOOD", 60, min_val=10),
                'max_sector_cache_entries': safe_env_int("MAX_SECTOR_CACHE_ENTRIES", 64, min_val=8),
            }
        except Exception as e:
            logging.debug(f"[env] Analyzer env_cache reload error: {e}")

# SIGHUP í•¸ë“¤ëŸ¬ ë“±ë¡ í•¨ìˆ˜ (CLIì—ì„œ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œ)
def install_sighup_handler():
    """SIGHUP í•¸ë“¤ëŸ¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
    
    âš ï¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œ ë¡œê¹…/ìœ í‹¸ ì´ˆê¸°í™” ì´í›„ 'ë§ˆì§€ë§‰'ì— í˜¸ì¶œí•˜ì„¸ìš”.
    ìˆœì„œ: _setup_logging_if_needed() â†’ ê¸°íƒ€ ì´ˆê¸°í™” â†’ install_sighup_handler()
    """
    try:
        signal.signal(signal.SIGHUP, _handle_sighup)
        logging.debug("[env] SIGHUP handler installed")
        _mark_sighup_installed()  # ì„¤ì¹˜ ì™„ë£Œ í‘œì‹œ
    except (AttributeError, OSError) as e:
        # Windows ë“±ì—ì„œëŠ” SIGHUP ë¯¸ì§€ì› - ì´ëŠ” ì •ìƒì ì¸ ë™ì‘
        import platform
        if platform.system() == "Windows":
            logging.debug("[env] SIGHUP not supported on Windows; env hot-reload disabled")
        else:
            logging.debug(f"[env] SIGHUP not supported on this platform: {e}")
        _mark_sighup_installed()  # í”Œë«í¼ ì œí•œìœ¼ë¡œ ì¸í•œ ì‹¤íŒ¨ë„ "ì„¤ì¹˜ ì‹œë„ë¨"ìœ¼ë¡œ í‘œì‹œ
    except Exception as e:
        # ê¸°íƒ€ ì˜ˆì™¸
        logging.debug(f"[env] SIGHUP handler installation failed: {e}")
        _mark_sighup_installed()  # ì„¤ì¹˜ ì‹œë„ëŠ” í–ˆìœ¼ë¯€ë¡œ í‘œì‹œ

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================

def normalize_market_cap_ekwon(x: Optional[float]) -> Optional[float]:
    """
    Normalize market cap to ì–µì› (eokwon).
    Heuristics:
      - If value looks like ì–µì› (<= 2,000,000 = 200ì¡°), keep as-is.
      - If value looks like ì› (>= 1e11 = 1,000ì–µ), convert to ì–µì› by /1e8.
      - Otherwise treat as ambiguous â†’ optional non-strict conversion via env.
    """
    v = DataValidator.safe_float_optional(x)
    if v is None or not math.isfinite(v) or v <= 0:
        return None

    # Enhanced heuristic: avoid tiny KRW values being treated as eokwon
    # Values like 20,000,001ì› should not be treated as 20,000,001ì–µì›
    max_eokwon_threshold = safe_env_float("MARKET_CAP_ASSUME_EOKWON_MAX", 2_000_000, 0.0)  # 200ì¡° ì–µì›
    min_eokwon_threshold = safe_env_float("MARKET_CAP_ASSUME_EOKWON_MIN", 1.0, 0.0)  # 1ì–µì› (ì†Œí˜•ì£¼ í¬í•¨)
    
    # If already reasonable in ì–µì› range, assume eokwon
    # But exclude very small values that are likely in won units
    if v <= max_eokwon_threshold and v >= min_eokwon_threshold and v >= 1e7:
        logging.debug(f"[unit] market_cap assumed eokwon: {x} -> {v}")
        return v

    # If looks like KRW (ì›): anything â‰¥ 1e11 (1,000ì–µ ì›) convert to ì–µì›
    if v >= 1e11:
        converted = v / 1e8
        logging.debug(f"[unit] market_cap converted from wonâ†’eokwon: {x} -> {converted}")
        return converted

    # Ambiguous band (1e7 ~ 1e11): gate via env for safety (ìºì‹œëœ ê°’ ì‚¬ìš©)
    non_strict = _ENV_CACHE['market_cap_strict_mode'].lower() != "true"
    if non_strict and (1e7 <= v < 1e11):
        converted = v / 1e8
        logging.debug(f"[unit] market_cap non-strict (ambiguous) wonâ†’eokwon: {x} -> {converted} (ì²œë‹¨ìœ„ êµ¬ë¶„ í•´ì„ ê²°ê³¼)")
        return converted

    # Confidence logging when discarding ambiguous values (1íšŒ ê²½ê³  í™œìš©) - ìŠ¤ë ˆë“œ ì•ˆì „
    global _market_cap_ambiguous_logged, _market_cap_ambiguous_counter, _market_cap_last_agg_ts
    with _market_cap_ambiguous_lock:
        if 1e10 <= v < 1e11 and not _market_cap_ambiguous_logged:
            # 1e10 â‰¤ v < 1e11ë§Œ ê²½ê³  í›„ None (ì½”ìŠ¤ë‹¥ ì†Œí˜•ì£¼ ì› ë‹¨ìœ„ ì‹œì´ ê³ ë ¤)
            logging.warning("[unit] market_cap ambiguous range encountered (strict mode). Consider MARKET_CAP_STRICT_MODE=false temporarily for diagnosis.")
            _market_cap_ambiguous_logged = True
        elif 1e10 <= v < 1e11:
            _market_cap_ambiguous_counter += 1
            now = _monotonic()
            if now - _market_cap_last_agg_ts > 60.0 and _market_cap_ambiguous_counter > 0:
                logging.warning(f"[unit] market_cap ambiguous (strict mode) last 60s: {_market_cap_ambiguous_counter} hits")
                _market_cap_ambiguous_counter = 0
                _market_cap_last_agg_ts = now  # Set timestamp when warning is logged
            else:
                logging.debug(f"[unit] market_cap ambiguous range dropped in strict mode: {x} -> None (1e10 â‰¤ v < 1e11)")
        elif 1e7 <= v < 1e10:
            # 1e7 â‰¤ v < 1e10ì€ ì¶”ì  ë©”íŠ¸ë¦­ + ìƒ˜í”Œ ì €ì¥ (ë””ë²„ê·¸)
            logging.debug(f"[unit] market_cap small value dropped: {x} -> None (1e7 â‰¤ v < 1e10, likely small cap in won)")
        elif v < 1e7:
            logging.debug(f"[unit] market_cap too small (dropped): {x} -> None (ì²œë‹¨ìœ„ êµ¬ë¶„ í•´ì„ ê²°ê³¼)")
    
    # All ambiguous cases return None
    return None

# íƒ€ì… ì •ì˜
JSONValue = Union[None, bool, int, float, str, List["JSONValue"], Dict[str, "JSONValue"]]
PeerTriple = Tuple[float, float, float]

# âœ… TypedDict ì •ì˜: ë°ì´í„° êµ¬ì¡° ë“œë¦¬í”„íŠ¸ ë°©ì§€ ë° ì—ë””í„° íŒíŠ¸ ê°œì„ 
class PriceData(TypedDict, total=False):
    """ê°€ê²© ë°ì´í„° êµ¬ì¡°"""
    current_price: Optional[float]
    w52_high: Optional[float]
    w52_low: Optional[float]
    per: Optional[float]
    pbr: Optional[float]
    eps: Optional[float]
    bps: Optional[float]
    volume: Optional[int]
    market_cap: Optional[float]
    price_change: Optional[float]
    price_change_rate: Optional[float]

class FinancialData(TypedDict, total=False):
    """ì¬ë¬´ ë°ì´í„° êµ¬ì¡°"""
    roe: Optional[float]
    roa: Optional[float]
    debt_ratio: Optional[float]
    equity_ratio: Optional[float]
    revenue_growth_rate: Optional[float]
    operating_income_growth_rate: Optional[float]
    net_income_growth_rate: Optional[float]
    net_profit_margin: Optional[float]
    gross_profit_margin: Optional[float]
    current_ratio: Optional[float]
    profitability_grade: Optional[str]

class SectorAnalysis(TypedDict, total=False):
    """ì„¹í„° ë¶„ì„ ê²°ê³¼ êµ¬ì¡°"""
    grade: str
    total_score: Optional[float]
    breakdown: Dict[str, float]
    is_leader: bool
    base_score: Optional[float]
    leader_bonus: float
    notes: List[str]

# =============================================================================
# ë¡œê¹… ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹°
# =============================================================================

# ---- ëŸ°íƒ€ì„ ë¡œê¹… ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´) ------------------------------------
_LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
_LOG_FMT = os.getenv(
    "LOG_FORMAT",
    "%(asctime)s %(levelname)s [%(name)s] %(message)s"
)
# âœ… ë¡œê·¸ ì´ˆê¸°í™” íŒ¨í„´ ê°œì„ : ëª¨ë“ˆ import ì‹œì ì—ëŠ” ì„¤ì •í•˜ì§€ ì•Šê³ , ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œë§Œ ê¸°ë³¸ ë¡œê¹… ì„¤ì •
def _setup_logging_if_needed():
    """ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œë§Œ í˜¸ì¶œí•˜ì—¬ ê¸°ë³¸ ë¡œê¹… ì„¤ì •
    
    CLI ì‚¬ìš© ì˜ˆì‹œ:
        from enhanced_integrated_analyzer_refactored import _setup_logging_if_needed, install_sighup_handler
        
        def main():
            _setup_logging_if_needed()  # ë¡œê¹… ì´ˆê¸°í™”
            # ê¸°íƒ€ í™˜ê²½/ìœ í‹¸ ì´ˆê¸°í™”
            install_sighup_handler()    # ëŸ°íƒ€ì„ í™˜ê²½ë³€ìˆ˜ í•«ë¦¬ë¡œë“œ
            # ë©”ì¸ ë¡œì§ ì‹¤í–‰
    """
    root = logging.getLogger()
    if not root.handlers:
        try:
            logging.basicConfig(
                level=getattr(logging, _LOG_LEVEL, logging.INFO),
                format=_LOG_FMT,
                datefmt="%H:%M:%S",
            )
        except Exception:
            # ì´ë¯¸ ë‹¤ë¥¸ í™˜ê²½ì—ì„œ í•¸ë“¤ëŸ¬ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìƒˆ í•¸ë“¤ëŸ¬ ì¶”ê°€ëŠ” ê±´ë„ˆëœ€
            if not root.handlers:
                logging.basicConfig(level=logging.INFO, format="%(levelname)s %(message)s")
            logging.warning("ë¡œê·¸ ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ì¡´ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

def _validate_startup_configuration():
    """ë¶€íŒ… ì‹œ êµ¬ì„± ì‹¤ìˆ˜ ê²€ì¦ ë° ì°¨ë‹¨"""
    errors = []
    warnings = []
    
    # 1. ë°¸ë¥˜ì—ì´ì…˜ í˜ë„í‹° ì´ì¤‘ ì ìš© ê²€ì¦
    price_penalty = safe_env_bool("VAL_PENALTY_IN_PRICE", True)
    fin_penalty = safe_env_bool("VAL_PENALTY_IN_FIN", False)
    
    if price_penalty and fin_penalty:
        errors.append("VAL_PENALTY_IN_PRICE and VAL_PENALTY_IN_FIN cannot both be True. This causes double penalty application.")
    
    # 2. ì‹œì´ ì •ê·œí™” ëª¨ë“œ ê²€ì¦
    strict_mode = safe_env_bool("MARKET_CAP_STRICT_MODE", True)
    if not strict_mode:
        warnings.append("MARKET_CAP_STRICT_MODE is disabled. This may allow ambiguous market cap values.")
    
    # 3. ë ˆì´íŠ¸ë¦¬ë¯¸í„° ì„¤ì • ê²€ì¦
    max_tps = safe_env_int("KIS_MAX_TPS", 8, 1)
    if max_tps > 20:
        warnings.append(f"KIS_MAX_TPS is very high ({max_tps}). Consider reducing to avoid API quota issues.")
    
    # 4. ìºì‹œ ì••ì¶• ì„ê³„ê°’ ê²€ì¦
    compress_min = safe_env_int("KIS_CACHE_COMPRESS_MIN_BYTES", 8 * 1024, 1024)
    if compress_min < 1024:
        warnings.append(f"KIS_CACHE_COMPRESS_MIN_BYTES is very low ({compress_min}). Consider increasing to avoid CPU overhead.")
    
    # 5. SIGHUP í•¸ë“¤ëŸ¬ ì„¤ì¹˜ í™•ì¸
    if not hasattr(_validate_startup_configuration, '_sighup_installed'):
        warnings.append("SIGHUP handler not installed. Environment variable hot-reload is disabled.")
    
    # ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
    if errors:
        error_msg = "Startup configuration errors:\n" + "\n".join(f"  - {error}" for error in errors)
        if warnings:
            error_msg += "\nWarnings:\n" + "\n".join(f"  - {warning}" for warning in warnings)
        raise ValueError(error_msg)
    
    # ê²½ê³ ë§Œ ìˆìœ¼ë©´ ë¡œê¹…
    if warnings:
        for warning in warnings:
            logging.warning(f"[startup] {warning}")
    
    logging.info("[startup] Configuration validation passed")

def _mark_sighup_installed():
    """SIGHUP í•¸ë“¤ëŸ¬ ì„¤ì¹˜ ì™„ë£Œ í‘œì‹œ"""
    _validate_startup_configuration._sighup_installed = True
# ---------------------------------------------------------------------------

class LogLevel:
    """ë¡œê¹… ë ˆë²¨ ìƒìˆ˜"""
    ERROR = "error"
    WARNING = "warning"
    INFO = "info"
    DEBUG = "debug"

class ErrorType:
    """ì—ëŸ¬ íƒ€ì… ë¶„ë¥˜ ìƒìˆ˜ (ë©”íŠ¸ë¦­ìŠ¤ ì§‘ê³„ìš©)"""
    API_TIMEOUT = "api_timeout"
    API_CONNECTION = "api_connection"
    API_RATE_LIMIT = "api_rate_limit"
    DATA_PARSE = "data_parse"
    SECTOR_PEER_DATA = "sector_peer_data_error"
    FINANCIAL_DATA = "financial_data_error"
    PRICE_DATA = "price_data_error"
    STABILITY_RATIO = "stability_ratio_error"
    # âœ… ì¶”ê°€ëœ ì—ëŸ¬íƒ€ì… ìƒìˆ˜ë“¤
    OPINION = "opinion_analysis_error"
    ESTIMATE = "estimate_analysis_error"
    EMPTY_PRICE_PAYLOAD = "empty_price_payload"
    INVALID_52W_BAND = "invalid_52w_band"  # 52ì£¼ ë°´ë“œ ë¹ˆì•½/í‡´í™”
    HTTP_4XX = "http_4xx"
    HTTP_5XX = "http_5xx"
    UNKNOWN = "unknown_error"
    
    # ìƒìœ„ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (SRE ëŒ€ì‹œë³´ë“œìš©)
    CATEGORY_MAP = {
        API_TIMEOUT: "ë„¤íŠ¸ì›Œí¬",
        API_CONNECTION: "ë„¤íŠ¸ì›Œí¬", 
        API_RATE_LIMIT: "HTTP",
        HTTP_4XX: "HTTP",
        HTTP_5XX: "HTTP",
        DATA_PARSE: "ë°ì´í„°",
        FINANCIAL_DATA: "ë°ì´í„°",
        PRICE_DATA: "ë°ì´í„°",
        EMPTY_PRICE_PAYLOAD: "ë°ì´í„°",
        INVALID_52W_BAND: "ë°ì´í„°",
        SECTOR_PEER_DATA: "ë¶„ì„",
        STABILITY_RATIO: "ë¶„ì„",
        OPINION: "ë¶„ì„",
        ESTIMATE: "ë¶„ì„",
        UNKNOWN: "ê¸°íƒ€"
    }
    
    @classmethod
    def get_category(cls, error_type: str) -> str:
        """ì—ëŸ¬ íƒ€ì…ì„ ìƒìœ„ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘"""
        return cls.CATEGORY_MAP.get(error_type, "ê¸°íƒ€")

def log_error(operation: str, symbol: str = None, error: Exception = None, level: str = LogLevel.WARNING):
    """ì¼ê´€ëœ ì—ëŸ¬ ë¡œê¹… í¬ë§· (ìš´ì˜ ë¡œê·¸ grep ì¹œí™”ì )"""
    if symbol:
        message = f"{operation} ì‹¤íŒ¨ | symbol={symbol} | err={error}"
    else:
        message = f"{operation} ì‹¤íŒ¨ | err={error}"
    
    # âœ… LogLevel ê°’ ì¼ê´€ì„± ê°œì„ : ë ˆë²¨ ë§¤í•‘ ì‚¬ìš©
    LEVEL_MAP = {
        LogLevel.ERROR: logging.error,
        LogLevel.WARNING: logging.warning,
        LogLevel.INFO: logging.info,
        LogLevel.DEBUG: logging.debug
    }
    LEVEL_MAP.get(level, logging.warning)(message)

def log_success(operation: str, symbol: str = None, details: str = None):
    """ì¼ê´€ëœ ì„±ê³µ ë¡œê¹… í¬ë§·"""
    if symbol and details:
        message = f"âœ… {operation} ì„±ê³µ {symbol}: {details}"
    elif symbol:
        message = f"âœ… {operation} ì„±ê³µ {symbol}"
    else:
        message = f"âœ… {operation} ì„±ê³µ"
    
    logging.info(message)

def safe_env_int(key: str, default: int, min_val: Optional[int] = None) -> int:
    """ì•ˆì „í•œ í™˜ê²½ë³€ìˆ˜ ì •ìˆ˜ íŒŒì‹± (0=auto ì„¤ì • í—ˆìš©)"""
    try:
        value = int(os.getenv(key, str(default)))
    except (ValueError, TypeError):
        value = default
    if min_val is None:
        return value
    return max(min_val, value)

def safe_env_float(key: str, default: float, min_val: float = 0.0) -> float:
    """ì•ˆì „í•œ í™˜ê²½ë³€ìˆ˜ ì‹¤ìˆ˜ íŒŒì‹± (ìŒìˆ˜ ë°©ì–´)"""
    try:
        value = float(os.getenv(key, str(default)))
        return max(min_val, value)  # ìµœì†Œê°’ ë³´ì¥
    except (ValueError, TypeError):
        return max(min_val, default)

def safe_env_bool(key: str, default: bool = False) -> bool:
    """ì•ˆì „í•œ í™˜ê²½ë³€ìˆ˜ ë¶ˆë¦° íŒŒì‹± (robust parser)"""
    v = os.getenv(key)
    if v is None:
        return default
    return str(v).strip().lower() in {"1", "true", "t", "yes", "y", "on"}

def safe_env_ms_to_seconds(key: str, default_ms: float, min_ms: float = 0.0) -> float:
    """
    ë°€ë¦¬ì´ˆ(ms) í™˜ê²½ë³€ìˆ˜ë¥¼ ì´ˆ(second)ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜.
    RATE_LIMITER_MIN_SLEEP_MS ê°™ì€ í‚¤ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ì˜ëª» ì‚¬ìš©í•˜ëŠ” ë²„ê·¸ ë°©ì§€.
    """
    try:
        ms = float(os.getenv(key, str(default_ms)))
        ms = max(min_ms, ms)
    except (ValueError, TypeError):
        ms = max(min_ms, default_ms)
    return ms / 1000.0

# =============================================================================
# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í´ë˜ìŠ¤
# =============================================================================

class MetricsCollector:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ê´€ë¦¬"""
    
    def __init__(self):
        self.metrics = {
            'api_calls': {'total': 0, 'success': 0, 'error': 0},
            'cache_hits': {'price': 0, 'financial': 0, 'sector': 0},
            'cache_misses': {'price': 0, 'financial': 0, 'sector': 0},
            'analysis_duration': {'total': 0, 'count': 0, 'avg': 0},
            'sector_evaluation': {'total': 0, 'count': 0, 'avg': 0},
            'stocks_analyzed': 0,
            'errors_by_type': {},
            # âœ… ì„¹í„° í”¼ì–´ ìƒ˜í”Œ í¬ê¸° ë©”íŠ¸ë¦­ ì¶”ê°€
            'sector_sample_insufficient': 0,
            # âœ… ë©”íŠ¸ë¦­ ê°œì„ : missing í•„ë“œ ì¹´ìš´í„° ì¶”ê°€
            'missing_financial_fields': 0,
            # âœ… API ì¬ì‹œë„ ì¤‘ê°„ ì‹¤íŒ¨ ì¹´ìš´í„° ì¶”ê°€ (ì´ì¤‘ ì§‘ê³„ ë°©ì§€)
            'api_retry_attempt_errors': 0,
            # âœ… PER/PBR ìŠ¤í‚µ ë©”íŠ¸ë¦­ ì¶”ê°€
            'valuation_skips': {'per_epsmin': 0, 'pbr_bpsmin': 0},
            # âœ… ë¹ˆ í˜ì´ë¡œë“œ ë©”íŠ¸ë¦­ ì¶”ê°€
            'empty_price_payloads': 0,
            'start_time': _monotonic()
        }
        # Histogram buckets for duration analysis (seconds)
        # âœ… ë©”íŠ¸ë¦­ ê°œì„ : p95 ë°±ë¶„ìœ„ ì¶”ê°€ (SREê°€ ì£¼ë¡œ ì‚¬ìš©)
        # ìš´ì˜ ê¸°ì¤€: p90ì´ 5ì´ˆ, p95ê°€ 10ì´ˆ ë„˜ìœ¼ë©´ ê²½ê³  (SLO)
        self.duration_buckets = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
        self.analysis_histogram = [0] * (len(self.duration_buckets) + 1)  # +1 for overflow
        self.sector_histogram = [0] * (len(self.duration_buckets) + 1)
        self.lock = RLock()
    
    def record_api_call(self, success: bool, error_type: str = None):
        """API í˜¸ì¶œ ê¸°ë¡ (ìµœì¢… ê²°ê³¼ë§Œ)
        
        Note: This should only be called for final API results. 
        Do not call this when _with_retries has already recorded the final failure.
        """
        with self.lock:
            self.metrics['api_calls']['total'] += 1
            if success:
                self.metrics['api_calls']['success'] += 1
            else:
                self.metrics['api_calls']['error'] += 1
                if error_type:
                    self.metrics['errors_by_type'][error_type] = self.metrics['errors_by_type'].get(error_type, 0) + 1

    def record_api_attempt_error(self, error_type: str = None):
        """API ì¬ì‹œë„ ì¤‘ê°„ ì‹¤íŒ¨ ê¸°ë¡ (ì´ì¤‘ ì§‘ê³„ ë°©ì§€)"""
        with self.lock:
            self.metrics['api_retry_attempt_errors'] += 1
            if error_type:
                self.metrics['errors_by_type'][error_type] = self.metrics['errors_by_type'].get(error_type, 0) + 1

    def record_flag_error(self, error_type: str):
        """í”Œë˜ê·¸ ì—ëŸ¬ ê¸°ë¡ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
        with self.lock:
            self.metrics['errors_by_type'][error_type] = \
                self.metrics['errors_by_type'].get(error_type, 0) + 1

    def record_valuation_skip(self, kind: str):
        """ë°¸ë¥˜ì—ì´ì…˜ ìŠ¤í‚µ ê¸°ë¡ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
        with self.lock:
            self.metrics['valuation_skips'][kind] = \
                self.metrics['valuation_skips'].get(kind, 0) + 1
    
    def record_cache_hit(self, cache_type: str):
        """ìºì‹œ íˆíŠ¸ ê¸°ë¡"""
        with self.lock:
            self.metrics['cache_hits'].setdefault(cache_type, 0)
            self.metrics['cache_hits'][cache_type] += 1
    
    def record_cache_miss(self, cache_type: str):
        """ìºì‹œ ë¯¸ìŠ¤ ê¸°ë¡"""
        with self.lock:
            self.metrics['cache_misses'].setdefault(cache_type, 0)
            self.metrics['cache_misses'][cache_type] += 1
    
    def record_analysis_duration(self, duration: float):
        """ë¶„ì„ ì†Œìš” ì‹œê°„ ê¸°ë¡"""
        with self.lock:
            self.metrics['analysis_duration']['total'] += duration
            self.metrics['analysis_duration']['count'] += 1
            self.metrics['analysis_duration']['avg'] = (
                self.metrics['analysis_duration']['total'] / self.metrics['analysis_duration']['count']
            )
            # Record in histogram
            bucket_idx = self._find_bucket(duration, self.duration_buckets)
            self.analysis_histogram[bucket_idx] += 1
    
    def record_sector_evaluation(self, duration: float):
        """ì„¹í„° í‰ê°€ ì†Œìš” ì‹œê°„ ê¸°ë¡"""
        with self.lock:
            self.metrics['sector_evaluation']['total'] += duration
            self.metrics['sector_evaluation']['count'] += 1
            self.metrics['sector_evaluation']['avg'] = (
                self.metrics['sector_evaluation']['total'] / self.metrics['sector_evaluation']['count']
            )
            # Record in histogram
            bucket_idx = self._find_bucket(duration, self.duration_buckets)
            self.sector_histogram[bucket_idx] += 1
    
    def record_sector_sample_insufficient(self, sector_name: str = None):
        """ì„¹í„° í”¼ì–´ í‘œë³¸ ë¶€ì¡± ê¸°ë¡"""
        with self.lock:
            self.metrics['sector_sample_insufficient'] += 1
            if sector_name:
                if 'sector_sample_insufficient_by_sector' not in self.metrics:
                    self.metrics['sector_sample_insufficient_by_sector'] = {}
                self.metrics['sector_sample_insufficient_by_sector'][sector_name] = \
                    self.metrics['sector_sample_insufficient_by_sector'].get(sector_name, 0) + 1
    
    def record_missing_financial_fields(self, count: int = 1):
        """âœ… missing ì¬ë¬´ í•„ë“œ ì¹´ìš´í„°: ë°ì´í„° í’ˆì§ˆ ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§"""
        with self.lock:
            self.metrics['missing_financial_fields'] += count
    
    def record_stocks_analyzed(self, count: int):
        """ë¶„ì„ëœ ì¢…ëª© ìˆ˜ ê¸°ë¡"""
        with self.lock:
            self.metrics['stocks_analyzed'] += count
    
    def get_cache_hit_rate(self, cache_type: str) -> float:
        """ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°"""
        with self.lock:
            hits = self.metrics['cache_hits'].get(cache_type, 0)
            misses = self.metrics['cache_misses'].get(cache_type, 0)
            total = hits + misses
            return (hits / total * 100.0) if total > 0 else 0.0
    
    def get_api_success_rate(self) -> float:
        """API ì„±ê³µë¥  ê³„ì‚°"""
        with self.lock:
            total = self.metrics['api_calls']['total']
            success = self.metrics['api_calls']['success']
            return (success / total * 100) if total > 0 else 0.0
    
    def _find_bucket(self, value: float, buckets: List[float]) -> int:
        """Find histogram bucket index for a value"""
        for i, bucket in enumerate(buckets):
            if value <= bucket:
                return i
        return len(buckets)  # Overflow bucket
    
    def get_percentiles(self, histogram: List[int], buckets: List[float], percentile: float) -> float:
        """Calculate percentile from histogram"""
        total = sum(histogram)
        if total == 0:
            return 0.0
        
        target = total * (percentile / 100.0)
        cumulative = 0
        
        for i, count in enumerate(histogram):
            cumulative += count
            if cumulative >= target:
                if i < len(buckets):
                    return buckets[i]
                else:
                    return buckets[-1] * 2  # Estimate for overflow
        return buckets[-1] * 2
    
    def get_summary(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìš”ì•½ ë°˜í™˜"""
        with self.lock:
            # SLO ê²½ê³  ì²´í¬
            p90 = self.get_percentiles(self.analysis_histogram, self.duration_buckets, 90)
            p95 = self.get_percentiles(self.analysis_histogram, self.duration_buckets, 95)
            if p90 > 5.0:
                logging.warning(f"[SLO] ë¶„ì„ p90 {p90:.1f}s > 5s")
            if p95 > 10.0:
                logging.warning(f"[SLO] ë¶„ì„ p95 {p95:.1f}s > 10s")
            
            # ìƒìœ„ ì¹´í…Œê³ ë¦¬ë³„ ì—ëŸ¬ ì§‘ê³„ (SRE ëŒ€ì‹œë³´ë“œìš©)
            errors_by_category = {}
            for error_type, count in self.metrics['errors_by_type'].items():
                category = ErrorType.get_category(error_type)
                errors_by_category[category] = errors_by_category.get(category, 0) + count
            
            return {
                'runtime_seconds': _monotonic() - self.metrics['start_time'],
                'stocks_analyzed': self.metrics['stocks_analyzed'],
                'api_calls': self.metrics['api_calls'].copy(),
                'api_success_rate': self.get_api_success_rate(),
                'cache_hit_rates': {
                    'price': self.get_cache_hit_rate('price'),
                    'financial': self.get_cache_hit_rate('financial'),
                    'sector': self.get_cache_hit_rate('sector')
                },
                'avg_analysis_duration': self.metrics['analysis_duration']['avg'],
                'avg_sector_evaluation': self.metrics['sector_evaluation']['avg'],
                'errors_by_type': self.metrics['errors_by_type'].copy(),
                'errors_by_category': errors_by_category,  # SRE ëŒ€ì‹œë³´ë“œìš© ìƒìœ„ ì¹´í…Œê³ ë¦¬
                'sector_sample_insufficient': self.metrics['sector_sample_insufficient'],
                'sector_sample_insufficient_by_sector': self.metrics.get('sector_sample_insufficient_by_sector', {}),
                'analysis_p50': self.get_percentiles(self.analysis_histogram, self.duration_buckets, 50),
                'analysis_p90': p90,
                'analysis_p95': p95,
                'sector_p50': self.get_percentiles(self.sector_histogram, self.duration_buckets, 50),
                'sector_p90': self.get_percentiles(self.sector_histogram, self.duration_buckets, 90),
                'sector_p95': self.get_percentiles(self.sector_histogram, self.duration_buckets, 95)
            }

# Safer price/52w checks
def _none_if_missing_strict(x):
    """Return None if value is truly missing, keep 0.0 if provider returns it"""
    v = DataValidator.safe_float_optional(x)
    return v  # keep 0.0 if provider truly returns it

# Safe formatter for consistent number display
def fmt(x, suffix='', nd=1):
    """Centralized number formatter that handles None/NaN consistently"""
    try:
        if x is None or not math.isfinite(float(x)):
            return "N/A"
        return f"{float(x):.{nd}f}{suffix}"
    except Exception:
        return "N/A"

def fmt_pct(x, nd=1):
    """Percentage formatter that avoids N/A%"""
    v = DataValidator.safe_float_optional(x)
    return f"{v:.{nd}f}%" if v is not None else "N/A"


# API ì¬ì‹œë„ ìœ í‹¸ (ë°±ì˜¤í”„+ì§€í„°) - expanded transient error handling
try:
    from requests.exceptions import Timeout as ReqTimeout, ReadTimeout, ConnectTimeout, ConnectionError as ReqConnErr, HTTPError
except ImportError:
    class ReqTimeout(Exception): ...
    class ReadTimeout(Exception): ...
    class ConnectTimeout(Exception): ...
    class ReqConnErr(Exception): ...
    class HTTPError(Exception): ...

import socket

def _classify_http_error(e: Exception) -> Tuple[bool, str, Optional[int]]:
    """HTTPErrorë¥¼ ì¬ì‹œë„ ì—¬ë¶€/ì—ëŸ¬íƒ€ì…/ìƒíƒœì½”ë“œë¡œ ë¶„ë¥˜"""
    status = None
    if isinstance(e, HTTPError) and getattr(e, "response", None) is not None:
        try:
            status = e.response.status_code
        except Exception:
            status = None
    # 429: ë ˆì´íŠ¸ë¦¬ë°‹ â†’ ì¬ì‹œë„
    if status == 429:
        return True, ErrorType.API_RATE_LIMIT, status
    # ê²Œì´íŠ¸ì›¨ì´/ì„œë²„ ê³„ì—´ â†’ ì¬ì‹œë„
    if status in (500, 502, 503, 504):
        return True, ErrorType.HTTP_5XX, status
    # ë‚˜ë¨¸ì§€ 4xxëŠ” í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ â†’ ì¬ì‹œë„ ê¸ˆì§€
    if status is not None and 400 <= status < 500:
        return False, ErrorType.HTTP_4XX, status
    # ìƒíƒœì½”ë“œ ë¶ˆëª…: ì¬ì‹œë„ ë¹„ê²°ì • â†’ ì¼ë°˜ ë„¤íŠ¸ì›Œí¬ ë¶„ë¥˜ì— ìœ„ì„
    # ë¡œê¹…ì— ìƒíƒœì½”ë“œê°€ ì—†ë‹¤ëŠ” ì ì„ ëª…í™•íˆ ë‚¨ê¸°ë©´ ìš´ì˜ ë¶„ì„ì´ í¸í•¨
    if status is None:
        logging.debug(f"[retry] HTTPError with status=None, treating as UNKNOWN for retry decision")
    return True, ErrorType.UNKNOWN, status

TRANSIENT_ERRORS = (TimeoutError, ReqTimeout, ReadTimeout, ConnectTimeout, ReqConnErr, socket.timeout, HTTPError)
def _with_retries(call, tries=5, base=0.5, jitter=0.3, retry_on=TRANSIENT_ERRORS, max_total_sleep=15.0, metrics_attempt=None, metrics_final=None):
    """API í˜¸ì¶œ ì¬ì‹œë„ ë˜í¼ (ì„ ë³„ì  ì¬ì‹œë„ + ì´ ì†Œìš” ìƒí•œ)"""
    slept = 0.0
    for i in range(tries):
        try:
            result = call()
            # ì„±ê³µ ì‹œì—ëŠ” ìµœì¢… ê²°ê³¼ë§Œ ê¸°ë¡ (ì´ì¤‘ ì§‘ê³„ ë°©ì§€)
            if metrics_final:
                try:
                    metrics_final(success=True, error_type=None)
                except Exception:
                    pass
            return result
        except Exception as e:
            # HTTP ì˜¤ë¥˜ ì •êµ ë¶„ë¥˜
            et = ErrorType.UNKNOWN
            if isinstance(e, (ReqTimeout, ReadTimeout, ConnectTimeout, TimeoutError, socket.timeout)):
                et = ErrorType.API_TIMEOUT
            elif isinstance(e, ReqConnErr):
                et = ErrorType.API_CONNECTION
            elif isinstance(e, HTTPError):
                should_retry, et_http, status = _classify_http_error(e)
                et = et_http
                if not should_retry:
                    # HTTP 4xx ë“± ì¬ì‹œë„ ê¸ˆì§€ ì˜¤ë¥˜ëŠ” ì¦‰ì‹œ final ê¸°ë¡ í›„ ì¢…ë£Œ
                    if metrics_final:
                        try: metrics_final(success=False, error_type=et)
                        except Exception: pass
                    raise  # â† ì—¬ê¸°ì„œ ë°”ë¡œ íƒˆì¶œí•˜ë¯€ë¡œ retry_on ê²½ë¡œì™€ ê²©ë¦¬ë¨
                # HTTP 5xx/429 ë“± ì¬ì‹œë„ ê°€ëŠ¥í•œ ì˜¤ë¥˜ëŠ” ì•„ë˜ retry_on ê²½ë¡œë¡œ ê³„ì†
            
            # ì‹¤íŒ¨í–ˆìœ¼ë‚˜ ì¬ì‹œë„í•  ê²½ìš°ì—ë§Œ attempt ê¸°ë¡ (HTTP 4xxëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)
            if i < tries - 1 and isinstance(e, retry_on):
                if metrics_attempt:
                    try:
                        metrics_attempt(error_type=et)  # â† record_api_attempt_errorë§Œ í˜¸ì¶œ
                    except Exception:
                        pass
            else:
                # ìµœì¢… ì‹¤íŒ¨ëŠ” finalë§Œ ê¸°ë¡ (attempt ë¯¸ê¸°ë¡ ë³´ì¥)
                if metrics_final:
                    try:
                        metrics_final(success=False, error_type=et)
                    except Exception:
                        pass
                raise

            backoff = base * (2 ** i) + random.uniform(0, jitter)
            if slept + backoff > max_total_sleep:
                backoff = max(0.0, max_total_sleep - slept)
            if backoff > 0:
                time.sleep(backoff)
                slept += backoff
from concurrent.futures import ThreadPoolExecutor, as_completed

# ë¡œê¹… ì„¤ì •ì€ ë©”ì¸ ì‹¤í–‰ë¶€ì—ì„œ ì´ˆê¸°í™”
# rich import ì œê±° (ë¯¸ì‚¬ìš©)
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
# from enum import Enum  # enum.Enumìœ¼ë¡œ ì§ì ‘ ì‚¬ìš©

# ê¸°ì¡´ importë“¤ (ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨)
try:
    from kis_data_provider import KISDataProvider
    from enhanced_price_provider import EnhancedPriceProvider
    from investment_opinion_analyzer import InvestmentOpinionAnalyzer
    from estimate_performance_analyzer import EstimatePerformanceAnalyzer
    from financial_ratio_analyzer import FinancialRatioAnalyzer
    from profit_ratio_analyzer import ProfitRatioAnalyzer
    from stability_ratio_analyzer import StabilityRatioAnalyzer
    from test_integrated_analysis import create_integrated_analysis
except ImportError as e:
    logging.error(f"âŒ í•„ìˆ˜ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    if safe_env_bool("ENABLE_FAKE_PROVIDERS", False):
        logging.warning("ENABLE_FAKE_PROVIDERS=true â†’ ë”ë¯¸ êµ¬í˜„ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
        class KISDataProvider:
            def __init__(self, *args, **kwargs): 
                pass
            def get_stock_price_info(self, symbol):
                # 52ì£¼ ê³ ì €/ê±°ë˜ëŸ‰ í¬í•¨ â†’ ê°€ê²©ìœ„ì¹˜ ê³„ì‚° ë° UI ë¼ë²¨ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
                return {
                    'current_price': 80000.0,
                    'w52_high': 90000.0,
                    'w52_low': 60000.0,
                    'volume': 1234567,
                    'per': 15.0, 'pbr': 1.2, 'eps': 1000.0, 'bps': 8000.0
                }
            def get_financial_ratios(self, symbol): 
                return [{'roe': 12.5, 'roa': 8.0, 'debt_ratio': 30.0}]
            def get_profit_ratios(self, symbol): 
                return [{'gross_margin': 25.0, 'operating_margin': 15.0, 'net_margin': 10.0}]
            def get_stability_ratios(self, symbol): 
                return [{'current_ratio': 1.5, 'quick_ratio': 1.2, 'debt_to_equity': 0.4}]
        
        class EnhancedPriceProvider:
            def __init__(self, *args, **kwargs):
                pass
            def get_comprehensive_price_data(self, symbol):
                # current_price/52ì£¼ ê³ ì €/ì‹œì´ í¬í•¨ â†’ end-to-end ê²½ë¡œ ë™ì‘
                return {
                    'current_price': 80000.0,
                    'w52_high': 90000.0,
                    'w52_low': 60000.0,
                    'volume': 1234567,
                    'eps': 1000.0, 'bps': 8000.0,
                    'market_cap': 500_000_000_000  # ì› ë‹¨ìœ„(â†’ ë‚´ë¶€ì—ì„œ ì–µì› ë³€í™˜)
                }
        
        class InvestmentOpinionAnalyzer:
            def analyze_single_stock(self, symbol, days_back=30): 
                return {'buy': 5, 'hold': 3, 'sell': 1, 'target_price': 50000}
        
        class EstimatePerformanceAnalyzer:
            def analyze_single_stock(self, symbol): 
                return {'accuracy': 0.75, 'bias': 0.05, 'revision_trend': 'up'}
        
        class FinancialRatioAnalyzer:
            def __init__(self, *args, **kwargs):
                pass
            def get_financial_ratios(self, symbol):
                return [{'roe': 12.5, 'roa': 8.0, 'debt_ratio': 30.0}]
        
        class ProfitRatioAnalyzer:
            def __init__(self, *args, **kwargs):
                pass
            def get_profit_ratios(self, symbol):
                return [{'gross_margin': 25.0, 'operating_margin': 15.0, 'net_margin': 10.0}]
        
        class StabilityRatioAnalyzer:
            def __init__(self, *args, **kwargs):
                pass
            def get_stability_ratios(self, symbol):
                return [{'current_ratio': 1.5, 'quick_ratio': 1.2, 'debt_to_equity': 0.4}]
        
        def create_integrated_analysis(opinion, estimate): 
            return {'score': 75.0, 'recommendation': 'BUY', 'confidence': 0.8}
    else:
        logging.error("ğŸ’¡ í•´ê²°: ëª¨ë“ˆ ê²½ë¡œ/ì„¤ì¹˜ í™•ì¸ ë˜ëŠ” ENABLE_FAKE_PROVIDERS=true")
        raise

# =============================================================================
# 1. ë°ì´í„° í´ë˜ìŠ¤ ë° ì—´ê±°í˜•
# =============================================================================

class AnalysisStatus(enum.Enum):
    """ë¶„ì„ ìƒíƒœ ì—´ê±°í˜•"""
    SUCCESS = "success"
    ERROR = "error"
    SKIPPED_PREF = "skipped_pref"
    NO_DATA = "no_data"


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    symbol: str
    name: str
    status: AnalysisStatus
    enhanced_score: float = 0.0
    enhanced_grade: str = 'F'
    market_cap: Optional[float] = None
    current_price: float = 0.0
    price_position: Optional[float] = None
    price_band_outside: bool = False  # 52ì£¼ ë°´ë“œ ë°– ì—¬ë¶€ í”Œë˜ê·¸
    risk_score: Optional[float] = None
    financial_data: FinancialData = field(default_factory=dict)
    opinion_analysis: Dict[str, Any] = field(default_factory=dict)
    estimate_analysis: Dict[str, Any] = field(default_factory=dict)
    integrated_analysis: Dict[str, Any] = field(default_factory=dict)
    risk_analysis: Dict[str, Any] = field(default_factory=dict)
    score_breakdown: Dict[str, float] = field(default_factory=dict)
    raw_breakdown: Dict[str, float] = field(default_factory=dict)  # ì›ì ìˆ˜ breakdown
    error: Optional[str] = None
    price_data: PriceData = field(default_factory=dict)  # ê°€ê²© ë°ì´í„° ìºì‹±ìš©
    sector_analysis: Dict[str, Any] = field(default_factory=dict)  # ì„¹í„° ë¶„ì„ ê²°ê³¼
    # ê°€ì¹˜íˆ¬ì í™•ì¥ í•„ë“œ
    intrinsic_value: Optional[float] = None           # ë‚´ì¬ê°€ì¹˜(ì›)
    margin_of_safety: Optional[float] = None          # ì•ˆì „ë§ˆì§„(0~1)
    moat_grade: Optional[str] = None                  # 'Wide'/'Narrow'/'None' ë“±
    watchlist_signal: Optional[str] = None            # 'BUY'/'WATCH'/'PASS'
    target_buy: Optional[float] = None                # ëª©í‘œë§¤ìˆ˜ê°€
    playbook: List[str] = field(default_factory=list) # ê°€ì¹˜íˆ¬ì í”Œë ˆì´ë¶
    
    def to_dict(self) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        pdict = self.price_data or {}
        
        # ëŒ€ì‹œë³´ë“œìš© ìš”ì•½ í•„ë“œ ìƒì„±
        sector_summary = ""
        if self.sector_analysis and self.sector_analysis.get('total_score') is not None:
            score = self.sector_analysis.get('total_score', 0)
            grade = self.sector_analysis.get('grade', 'N/A')
            sector_summary = f"{grade}({score:.1f})"

        d = {
            "symbol": self.symbol,
            "name": self.name,
            "status": self.status.value if hasattr(self.status, 'value') else str(self.status),
            "error": self.error,
            "enhanced_score": self.enhanced_score,
            "enhanced_grade": self.enhanced_grade,
            "market_cap": self.market_cap,
            "current_price": pdict.get("current_price"),
            "price_position": self.price_position,
            "w52_high": pdict.get("w52_high"),
            "w52_low": pdict.get("w52_low"),
            "per": pdict.get("per"),
            "pbr": pdict.get("pbr"),
            "score_breakdown": self.score_breakdown,
            "raw_breakdown": self.raw_breakdown,
            "financial_data": self.financial_data,
            "sector_analysis": self.sector_analysis,
            "sector_valuation": sector_summary,
            "opinion_summary": self.opinion_analysis.get('summary', '') if self.opinion_analysis else '',
            "estimate_summary": self.estimate_analysis.get('summary', '') if self.estimate_analysis else '',
            # ê°€ì¹˜íˆ¬ì ê²°ê³¼
            "intrinsic_value": self.intrinsic_value,
            "margin_of_safety": self.margin_of_safety,
            "moat_grade": self.moat_grade,
            "watchlist_signal": self.watchlist_signal,
            "target_buy": self.target_buy,
            "playbook": self.playbook,
        }
        return serialize_for_json(d)
    

@dataclass(frozen=True)
class AnalysisConfig:
    """ë¶„ì„ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤ (ë¶ˆë³€)"""
    weights: Dict[str, float]
    financial_ratio_weights: Dict[str, float]
    estimate_analysis_weights: Dict[str, float]
    grade_thresholds: Dict[str, float]
    growth_score_thresholds: Dict[str, float]
    scale_score_thresholds: Dict[str, float]

# =============================================================================
# 2. ì¶”ìƒ í´ë˜ìŠ¤ ë° ì¸í„°í˜ì´ìŠ¤
# =============================================================================

class DataProvider(ABC):
    """ë°ì´í„° ì œê³µì ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def get_financial_data(self, symbol: str) -> Dict[str, Any]:
        """ì¬ë¬´ ë°ì´í„° ì¡°íšŒ"""
        pass
    
    @abstractmethod
    def get_price_data(self, symbol: str) -> Dict[str, Any]:
        """ê°€ê²© ë°ì´í„° ì¡°íšŒ"""
        pass

class ScoreCalculator(ABC):
    """ì ìˆ˜ ê³„ì‚°ê¸° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def calculate_score(self, data: Dict[str, Any], **kwargs) -> Tuple[float, Dict[str, float]]:
        """ì ìˆ˜ ê³„ì‚°"""
        pass

# =============================================================================
# 3. ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ë“¤
# =============================================================================

class TPSRateLimiter:
    """KIS OpenAPI TPS ì œí•œì„ ê³ ë ¤í•œ ë ˆì´íŠ¸ë¦¬ë¯¸í„° (FIFO ëŒ€ê¸°ì—´ + ê³µí‰í•œ ì›¨ì´í¬ì—…)"""
    
    def __init__(self, max_tps: int = None):
        # ê°œì„ ëœ ëª¨ë“ˆì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        if IMPROVED_MODULES_AVAILABLE:
            self._impl = get_default_rate_limiter()
            return
        
        # ê¸°ì¡´ êµ¬í˜„ (í•˜ìœ„ í˜¸í™˜ì„±)
        self.max_tps = max_tps or safe_env_int("KIS_MAX_TPS", 8, 1)
        self.ts = deque()                # ìµœê·¼ 1s ë°œê¸‰ íƒ€ì„ìŠ¤íƒ¬í”„
        self.cv = Condition()
        self.waiters = deque()           # FIFO ëŒ€ê¸°ì—´: (id, Condition)
        # ì§€í„° ìƒí•œì„ í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì • ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
        self.jitter_max = safe_env_float("RATE_LIMITER_JITTER_MAX", 0.004, 0.0)
        # âœ… notify_all ê¸°ë³¸ê°’ Falseë¡œ ë³€ê²½ (êµ°ì§‘ ì›¨ì´í¬ ë°©ì§€)
        self.notify_all = safe_env_bool("RATE_LIMITER_NOTIFY_ALL", False)
        # âœ… ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ ì˜µì…˜ (ê½‰ ë§‰í˜ ë°©ì§€)
        self.default_timeout = safe_env_float("RATE_LIMITER_DEFAULT_TIMEOUT", 2.0, 0.1)
        # âœ… ë°€ë¦¬ì´ˆ â†’ ì´ˆ ë³€í™˜ (ê¸°ì¡´ ë²„ê·¸: msë¥¼ ì´ˆë¡œ ì˜¤í•´)
        # RATE_LIMITER_MIN_SLEEP_MS: ë°€ë¦¬ì´ˆ ë‹¨ìœ„ (ê¸°ë³¸ê°’: 2.0ms, ìµœì†Œê°’: 1.0ms)
        self.min_sleep_seconds = safe_env_ms_to_seconds("RATE_LIMITER_MIN_SLEEP_MS", 2.0, 1.0)
    
    def acquire(self, timeout: float = None):
        """ìš”ì²­ í—ˆê°€ë¥¼ ë°›ìŠµë‹ˆë‹¤ (FIFO ëŒ€ê¸°ì—´ + ê³µí‰í•œ ì›¨ì´í¬ì—…)."""
        # ê°œì„ ëœ ëª¨ë“ˆì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ìœ„ì„
        if IMPROVED_MODULES_AVAILABLE:
            return self._impl.acquire(timeout)
        
        # ê¸°ì¡´ êµ¬í˜„ (í•˜ìœ„ í˜¸í™˜ì„±)
        timeout = self.default_timeout if timeout is None else timeout
        start = _monotonic()
        my_id = object()  # unique token
        
        with self.cv:
            self.waiters.append(my_id)
            
            while True:
                now = _monotonic()
                # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì •ë¦¬(í•­ìƒ ìˆ˜í–‰)
                one_sec_ago = now - 1.0
                while self.ts and self.ts[0] < one_sec_ago:
                    self.ts.popleft()

                is_my_turn = self.waiters and self.waiters[0] is my_id
                if is_my_turn and len(self.ts) < self.max_tps:
                    self.ts.append(now)
                    self.waiters.popleft()
                    # wake exactly one next waiter
                    self.cv.notify()
                    return

                waited = now - start
                if timeout is not None and waited >= timeout:
                    # cancel my spot if still queued
                    try:
                        self.waiters.remove(my_id)
                    except ValueError:
                        pass
                    logging.warning(f"[ratelimiter] acquire timeout (max_tps={self.max_tps})")
                    raise TimeoutError(f"Rate limiter acquire() timed out after {timeout:.1f}s (max_tps={self.max_tps}, in_window={len(self.ts)})")

                earliest = self.ts[0] if self.ts else now
                wait_for = max(0.0, (earliest + 1.0) - now)
                sleep_for = max(wait_for + random.uniform(0.0, self.jitter_max), self.min_sleep_seconds)
                if waited > 1.0:
                    logging.debug(f"[ratelimiter] waited={waited:.3f}s, in_window={len(self.ts)}, next={sleep_for:.3f}s")
                self.cv.wait(sleep_for)
    

class ConfigManager:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_file: str = "config.yaml"):
        self.config_file = config_file
        self._config_cache = None
        self._last_modified = 0
        default_config = self._get_default_config()['enhanced_integrated_analysis']
        self.weights = default_config['weights']
        self.financial_ratio_weights = default_config['financial_ratio_weights']
        self.grade_thresholds = default_config['grade_thresholds']
        self.scale_score_thresholds = default_config['scale_score_thresholds']
    
    def load_config(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
            current_modified = os.path.getmtime(self.config_file)
            if self._config_cache and current_modified <= self._last_modified:
                return self._config_cache
            
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            self._config_cache = config
            self._last_modified = current_modified
            return config
            
        except Exception as e:
            logging.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            'enhanced_integrated_analysis': {
                'weights': {
                    # BUY ì¢…ëª© ì¤‘ì‹¬ ê°€ì¤‘ì¹˜: ê°€ì¹˜íˆ¬ì/ê°€ê²©ìœ„ì¹˜ ë¹„ì¤‘ ëŒ€í­ ì¦ê°€
                    'opinion_analysis': 3,        # 5 â†’ 3 (-2) - ì˜ˆì¸¡ ìš”ì†Œ ê°ì†Œ
                    'estimate_analysis': 3,       # 5 â†’ 3 (-2) - ì˜ˆì¸¡ ìš”ì†Œ ê°ì†Œ
                    'financial_ratios': 20,       # 20 â†’ 20 (ìœ ì§€) - ì¬ë¬´ê±´ì „ì„± ìœ ì§€
                    'growth_analysis': 8,         # 12 â†’ 8 (-4) - ì„±ì¥ì„± ë¹„ì¤‘ ê°ì†Œ
                    'scale_analysis': 4,          # 5 â†’ 4 (-1) - ê·œëª¨ ë¹„ì¤‘ ê°ì†Œ
                    'price_position': 30,         # 28 â†’ 30 (+2) - ê°€ê²©ìœ„ì¹˜ ë¹„ì¤‘ ì¦ê°€
                    'value_investing': 40         # 25 â†’ 40 (+15) - ê°€ì¹˜íˆ¬ì ë¹„ì¤‘ ëŒ€í­ ì¦ê°€
                },
                'financial_ratio_weights': {
                    'roe_score': 7,              # 8 â†’ 7 (-1) - ì˜ì—…ì´ìµ ì¤‘ì‹¬ìœ¼ë¡œ ê°ì†Œ
                    'roa_score': 5,
                    'debt_ratio_score': 6,       # 7 â†’ 6 (-1) - ì˜ì—…ì´ìµ ì¤‘ì‹¬ìœ¼ë¡œ ê°ì†Œ
                    'net_profit_margin_score': 8,    # 7 â†’ 8 (+1) - ì˜ì—…ì´ìµ ì¤‘ì‹¬ìœ¼ë¡œ ì¦ê°€
                    'current_ratio_score': 3,
                    'growth_score': 6,                # 5 â†’ 6 (+1) - ì˜ì—…ì´ìµ ì¤‘ì‹¬ìœ¼ë¡œ ì¦ê°€
                    'profitability_consistency_score': 8  # 5 â†’ 8 (+3) - ì˜ì—…ì´ìµ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€í­ ì¦ê°€
                },
                'estimate_analysis_weights': {
                    'financial_health': 15,
                    'valuation': 15
                },
                'grade_thresholds': {
                    'A_plus': 80,
                    'A': 70,
                    'B_plus': 60,
                    'B': 50,
                    'C_plus': 40,
                    'C': 30,
                    'D_plus': 20,
                    'D': 10,
                    'F': 0
                },
                'growth_score_thresholds': {
                    'excellent': 20,
                    'good': 10,
                    'average': 0,
                    'poor': -10
                },
                'scale_score_thresholds': {
                    'mega_cap': 100000,
                    'large_cap': 50000,
                    'mid_large_cap': 10000,
                    'mid_cap': 5000,
                    'small_cap': 1000
                }
            }
        }

class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""
    
    @staticmethod
    def _finite(val: Any, default: float = 0.0) -> float:
        """NaN/Inf í´ë¦°ì—… ìœ í‹¸"""
        try:
            x = float(val)
            if math.isfinite(x):
                return x
        except Exception:
            pass
        return default
    
    @staticmethod
    def safe_divide(numerator: Any, denominator: Any, default: float = None, allow_negative_den: bool = False) -> Optional[float]:
        """ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ - NaN/Inf ë°©ì§€.
        Note: ë¶„ëª¨<=0 ì¸ ê²½ìš° default ë°˜í™˜ (PER/PBRì²˜ëŸ¼ ìŒìˆ˜/0ê°’ì´ ë¬´ì˜ë¯¸í•œ ì§€í‘œì— ë§ì¶¤)."""
        try:
            num = DataValidator._finite(numerator)
            den = DataValidator._finite(denominator)
            
            # ë¶„ëª¨ê°€ 0ì´ê±°ë‚˜ (ìŒìˆ˜ í—ˆìš©í•˜ì§€ ì•Šìœ¼ë©´) ìŒìˆ˜ë©´ default ë°˜í™˜
            if den == 0 or (den < 0 and not allow_negative_den):
                return default
            
            result = num / den
            if math.isfinite(result):
                return result
            else:
                return default
        except Exception:
            return default
    
    @staticmethod
    def safe_float(value: Any, default: float = 0.0) -> float:
        """ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜ (ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ì§€ì›)"""
        try:
            if value is None or pd.isna(value):
                return default
            if isinstance(value, str):
                v = value.strip().replace(',', '')
                if v == '':
                    return default
                return float(v)
            return float(value)
        except (ValueError, TypeError):
            return default
    
    @staticmethod
    def safe_float_optional(value: Any) -> Optional[float]:
        """ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜í•˜ë˜ ê²°ì¸¡ì¹˜ëŠ” Noneìœ¼ë¡œ ë³´ì¡´ (ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ì§€ì›)"""
        try:
            if value is None or pd.isna(value):
                return None
            if isinstance(value, float):
                return value if math.isfinite(value) else None
            if isinstance(value, str):
                v = value.strip().replace(',', '')
                if v == '':
                    return None
                x = float(v)
                return x if math.isfinite(x) else None
            x = float(value)
            return x if math.isfinite(x) else None
        except (ValueError, TypeError):
            return None
    
    @staticmethod
    def is_valid_symbol(symbol: str) -> bool:
        """ì¢…ëª© ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬"""
        if not symbol or not isinstance(symbol, str):
            return False
        import re
        return bool(re.match(r'^\d{6}$', symbol.strip()))
    
    @staticmethod
    def is_preferred_stock(name: str) -> bool:
        """ìš°ì„ ì£¼ ì—¬ë¶€ í™•ì¸ (ê°•í™”ëœ ì •ê·œì‹)"""
        if not name or not isinstance(name, str):
            return False
        s = name.strip()
        
        # âœ… í™˜ê²½ë³€ìˆ˜ë¡œ "ìš°ë¦¬" ì‹œì‘ ì¢…ëª©ì„ ìš°ì„ ì£¼ë¡œ ê°„ì£¼í• ì§€ ì œì–´ (ê¸°ë³¸ê°’: False = ê°„ì£¼ ì•ˆí•¨)
        if safe_env_bool("PREFERRED_STOCK_INCLUDE_WOORI", False) and s.startswith("ìš°ë¦¬"):
            return True
            
        import re
        # KRX ìŠ¤íƒ€ì¼ ì ‘ë¯¸ì‚¬ì™€ ëª…ì‹œì  í‚¤ì›Œë“œ (ë„ì–´ì“°ê¸°/íŠ¹ìˆ˜ë¬¸ì ë³€í˜• í—ˆìš©)
        # ë” ì—„ê²©í•œ íŒ¨í„´: ê´„í˜¸ í‘œê¸°, ëª…ì‹œì  í‚¤ì›Œë“œ, ìš°ì„ ì£¼ ì ‘ë¯¸ì‚¬ë§Œ í—ˆìš©
        pat = re.compile(r"(?:\((?:ìš°|ìš°B|ìš°C)\)|\bìš°ì„ ì£¼\b|(?:\s|^)ìš°(?:B|C)?$)")
        return bool(pat.search(s))
    
    @staticmethod
    def _getattr_or_get(d, key, default=None):
        """ê°ì²´/ë”•ì…”ë„ˆë¦¬ ì•ˆì „ ì ‘ê·¼ ìœ í‹¸"""
        try:
            return getattr(d, key)
        except Exception:
            try:
                return d.get(key, default)
            except Exception:
                return default

# =============================================================================
# JSON ì§ë ¬í™” ìœ í‹¸ (NumPy/Datetime/Decimal ì•ˆì „)
# =============================================================================
def serialize_for_json(obj: Any) -> JSONValue:
    """
    Convert various Python/NumPy/Decimal/Datetime containers to JSON-serializable.
    - Handles: dict/list/tuple/set, numpy scalars/arrays, Decimal, datetime/date, objects with __dict__
    """
    from datetime import date, datetime

    if obj is None or isinstance(obj, (str, int, float, bool)):
        return obj
    if isinstance(obj, Decimal):
        return float(obj)
    if isinstance(obj, enum.Enum):
        return obj.value
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    if hasattr(obj, "tolist"):  # numpy arrays
        try:
            return obj.tolist()
        except Exception:
            pass
    # numpy scalar detection (more robust than module check)
    if isinstance(obj, (np.generic,)):
        try:
            return obj.item()
        except Exception:
            pass
    if isinstance(obj, dict):
        return {serialize_for_json(k): serialize_for_json(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple, set)):
        return [serialize_for_json(x) for x in obj]
    if hasattr(obj, "__dict__"):
        return {k: serialize_for_json(v) for k, v in obj.__dict__.items()}
    return str(obj)


class DataConverter:
    """ë°ì´í„° ë³€í™˜ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    # í¼ì„¼íŠ¸ì„± ì§€í‘œ í•„ë“œ ì •ì˜ (ì´ì¤‘ ìŠ¤ì¼€ì¼ë§ ë°©ì§€)
    PERCENT_FIELDS = {
        "roe", "roa", "revenue_growth_rate", "operating_income_growth_rate",
        "net_income_growth_rate", "net_profit_margin", "gross_profit_margin",
        "debt_ratio", "equity_ratio", "current_ratio"
    }
    
    
    @staticmethod
    def to_percent(x: Any) -> float:
        """í¼ì„¼íŠ¸ ë‹¨ìœ„ë¡œ ê°•ì œ ë³€í™˜ (ì´ì¤‘ ìŠ¤ì¼€ì¼ë§ ë°©ì§€, ë¶€í˜¸ ë³´ì¡´)"""
        v = DataValidator.safe_float(x, 0.0)
        # |v|<=5ë©´ ë¹„ìœ¨ë¡œ ë³´ê³  Ã—100, ë¶€í˜¸ ìœ ì§€
        return v * 100.0 if abs(v) <= 5.0 else v
    
    @staticmethod
    def normalize_percentage(value: Any, assume_ratio_if_abs_lt_1: bool = True) -> Optional[float]:
        """í¼ì„¼íŠ¸ ê°’ì„ ì •ê·œí™” (0.12 â†’ 12.0)"""
        try:
            v = float(value)
            if pd.isna(v):
                return None
            return v * 100.0 if assume_ratio_if_abs_lt_1 and -1.0 <= v <= 1.0 else v
        except Exception:
            return None
    
    @staticmethod
    def format_percentage(value: Any, decimal_places: int = 1) -> str:
        """í¼ì„¼íŠ¸ ê°’ í¬ë§·íŒ…"""
        try:
            if value is None or pd.isna(value):
                return "N/A"
            v = float(value)
            return f"{v:.{decimal_places}f}%"
        except Exception:
            return "N/A"
    
    @staticmethod
    def standardize_financial_units(data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì¬ë¬´ ë°ì´í„° ë‹¨ìœ„ í‘œì¤€í™” (í¼ì„¼íŠ¸ì„± ì§€í‘œ % ë‹¨ìœ„ í†µì¼)
        - ê²°ì¸¡ì¹˜ëŠ” Noneìœ¼ë¡œ ë³´ì¡´í•˜ì—¬ ì´í›„ ìŠ¤ì½”ì–´ëŸ¬ì—ì„œ 'ë¶€ë¶„ ê²°ì¸¡ ê°€ì¤‘ì¹˜ ì¬ì •ê·œí™”'ê°€ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        
        âš ï¸ ì¤‘ìš”: % ë‹¨ìœ„ëŠ” ì´ í•¨ìˆ˜ì—ì„œë§Œ ë³€í™˜ë©ë‹ˆë‹¤. ì´í›„ íŒŒì´í”„ë¼ì¸ì—ì„œ ê°™ì€ í•„ë“œì— ì¶”ê°€ ë³€í™˜ ê¸ˆì§€.
        
        # DO NOT convert % units again after this point.
        # Any additional scaling will create double-scaling bugs (e.g., 0.03 -> 3 -> 300).
        """
        # í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì •ì±…ì´ ë°”ë€Œì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì§„ì… ì‹œì ì— ìºì‹œë¥¼ ê°±ì‹ 
        try:
            _refresh_env_cache()
        except Exception:
            pass
        out = data.copy()

        # 1) í¼ì„¼íŠ¸ í•„ë“œëŠ” ë¹„ìœ¨í˜•(<=5) â†’ %ë¡œ ë³€í™˜, ê²°ì¸¡ì€ None ìœ ì§€
        for k in DataConverter.PERCENT_FIELDS:
            if k in out:
                v = out[k]
                if v is None or (isinstance(v, float) and (not math.isfinite(v))):
                    out[k] = None
                else:
                    # âœ… current_ratio í¼ì„¼íŠ¸ í•´ì„ ê³ ì •: ê³µê¸‰ì›ì´ í¼ì„¼íŠ¸/ë°°ìˆ˜ í˜¼ì¬ ê°€ëŠ¥ â†’ ë³´ìˆ˜ì  ê°€ë“œ
                    # 
                    # ì²˜ë¦¬ ê·œì¹™ í‘œ:
                    # | ê°’ ë²”ìœ„ | í•´ì„ | ë³€í™˜ | ë¹„ê³  |
                    # |---------|------|------|------|
                    # | 0â€“10    | ë°°ìˆ˜ | Ã—100 | ì¼ë°˜ì ì¸ ìœ ë™ë¹„ìœ¨ ë°°ìˆ˜ê°’ |
                    # | â‰¥50     | %    | ê·¸ëŒ€ë¡œ | ì¼ë°˜ì ì¸ í¼ì„¼íŠ¸ê°’ |
                    # | 10â€“50   | ëª¨ë“œë³„ | clamp/as_is | ì• ë§¤ êµ¬ê°„ (í™˜ê²½ë³€ìˆ˜ ì œì–´) |
                    # 
                    if k == "current_ratio":
                        vv = DataValidator.safe_float_optional(v)
                        if vv is None:
                            out[k] = None
                        else:
                            # í™˜ê²½ë³€ìˆ˜ ê°€ë“œ: ê°•ì œ % í•´ì„ ëª¨ë“œ (ìºì‹œëœ ê°’ ì‚¬ìš©)
                            force_percent = _ENV_CACHE['current_ratio_force_percent'].lower() == "true"
                            
                            if force_percent:
                                # ê°•ì œ % ëª¨ë“œ: 0~5ëŠ” ë°°ìˆ˜ë¡œ ë³´ê³  %ë¡œ ë³€í™˜, ë‚˜ë¨¸ì§€ëŠ” %ë¡œ ê°„ì£¼
                                out[k] = vv * 100.0 if 0.0 <= vv <= 5.0 else vv
                                logging.debug(f"[unit] current_ratio force percent mode: {v} -> {out[k]} (0-5 range check applied)")
                            elif 0.0 <= vv <= 10.0:
                                out[k] = vv * 100.0
                                logging.debug(f"[unit] current_ratio treated as multiple: {v} -> {vv*100}")
                            elif vv >= 50.0:
                                out[k] = vv
                                logging.debug(f"[unit] current_ratio assumed as percent: {v} -> {vv}")
                            else:
                                # 10~50 ì‚¬ì´ ì• ë§¤ êµ¬ê°„ ì²˜ë¦¬ ì „ëµ (ìºì‹œëœ ê°’ ì‚¬ìš©)
                                ambiguous_strategy = _ENV_CACHE['current_ratio_ambiguous_strategy'].lower()
                                if ambiguous_strategy == "clamp":
                                    # í´ë¨í”„ ëª¨ë“œ: í•©ë¦¬ì  ë²”ìœ„ë¡œ ì œí•œ [10, 300]
                                    clamped = max(10.0, min(300.0, vv))
                                    out[k] = clamped
                                    logging.debug(f"[unit] current_ratio ambiguous range (clamped): {v} -> {clamped} (treated as %)")
                                else:  # as_is
                                    # as_is ëª¨ë“œ: ì›ë³¸ ê°’ ìœ ì§€í•˜ë˜ ì•„ì›ƒë¼ì´ì–´ë§Œ í´ë¦½
                                    out[k] = vv
                                    # ì™„ì „í•œ as_isë¼ë„ ì´ìƒì¹˜ë§Œì€ í´ë¦½
                                    if not (10.0 <= out[k] <= 10000.0):
                                        out[k] = max(10.0, min(10000.0, out[k]))
                                        logging.debug(f"[unit] current_ratio outlier clipped in as_is mode: {vv} -> {out[k]}")
                    else:
                        out[k] = DataConverter.enforce_canonical_percent(v, field_name=k)
                    # í•„ë“œë³„ í´ë¨í”„ ìƒí•œ ë¶„ë¦¬ (ê·¹ë‹¨ê°’ ë°©ì§€)
                    if out[k] is not None:
                        if k in ["roe", "roa"]:
                            # ìˆ˜ìµì„± ì§€í‘œ: 5,000% ìƒí•œ
                            if abs(out[k]) > 5000.0:
                                out[k] = math.copysign(5000.0, out[k])
                        elif k in ["revenue_growth_rate", "operating_income_growth_rate", "net_income_growth_rate"]:
                            # ì„±ì¥ë¥ : 1,000% ìƒí•œ
                            if abs(out[k]) > 1000.0:
                                out[k] = math.copysign(1000.0, out[k])
                        else:
                            # ê¸°íƒ€: 10,000% ìƒí•œ
                            if abs(out[k]) > 10000.0:
                                out[k] = math.copysign(10000.0, out[k])

        # 2) ë‚˜ë¨¸ì§€ ìŠ¤ì¹¼ë¼ë„ ê²°ì¸¡ì€ Noneìœ¼ë¡œ, ìˆ˜ì¹˜/ë¬¸ì ìˆ˜ì¹˜ë§Œ ì•ˆì „ ë³€í™˜
        for k, v in list(out.items()):
            if k in DataConverter.PERCENT_FIELDS:
                continue
            if isinstance(v, (int, float)):
                out[k] = v if math.isfinite(float(v)) else None
            elif isinstance(v, str):
                out[k] = DataValidator.safe_float_optional(v)  # ìˆ˜ì¹˜í˜• ë¬¸ìì—´ë§Œ float, ì•„ë‹ˆë©´ None
            elif v is None:
                out[k] = None
            # dict/list ë“± ë³µí•©í˜•ì€ ê·¸ëŒ€ë¡œ ë‘ (í•„ìš” ì‹œ ìƒìœ„ ë¡œì§ì—ì„œ ì²˜ë¦¬)

        # âœ… Percent canonicalization ë³´í˜¸ í”Œë˜ê·¸ ì„¤ì •
        out["_percent_canonicalized"] = True
        return out
    
    @staticmethod
    def as_percent_maybe_ratio(x: Any) -> float:
        """%/ë°°ìˆ˜ í˜¼ì¬ ì •ê·œí™” (0<ê°’â‰¤5 â†’ Ã—100 ê·œì¹™)
        
        NOTE: í˜„ ì‹œì ì—” ingestì—ì„œ ëª¨ë‘ %ë¡œ í‘œì¤€í™”ë˜ë‹ˆ ì¶”ê°€ ìŠ¤ì¼€ì¼ ê¸ˆì§€.
        standardize_financial_units()ì—ì„œ ëª¨ë“  í¼ì„¼íŠ¸ì„± ì§€í‘œë¥¼ %ë¡œ í†µì¼í•˜ë¯€ë¡œ
        ì´ í•¨ìˆ˜ëŠ” ë ˆê±°ì‹œ í˜¸í™˜ìš©ì´ë©°, ì¤‘ë³µ ìŠ¤ì¼€ì¼ ë°©ì§€ê°€ ì£¼ëª©ì ì…ë‹ˆë‹¤.
        """
        v = DataValidator.safe_float(x, 0.0)
        if v <= 0:
            return 0.0
        return v * 100.0 if v <= 5.0 else v
    
    @staticmethod
    def enforce_canonical_percent(x: Any, field_name: str = "unknown") -> Optional[float]:
        """Enforce canonical percentage units for consistent scoring
        
        Args:
            x: Input value (could be ratio or percentage)
            field_name: Field name for logging/debugging
            
        Returns:
            Value normalized to percentage (preserves sign), None if missing
        """
        # â† ì¶”ê°€: ê²°ì¸¡ ë³´ì¡´
        x_opt = DataValidator.safe_float_optional(x)
        if x_opt is None:
            return None
        v = float(x_opt)
        if not math.isfinite(v):
            return None
        # convert likely ratios to %
        if -5.0 <= v <= 5.0:
            v = v * 100.0
        # clamp extreme outliers but DO NOT kill sign
        if abs(v) > 10000.0:
            logging.debug(f"[percent-clamp] {field_name}={v} -> {math.copysign(10000.0, v)}")
            v = math.copysign(10000.0, v)
        return v

# =============================================================================
# 4. í•µì‹¬ ë¶„ì„ í´ë˜ìŠ¤ë“¤
# =============================================================================

class FinancialDataProvider(DataProvider):
    """ì¬ë¬´ ë°ì´í„° ì œê³µì"""
    
    def __init__(self, provider: KISDataProvider, rate_limiter: TPSRateLimiter, ttl: float = None, metrics: MetricsCollector = None):
        self.provider = provider
        self.price_provider = EnhancedPriceProvider()
        self.rate_limiter = rate_limiter
        self.financial_ratio_analyzer = FinancialRatioAnalyzer(provider)
        self.profit_ratio_analyzer = ProfitRatioAnalyzer(provider)
        self.stability_ratio_analyzer = StabilityRatioAnalyzer(provider)
        self._cache_price: "OrderedDict[str, Tuple[float, Dict[str, Any]]]" = OrderedDict()
        self._cache_fin: "OrderedDict[str, Tuple[float, Dict[str, Any]]]" = OrderedDict()
        self._cache_lock = RLock()
        # TTL ë¶„ë¦¬: ê°€ê²© ë°ì´í„°ëŠ” ì§§ê²Œ, ì¬ë¬´ ë°ì´í„°ëŠ” ê¸¸ê²Œ
        self._ttl = {
            'price': safe_env_float("KIS_CACHE_TTL_PRICE", 5.0, 0.1),
            'financial': safe_env_float("KIS_CACHE_TTL_FINANCIAL", 900.0, 1.0),
        }
        self._max_keys = safe_env_int("KIS_CACHE_MAX_KEYS", 2000, 100)
        self.metrics = metrics
    
    
    def _get_cached(self, cache, key):
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (ë™ì‹œì„± ì•ˆì „, TTL ë¶„ë¦¬, ì••ì¶• í•´ì œ)"""
        now = _monotonic()
        with self._cache_lock:
            hit = cache.get(key)
            cache_type = 'price' if cache is self._cache_price else 'financial'
            if hit and not (isinstance(hit, tuple) and len(hit) >= 2):
                logging.debug("cache entry shape invalid; dropping")
                if self.metrics:
                    self.metrics.record_cache_miss(cache_type)
                return None
            if hit:
                # TTL override ì§€ì› (ë¹ˆ ë°ì´í„°ìš©)
                ttl = hit[2] if len(hit) > 2 and hit[2] is not None else self._ttl[cache_type]
                if now - hit[0] < ttl:
                    cache.move_to_end(key)  # LRU ìµœê·¼ì„± ì—…ë°ì´íŠ¸
                    if self.metrics:
                        self.metrics.record_cache_hit(cache_type)
                    
                    # ì••ì¶•ëœ ë°ì´í„° í•´ì œ
                    if len(hit) > 3 and hit[3]:  # ì••ì¶• í”Œë˜ê·¸ í™•ì¸
                        import json
                        import gzip
                        try:
                            decompressed = json.loads(gzip.decompress(hit[1]).decode("utf-8"))
                            return decompressed
                        except (OSError, json.JSONDecodeError, UnicodeDecodeError):
                            # ì••ì¶• í•´ì œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
                            return hit[1]
                    else:
                        return hit[1]
        
        if self.metrics:
            self.metrics.record_cache_miss(cache_type)
        return None

    def _set_cached(self, cache, key, value, ttl_override=None):
        """ìºì‹œì— ë°ì´í„° ì €ì¥ (ë™ì‹œì„± ì•ˆì „, LRU í•œë„ ì ìš©, ë©”ëª¨ë¦¬ ìµœì í™”)"""
        with self._cache_lock:
            # ë¹ˆ ë°ì´í„°ëŠ” ì§§ì€ TTL ì ìš©
            if ttl_override is None and isinstance(value, dict) and not value:
                ttl_override = min(1.0, self._ttl['price'] * 0.2)  # 20% of normal TTL
            
            # ë©”ëª¨ë¦¬ ìµœì í™”: í° ë°ì´í„° ì••ì¶• (json ì§ë ¬í™” ê¸¸ì´ë¡œ íŒë‹¨)
            if isinstance(value, dict):
                import json, gzip
                payload = json.dumps(value, default=str).encode()
                if len(payload) > 8 * 1024:  # 8KB threshold for compression
                    try:
                        compressed = gzip.compress(payload)
                        cache[key] = (_monotonic(), compressed, ttl_override, True)
                        cache.move_to_end(key)
                        while len(cache) > self._max_keys:
                            cache.popitem(last=False)
                        return
                    except Exception:
                        pass
            cache[key] = (_monotonic(), value, ttl_override, False)
            cache.move_to_end(key)
            while len(cache) > self._max_keys:
                cache.popitem(last=False)  # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
    
    def get_financial_data(self, symbol: str) -> Dict[str, Any]:
        """ì¬ë¬´ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (TTL ìºì‹œ ì ìš©)."""
        # ìºì‹œ í™•ì¸
        hit = self._get_cached(self._cache_fin, symbol)
        if hit is not None:
            return hit
        
        financial_data = {}
        
        # ì¬ë¬´ë¹„ìœ¨ ë¶„ì„ (ì¬ì‹œë„ ì ìš©)
        try:
            # rate_limiter ì˜ˆì™¸ë§Œ ë°”ê¹¥ì—ì„œ ì§‘ê³„
            try:
                self.rate_limiter.acquire()
            except TimeoutError as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.API_TIMEOUT)
                raise
            
            # ì‹¤ì œ APIëŠ” _with_retriesê°€ ì§‘ê³„
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            financial_ratios = _with_retries(
                lambda: self.financial_ratio_analyzer.get_financial_ratios(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final
            )
            if financial_ratios and len(financial_ratios) > 0:
                latest_ratios = financial_ratios[0]
                financial_data.update({
                    'roe': DataValidator.safe_float_optional(latest_ratios.get('roe')),
                    'roa': DataValidator.safe_float_optional(latest_ratios.get('roa')),
                    'debt_ratio': DataValidator.safe_float_optional(latest_ratios.get('debt_ratio')),
                    'equity_ratio': DataValidator.safe_float_optional(latest_ratios.get('equity_ratio')),
                    'revenue_growth_rate': DataValidator.safe_float_optional(latest_ratios.get('revenue_growth_rate')),
                    'operating_income_growth_rate': DataValidator.safe_float_optional(latest_ratios.get('operating_income_growth_rate')),
                    'net_income_growth_rate': DataValidator.safe_float_optional(latest_ratios.get('net_income_growth_rate'))
                })
        except Exception as e:
            # _with_retriesê°€ ìµœì¢… ì‹¤íŒ¨ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìŒ. ì—¬ê¸°ì„  ë¡œê·¸ë§Œ.
            log_error("ì¬ë¬´ë¹„ìœ¨ ë¶„ì„", symbol, e)
        
        # ìˆ˜ìµì„±ë¹„ìœ¨ ë¶„ì„ (ì¬ì‹œë„ ì ìš©)
        try:
            # rate_limiter ì˜ˆì™¸ë§Œ ë°”ê¹¥ì—ì„œ ì§‘ê³„
            try:
                self.rate_limiter.acquire()
            except TimeoutError as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.API_TIMEOUT)
                raise
            
            # ì‹¤ì œ APIëŠ” _with_retriesê°€ ì§‘ê³„
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            profit_ratios = _with_retries(
                lambda: self.profit_ratio_analyzer.get_profit_ratios(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final
            )
            if profit_ratios and len(profit_ratios) > 0:
                latest_profit = profit_ratios[0]
                financial_data.update({
                    'net_profit_margin': DataValidator.safe_float_optional(latest_profit.get('net_profit_margin')),
                    'gross_profit_margin': DataValidator.safe_float_optional(latest_profit.get('gross_profit_margin')),
                    'profitability_grade': latest_profit.get('profitability_grade', 'í‰ê°€ë¶ˆê°€')
                })
        except Exception as e:
            # _with_retriesê°€ ìµœì¢… ì‹¤íŒ¨ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìŒ. ì—¬ê¸°ì„  ë¡œê·¸ë§Œ.
            log_error("ìˆ˜ìµì„±ë¹„ìœ¨ ë¶„ì„", symbol, e)
        
        # ì•ˆì •ì„±ë¹„ìœ¨ ë¶„ì„ (current_ratio í¬í•¨)
        try:
            # rate_limiter ì˜ˆì™¸ë§Œ ë°”ê¹¥ì—ì„œ ì§‘ê³„
            try:
                self.rate_limiter.acquire()
            except TimeoutError as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.API_TIMEOUT)
                raise
            
            # ì‹¤ì œ APIëŠ” _with_retriesê°€ ì§‘ê³„
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            stability = _with_retries(
                lambda: self.stability_ratio_analyzer.get_stability_ratios(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final
            )
            if stability and len(stability) > 0:
                latest_stab = stability[0]
                financial_data.update({
                    'current_ratio': DataValidator.safe_float_optional(latest_stab.get('current_ratio'))  # ì›ì‹œê°’ë§Œ ì €ì¥, ë‹¨ìœ„ í‘œì¤€í™”ëŠ” standardize_financial_unitsì—ì„œë§Œ
                })
        except Exception as e:
            # _with_retriesê°€ ìµœì¢… ì‹¤íŒ¨ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìŒ. ì—¬ê¸°ì„  ë¡œê·¸ë§Œ.
            log_error("ì•ˆì •ì„±ë¹„ìœ¨ ë¶„ì„", symbol, e)
        
        # ë‹¨ìœ„ í‘œì¤€í™” ì¼ê´„ ì ìš© (ìƒˆë¡œìš´ í‘œì¤€í™” í•¨ìˆ˜ ì‚¬ìš©)
        financial_data = DataConverter.standardize_financial_units(financial_data)
        # âœ… Percent canonicalization ë³´í˜¸ í”Œë˜ê·¸ ì„¤ì •
        financial_data["_percent_canonicalized"] = True
        
        # ê¸°ì¡´ í˜¼ì¬ ë‹¨ìœ„ ì •ê·œí™”ë„ ìœ ì§€ (í˜¸í™˜ì„±) - standardize_financial_units()ì—ì„œ í†µì¼ ì²˜ë¦¬
        # debt_ratio, equity_ratioëŠ” PERCENT_FIELDSì— í¬í•¨ë˜ì–´ ìë™ ì²˜ë¦¬ë¨

        # âš ï¸ FIX: ROE/ROAëŠ” ì´ë¯¸ standardize_financial_unitsì—ì„œ ìŠ¤ì¼€ì¼ í†µì¼ë¨.
        #       ì—¬ê¸°ì„œ ì¬ì°¨ 0<x<=5 ë°°ìœ¨ ë³´ì •ì„ í•˜ë©´ 0.03â†’3.0â†’300.0ì²˜ëŸ¼ ì´ì¤‘ ê³±ì…ˆ ë²„ê·¸ê°€ ë°œìƒ.
        #       ë”°ë¼ì„œ ì¶”ê°€ ë³´ì • ë£¨í”„ë¥¼ ì œê±°í•˜ì—¬ ì´ì¤‘ ìŠ¤ì¼€ì¼ë§ì„ ê·¼ë³¸ ì°¨ë‹¨.
        
        # PER/PBRëŠ” get_price_data()ì—ì„œ ë‹¨ì¼ ì†ŒìŠ¤ë¡œ ê³„ì‚°ë¨ (ì¤‘ë³µ ì œê±°)
        
        # ìºì‹œì— ì €ì¥
        self._set_cached(self._cache_fin, symbol, financial_data)
        return financial_data
    
    def get_price_data(self, symbol: str) -> Dict[str, Any]:
        """ê°€ê²© ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (TTL ìºì‹œ ì ìš©)."""
        # ìºì‹œ í™•ì¸
        hit = self._get_cached(self._cache_price, symbol)
        if hit is not None:
            return hit
            
        try:
            # Rate limiter ì ìš© (price_provider í˜¸ì¶œ ì „)
            try:
                self.rate_limiter.acquire()
            except TimeoutError as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.API_TIMEOUT)
                raise
            
            # í–¥ìƒëœ ê°€ê²© í”„ë¡œë°”ì´ë” ì‚¬ìš© (ë¦¬íŠ¸ë¼ì´ + ë©”íŠ¸ë¦­ ì½œë°±ìœ¼ë¡œ ì¼ì›í™”)
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            price_data = _with_retries(
                lambda: self.price_provider.get_comprehensive_price_data(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final  # ìµœì¢… ë©”íŠ¸ë¦­ ê¸°ë¡ ì¼ì›í™”
            )
            
            if price_data and price_data != {}:
                # ê²°ì¸¡ì¹˜ í‘œí˜„ ì¼ê´€ì„±: "ì—†ìœ¼ë©´ None"ë¡œ í†µì¼ (legitimate zero í—ˆìš©)
                def _local_none_if_missing(x):
                    """None for None/NaN; allow legitimate zero"""
                    return DataValidator.safe_float_optional(x)
                
                data = {
                    'current_price': _local_none_if_missing(price_data.get('current_price')),
                    'price_change': _local_none_if_missing(price_data.get('price_change')),
                    'price_change_rate': _local_none_if_missing(price_data.get('price_change_rate')),
                    'volume': int(round(v)) if (v := _local_none_if_missing(price_data.get('volume'))) is not None else None,
                    'eps': _local_none_if_missing(price_data.get('eps')),
                    'bps': _local_none_if_missing(price_data.get('bps')),
                    'market_cap': normalize_market_cap_ekwon(_local_none_if_missing(price_data.get('market_cap')))
                }
                
                # PER/PBR ê³„ì‚° (EPS/BPSê°€ ì–‘ìˆ˜ì¼ ë•Œë§Œ, 0ì› ì£¼ê°€ ë°©ì–´)
                cp = DataValidator.safe_float_optional(price_data.get('current_price'))
                eps = DataValidator.safe_float_optional(price_data.get('eps'))
                bps = DataValidator.safe_float_optional(price_data.get('bps'))
                
                # PER/PBR ê³„ì‚° ê°€ë“œ: í˜„ì‹¤ì  ë””í´íŠ¸(í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì ˆ ê°€ëŠ¥): ê·¹ì†Œ EPS/BPSì—ì„œ PER/PBR í­ì£¼ ë°©ì§€
                EPS_MIN = safe_env_float("EPS_MIN", 0.1, 0.0)  # 0.1ì› ì´ìƒë§Œ PER ê³„ì‚° (ì™„í™”)
                BPS_MIN = safe_env_float("BPS_MIN", 100.0, 0.0)  # 100ì› ì´ìƒë§Œ PBR ê³„ì‚° (ì™„í™”)
                
                # ë‹¨ìœ„ ê²€ì¦ ë¡œê¹… (1íšŒë§Œ, ë””ë²„ê¹…ìš©)
                if eps is not None and eps > 0:
                    logging.debug(f"[unit-check] EPS={eps:.2f} for {symbol} (ë‹¨ìœ„: ì›)")
                if bps is not None and bps > 0:
                    logging.debug(f"[unit-check] BPS={bps:.2f} for {symbol} (ë‹¨ìœ„: ì›)")
                # âœ… PER ê³„ì‚° ê°€ë“œ ëª…í™•í™”: current_price > 0 í•„ìš” (ì •ì§€/ë‹¨ì£¼ ë“±)
                if eps is not None and eps > EPS_MIN and cp is not None and cp > 0:
                    data['per'] = DataValidator.safe_divide(cp, eps)
                else:
                    data['per'] = None  # ì›ì¸: eps_min ë¯¸ë‹¬/ê²°ì¸¡/ì •ì§€/ê°€ê²©<=0
                    if self.metrics:
                        self.metrics.record_valuation_skip('per_epsmin')
                # âœ… PBR ê³„ì‚° ê°€ë“œ ëª…í™•í™”: current_price > 0 í•„ìš” (ì •ì§€/ë‹¨ì£¼ ë“±)
                if bps is not None and bps > BPS_MIN and cp is not None and cp > 0:
                    data['pbr'] = DataValidator.safe_divide(cp, bps)
                else:
                    data['pbr'] = None  # ì›ì¸: bps_min ë¯¸ë‹¬/ê²°ì¸¡/ì •ì§€/ê°€ê²©<=0
                    if self.metrics:
                        self.metrics.record_valuation_skip('pbr_bpsmin')
                
                # âœ… PER/PBR ìƒí•œ í´ë¨í”„ í™˜ê²½ë³€ìˆ˜í™”: ìš´ì˜ ì¤‘ íŠœë‹ ê°€ëŠ¥
                PER_MAX = safe_env_float("PER_MAX_DEFAULT", 500.0, 100.0)
                PBR_MAX = safe_env_float("PBR_MAX_DEFAULT", 100.0, 10.0)
                if data['per'] is not None:
                    data['per'] = min(data['per'], PER_MAX)  # ìƒí•œ í´ë¨í”„
                if data['pbr'] is not None:
                    data['pbr'] = min(data['pbr'], PBR_MAX)  # ìƒí•œ í´ë¨í”„
                
                # 52ì£¼ ê³ ì € ì •ë³´ ì¡°íšŒ (ì‹¤ì‹œê°„ í”Œë˜ê·¸ì— ë”°ë¼)
                w52h = _none_if_missing_strict(price_data.get('w52_high'))
                w52l = _none_if_missing_strict(price_data.get('w52_low'))
                
                if getattr(self, 'include_realtime', True) and (w52h is None or w52l is None):
                    # KIS APIì—ì„œ ì¶”ê°€ ì¡°íšŒ
                    try:
                        self.rate_limiter.acquire()
                        cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                        cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                        price_info = _with_retries(
                            lambda: self.provider.get_stock_price_info(symbol),
                            metrics_attempt=cb_attempt,
                            metrics_final=cb_final
                        )
                        if price_info:
                            w52h = _none_if_missing_strict(price_info.get('w52_high')) if w52h is None else w52h
                            w52l = _none_if_missing_strict(price_info.get('w52_low')) if w52l is None else w52l
                    except Exception as e:
                        # _with_retriesê°€ ìµœì¢… ì‹¤íŒ¨ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìŒ. ì—¬ê¸°ì„  ë¡œê·¸ë§Œ.
                        logging.debug(f"KIS API 52ì£¼ ê³ ì € ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ {symbol}: {e}")
                
                # 52ì£¼ ê³ ì € ë°ì´í„° ì €ì¥ (ìœ íš¨í•œ ê°’ë§Œ)
                if w52h is not None: data['w52_high'] = w52h
                if w52l is not None: data['w52_low'] = w52l
                
                # ìºì‹œì— ì €ì¥
                self._set_cached(self._cache_price, symbol, data)
                return data
            else:
                # ë¹ˆ í˜ì´ë¡œë“œ ì²˜ë¦¬ (API í˜¸ì¶œì€ ì„±ê³µí–ˆì§€ë§Œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ)
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.EMPTY_PRICE_PAYLOAD)
                    self.metrics.metrics['empty_price_payloads'] += 1
                data = {}
                self._set_cached(self._cache_price, symbol, data)
                return data
        except Exception as e:
            # _with_retriesê°€ ì´ë¯¸ ì‹¤íŒ¨ë¥¼ ê¸°ë¡í•˜ë¯€ë¡œ ì¤‘ë³µ ê¸°ë¡ ë°©ì§€
            log_error("ê°€ê²© ë°ì´í„° ì¡°íšŒ", symbol, e)
            data = {}
            self._set_cached(self._cache_price, symbol, data)
            return data

class EnhancedScoreCalculator(ScoreCalculator):
    """í–¥ìƒëœ ì ìˆ˜ ê³„ì‚°ê¸°"""
    
    def __init__(self, config: AnalysisConfig):
        self.config = config
    
    def calculate_score(self, data: Dict[str, Any], *, sector_info: Optional[Dict[str, Any]] = None, price_data: Optional[Dict[str, Any]] = None) -> Tuple[float, Dict[str, float]]:
        """í†µí•© ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (ìˆœìˆ˜ í•¨ìˆ˜).
        
        ê°€ì¤‘ì¹˜ ì²˜ë¦¬ ì •ì±…:
        - ê²°ì¸¡ ë°ì´í„°ëŠ” ì¤‘ë¦½ì (50) ì ìš© í›„ ê°€ì¤‘ì¹˜ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„
        - ê°€ì¤‘ì¹˜ ì¬ì •ê·œí™”ë¡œ ì´í•©ì´ 100ì´ ë˜ë„ë¡ ì¡°ì •
        - ì´ëŠ” ì¤‘ë¦½ í¸í–¥ ì „ëµìœ¼ë¡œ ì•ˆì •ì ì¸ ì ìˆ˜ ì‚°ì¶œì„ ë³´ì¥
        """
        score = 0.0
        breakdown = {}
        
        # ê° ë¶„ì„ ìš”ì†Œë³„ ì ìˆ˜ ê³„ì‚° (None = ë°ì´í„° ì—†ìŒ)
        def _use(score, key):
            if score is None:
                return 50.0, self.config.weights.get(key, 0) * 0.5
            return score, self.config.weights.get(key, 0)
        
        # PER/PBR ê¸°ë°˜ ë°¸ë¥˜ì—ì´ì…˜ í˜ë„í‹° ì¶”ê°€ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´) - ì´ì¤‘ í˜ë„í‹° ë°©ì§€
        apply_val_in_price = safe_env_bool("VAL_PENALTY_IN_PRICE", True)
        apply_val_in_fin = safe_env_bool("VAL_PENALTY_IN_FIN", False)
        
        # ì´ì¤‘ í˜ë„í‹° ìƒì¶© ê²€ì¶œ ë° ê²½ê³ 
        if apply_val_in_price and apply_val_in_fin:
            logging.warning("[val-penalty] PRICEì™€ FIN ë™ì‹œ ì ìš© ê°ì§€ â†’ FIN ë¹„í™œì„±í™” ê¶Œì¥")
            apply_val_in_fin = False
        
        opinion_score, w_op = _use(self._calculate_opinion_score(data.get('opinion_analysis', {})), 'opinion_analysis')
        estimate_score, w_est = _use(self._calculate_estimate_score(data.get('estimate_analysis', {})), 'estimate_analysis')
        financial_score, w_fin = _use(self._calculate_financial_score(data.get('financial_data', {}), price_data=data.get('price_data'), apply_val_in_fin=apply_val_in_fin), 'financial_ratios')
        growth_score, w_gro = _use(self._calculate_growth_score(data.get('financial_data', {})), 'growth_analysis')
        scale_score, w_sca = _use(self._calculate_scale_score(data.get('market_cap', 0)), 'scale_analysis')
        
        # 52ì£¼ ìœ„ì¹˜ ì ìˆ˜ ê³„ì‚° (missing data half weight ê·œì¹™ ì¼ê´€ì„±)
        pp_raw = data.get('price_position')
        pp_score = self._calculate_price_position_score(pp_raw) if pp_raw is not None else None
            
        if price_data and apply_val_in_price:
            per = price_data.get('per')
            pbr = price_data.get('pbr')
            valuation_penalty = self._calculate_per_pbr_penalty(per, pbr)
            if valuation_penalty is not None:
                # ë°¸ë¥˜ì—ì´ì…˜ í˜ë„í‹°ë¥¼ ê°€ê²©ìœ„ì¹˜ ì ìˆ˜ì— ë°˜ì˜
                pp_score = pp_score * valuation_penalty if pp_score is not None else valuation_penalty * 50
        
        price_position_score, w_pp = _use(pp_score, 'price_position')

        # ì‹ ê·œ: ê°€ì¹˜íˆ¬ì ì ìˆ˜ (ì‚¬ì—…ì˜ ì§ˆ + ì•ˆì „ë§ˆì§„)
        value_score, w_val = _use(
            self._calculate_value_investing_score(
                financial_data=data.get('financial_data', {}),
                price_data=data.get('price_data', {}),
                intrinsic_value=data.get('intrinsic_value')
            ),
            'value_investing'
        )
        
        # ì ìˆ˜ í´ë¨í•‘ (ê·¹ë‹¨ì¹˜/ì˜¤ë²„ìŠ¤ì¼€ì¼ ë°©ì§€)
        def _clamp01(x): 
            return max(0.0, min(100.0, x if x is not None else 50.0))
        
        opinion_score = _clamp01(opinion_score)
        estimate_score = _clamp01(estimate_score)
        financial_score = _clamp01(financial_score)
        growth_score = _clamp01(growth_score)
        scale_score = _clamp01(scale_score)
        price_position_score = _clamp01(price_position_score)
        value_score = _clamp01(value_score)
        
        # ê°€ì¤‘ì¹˜ ì¬ì •ê·œí™” (ê²°ì¸¡ ë°ì´í„°ëŠ” 50ì  + half-weightë¡œ í•­ìƒ í¬í•¨)
        valid_scores = []
        weights_for_norm = []
        for s, w in [
            (opinion_score, w_op),
            (estimate_score, w_est),
            (financial_score, w_fin),
            (growth_score, w_gro),
            (scale_score, w_sca),
            (price_position_score, w_pp),
            (value_score, w_val),
        ]:
            # _use() already returned (score_or_50, adjusted_weight)
            # So at this point s is never None; keep as-is for clarity.
            valid_scores.append((s, w))
            weights_for_norm.append(w)
        
        total_weight = sum(weights_for_norm)
        if total_weight > 0:
            score = sum(s * (w / total_weight) for s, w in valid_scores)
        else:
            score = 50.0
        
        if total_weight > 0:
            breakdown = {
                'íˆ¬ìì˜ê²¬': opinion_score * (w_op / total_weight) if opinion_score is not None else 0,
                'ì¶”ì •ì‹¤ì ': estimate_score * (w_est / total_weight) if estimate_score is not None else 0,
                'ì¬ë¬´ë¹„ìœ¨': financial_score * (w_fin / total_weight) if financial_score is not None else 0,
                'ì„±ì¥ì„±': growth_score * (w_gro / total_weight) if growth_score is not None else 0,
                'ê·œëª¨': scale_score * (w_sca / total_weight) if scale_score is not None else 0,
                'ê°€ê²©ìœ„ì¹˜': price_position_score * (w_pp / total_weight) if price_position_score is not None else 0,
                'ê°€ì¹˜íˆ¬ì': value_score * (w_val / total_weight) if value_score is not None else 0
            }
        else:
            breakdown = {
                'íˆ¬ìì˜ê²¬': 0, 'ì¶”ì •ì‹¤ì ': 0, 'ì¬ë¬´ë¹„ìœ¨': 0,
                'ì„±ì¥ì„±': 0, 'ê·œëª¨': 0, 'ê°€ê²©ìœ„ì¹˜': 0, 'ê°€ì¹˜íˆ¬ì': 0
            }
        
        # ì›ì ìˆ˜ breakdown ì¶”ê°€ (0~100 ìŠ¤ì¼€ì¼, ê°€ì¤‘ì¹˜ ë¯¸ì ìš©)
        raw_breakdown = {
            'opinion_raw': opinion_score,
            'estimate_raw': estimate_score,
            'financial_raw': financial_score,
            'growth_raw': growth_score,
            'scale_raw': scale_score,
            'price_position_raw': price_position_score,
            'value_raw': value_score,
        }
        
        return min(100, max(0, score)), {**breakdown, **raw_breakdown}
    
    def _calculate_opinion_score(self, opinion_data: Dict[str, Any]) -> Optional[float]:
        """íˆ¬ìì˜ê²¬ ì ìˆ˜ ê³„ì‚° (ë°ì´í„° ì—†ìœ¼ë©´ None ë°˜í™˜)"""
        # consensus_scoreë¥¼ ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°
        consensus_score = None
        if 'consensus_score' in opinion_data:
            consensus_score = opinion_data.get('consensus_score')
        elif 'consensus_analysis' in opinion_data:
            consensus_score = opinion_data.get('consensus_analysis', {}).get('consensus_score')
        
        if consensus_score is not None:
            try:
                cs = max(-1.0, min(1.0, float(consensus_score)))
                return (cs + 1.0) * 50.0  # -1~1 â†’ 0~100
            except Exception:
                pass
        return None  # ë°ì´í„° ì—†ìŒ
    
    def _calculate_estimate_score(self, estimate_data: Dict[str, Any]) -> Optional[float]:
        """ì¶”ì •ì‹¤ì  ì ìˆ˜ ê³„ì‚° (ë°ì´í„° ì—†ìœ¼ë©´ None ë°˜í™˜)"""
        if not estimate_data:
            return None  # ë°ì´í„° ì—†ìŒ
        
        w = self.config.estimate_analysis_weights
        fh = DataValidator.safe_float(estimate_data.get('financial_health_score', 0))  # 0~15
        val = DataValidator.safe_float(estimate_data.get('valuation_score', 0))        # 0~15
        
        # ë‘˜ ë‹¤ 0ì´ë©´ ë°ì´í„° ì—†ìŒìœ¼ë¡œ ê°„ì£¼
        if fh == 0 and val == 0:
            return None
        
        total_weight = w['financial_health'] + w['valuation']
        # 0~15ë¥¼ ê°€ì¤‘ í‰ê·  â†’ 0~15 â†’ 0~100
        weighted_raw = (fh * w['financial_health'] + val * w['valuation']) / total_weight  # 0~15
        return (weighted_raw / 15.0) * 100.0
    
    def _calculate_financial_score(self, financial_data: Dict[str, Any], *, price_data: Optional[Dict[str, Any]] = None, apply_val_in_fin: bool = False) -> Optional[float]:
        """ì¬ë¬´ë¹„ìœ¨ ì ìˆ˜ ê³„ì‚° (ì¡´ì¬í•˜ëŠ” ì§€í‘œë§Œ ê°€ì¤‘í•©, ëª¨ë‘ ê²°ì¸¡ì´ë©´ None ë°˜í™˜)
        
        **ì´ì¤‘ ìŠ¤ì¼€ì¼ ê¸ˆì§€**: ì´ í•¨ìˆ˜ëŠ” % ì…ë ¥ì„ ì „ì œë¡œ í•¨ (DataConverter.standardize_financial_units()ì—ì„œ ë³€í™˜ë¨)
        """
        if not financial_data:
            return None
        
        # âœ… Percent canonicalization ë³´í˜¸ ì²´í¬ (resilience ê°œì„ )
        fd = dict(financial_data)  # local snapshot
        if fd.get("_percent_canonicalized") is not True:
            logging.warning("WARNING: financial_data not canonicalized! Re-scaling detected. Applying on-the-fly canonicalization.")
            fd = DataConverter.standardize_financial_units(fd)
            fd["_percent_canonicalized"] = True
        
        # NOTE: ì…ë ¥ì€ canonical % (DataConverter.standardize_financial_units ì´í›„)
        # ì¬ìŠ¤ì¼€ì¼ ê¸ˆì§€: ìˆ«ì ë²”ìœ„ë§Œ ê²€ì¦ (ë¡œì»¬ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ë¶€ìˆ˜íš¨ê³¼ ë°©ì§€)
        _roe = DataValidator.safe_float_optional(fd.get('roe'))
        _roa = DataValidator.safe_float_optional(fd.get('roa'))
        _debt = DataValidator.safe_float_optional(fd.get('debt_ratio'))
        _npm = DataValidator.safe_float_optional(fd.get('net_profit_margin'))
        _cr = DataValidator.safe_float_optional(fd.get('current_ratio'))

        w = self.config.financial_ratio_weights
        roe_w = w.get('roe_score', 8)
        roa_w = w.get('roa_score', 5)
        debt_w = w.get('debt_ratio_score', 7)
        npm_w = w.get('net_profit_margin_score', 5)
        cr_w = w.get('current_ratio_score', 3)

        # ë¡œì»¬ ìŠ¤ëƒ…ìƒ· ì‚¬ìš© (financial_data ìˆ˜ì • ê¸ˆì§€)
        roe = _roe
        roa = _roa
        debt_ratio = _debt
        npm = _npm
        cr = _cr
        # Current ratio units: now fully canonicalized in standardize_financial_units

        acc = 0.0
        wsum = 0.0

        if roe is not None:
            roe_point = 1.0 if roe >= 20 else 0.75 if roe >= 15 else 0.5 if roe >= 10 else 0.25 if roe >= 5 else 0.0
            acc += roe_point * roe_w; wsum += roe_w
        if roa is not None:
            roa_point = 1.0 if roa >= 10 else 0.8 if roa >= 7 else 0.6 if roa >= 5 else 0.4 if roa >= 3 else 0.0
            acc += roa_point * roa_w; wsum += roa_w
        if debt_ratio is not None:
            debt_point = 1.0 if debt_ratio <= 30 else 0.75 if debt_ratio <= 50 else 0.5 if debt_ratio <= 70 else 0.25 if debt_ratio <= 100 else 0.0
            acc += debt_point * debt_w; wsum += debt_w
        if npm is not None:
            npm_point = 1.0 if npm >= 15 else 0.8 if npm >= 10 else 0.6 if npm >= 5 else 0.4 if npm >= 2 else 0.0
            acc += npm_point * npm_w; wsum += npm_w
        if cr is not None:
            cr_point = 1.0 if cr >= 200 else 0.67 if cr >= 150 else 0.33 if cr >= 100 else 0.0
            acc += cr_point * cr_w; wsum += cr_w

        # ìˆ˜ìµì„± ì¼ê´€ì„± í‰ê°€ ì¶”ê°€
        consistency_score = self._calculate_profitability_consistency_score(financial_data)
        if consistency_score is not None:
            consistency_w = w.get('profitability_consistency_score', 5)
            acc += consistency_score * consistency_w; wsum += consistency_w

        # ë°¸ë¥˜ì—ì´ì…˜ í˜ë„í‹° ì¶”ê°€ (PER/PBR ê¸°ë°˜ ê³ í‰ê°€ ì¢…ëª© ì°¨ë‹¨)
        per = None
        pbr = None
        if price_data:
            per = DataValidator.safe_float_optional(price_data.get('per'))
            pbr = DataValidator.safe_float_optional(price_data.get('pbr'))

        valuation_penalty = self._calculate_per_pbr_penalty(per, pbr)
        if valuation_penalty is not None:
            # penalty(0.3~1.0)ë¥¼ 'íšë“ ë¹„ìœ¨'ë¡œ ì‚¬ìš©: ê³ í‰ê°€(ì‘ì€ ê°’)ì¼ìˆ˜ë¡ ì ê²Œ ë°˜ì˜
            # í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´ ê°€ëŠ¥ (ê¸°ë³¸ê°’ Falseë¡œ ì´ì¤‘ í˜ë„í‹° ë°©ì§€)
            # apply_val_in_finì€ ì´ë¯¸ calculate_scoreì—ì„œ ìƒì¶© ê²€ì¶œë¨
            if apply_val_in_fin:
                valuation_w = w.get('valuation_penalty_score', 2)
                acc += valuation_penalty * valuation_w
                wsum += valuation_w

        if wsum == 0:
            return None  # ëª¨ë‘ ê²°ì¸¡ â†’ ìƒìœ„ì—ì„œ half-weight + 50ì  ì²˜ë¦¬
        return (acc / wsum) * 100.0
    
    def _calculate_growth_score(self, financial_data: Dict[str, Any]) -> Optional[float]:
        """ì„±ì¥ì„± ì ìˆ˜ ê³„ì‚° (ì˜ì—…ì´ìµ ì¤‘ì‹¬ ê°•í™” ë²„ì „)"""
        if not financial_data:
            return None  # ë°ì´í„° ì—†ìŒ
        
        revenue_growth = DataValidator.safe_float_optional(financial_data.get('revenue_growth_rate'))
        operating_growth = DataValidator.safe_float_optional(financial_data.get('operating_income_growth_rate'))
        net_growth = DataValidator.safe_float_optional(financial_data.get('net_income_growth_rate'))
        
        # ê²°ì¸¡ì¹˜ë§Œ None ë°˜í™˜, 0%ëŠ” ì¤‘ë¦½ ì ìˆ˜ë¡œ ì²˜ë¦¬
        if revenue_growth is None:
            return None
        
        # ì…ë ¥ í´ë¦½ìœ¼ë¡œ ê·¹ë‹¨ì¹˜ ë°©ì§€ (-100~+100%)
        revenue_growth = max(-100.0, min(100.0, revenue_growth))
        
        # ì˜ì—…ì´ìµì´ ìˆìœ¼ë©´ ì˜ì—…ì´ìµ ì¤‘ì‹¬ í‰ê°€, ì—†ìœ¼ë©´ ë§¤ì¶œ ì¤‘ì‹¬ í‰ê°€
        if operating_growth is not None:
            operating_growth = max(-100.0, min(100.0, operating_growth))
            
            # ì˜ì—…ì´ìµ ì¤‘ì‹¬ ì ìˆ˜ ê³„ì‚° (ë” ì—„ê²©í•œ ê¸°ì¤€)
            if operating_growth >= 30:    # 30% ì´ìƒ
                base_score = 100.0
            elif operating_growth >= 20:  # 20% ì´ìƒ
                base_score = 85.0
            elif operating_growth >= 10:  # 10% ì´ìƒ
                base_score = 70.0
            elif operating_growth >= 0:   # 0% ì´ìƒ
                base_score = 50.0
            elif operating_growth >= -10: # -10% ì´ìƒ
                base_score = 30.0
            elif operating_growth >= -20: # -20% ì´ìƒ
                base_score = 15.0
            else:  # -20% ë¯¸ë§Œ
                base_score = 5.0
        else:
            # ì˜ì—…ì´ìµì´ ì—†ìœ¼ë©´ ë§¤ì¶œ ì¤‘ì‹¬ í‰ê°€
            thresholds = self.config.growth_score_thresholds
            if revenue_growth >= thresholds.get('excellent', 20):
                base_score = 100.0
            elif revenue_growth >= thresholds.get('good', 10):
                base_score = 80.0
            elif revenue_growth >= thresholds.get('average', 0):
                base_score = 50.0
            elif revenue_growth >= thresholds.get('poor', -10):
                base_score = 30.0
            else:
                base_score = 10.0
        
        # ì˜ì—…ì´ìµ-ìˆœì´ìµ ì¼ê´€ì„± ë¶„ì„ (ê°•í™”ëœ í˜ë„í‹°)
        if operating_growth is not None and net_growth is not None:
            profit_diff = operating_growth - net_growth
            
            # ì˜ì—…ì´ìµê³¼ ìˆœì´ìµì˜ ë°©í–¥ì´ ë°˜ëŒ€ì´ë©´ ê°•í•œ í˜ë„í‹°
            if (operating_growth > 0 and net_growth < 0) or (operating_growth < 0 and net_growth > 0):
                # ë°©í–¥ì´ ë°˜ëŒ€ë©´ 70% í˜ë„í‹°
                base_score *= 0.3
            elif abs(profit_diff) > 50:  # 50% ì´ìƒ ì°¨ì´
                base_score *= 0.4  # 60% í˜ë„í‹°
            elif abs(profit_diff) > 30:  # 30% ì´ìƒ ì°¨ì´
                base_score *= 0.6  # 40% í˜ë„í‹°
            elif abs(profit_diff) > 20:  # 20% ì´ìƒ ì°¨ì´
                base_score *= 0.8  # 20% í˜ë„í‹°
        
        # ìˆœì´ìµ ì„±ì¥ë¥  ì¶”ê°€ ë³´ì • (ì˜ì—…ì´ìµê³¼ í•¨ê»˜ ê³ ë ¤)
        if net_growth is not None:
            net_growth = max(-100.0, min(100.0, net_growth))
            
            # ìˆœì´ìµì´ ë§¤ìš° ë‚˜ì˜ë©´ ì¶”ê°€ í˜ë„í‹°
            if net_growth < -30:  # -30% ë¯¸ë§Œ
                base_score *= 0.5  # 50% í˜ë„í‹°
            elif net_growth < -20:  # -20% ë¯¸ë§Œ
                base_score *= 0.7  # 30% í˜ë„í‹°
            elif net_growth < -10:  # -10% ë¯¸ë§Œ
                base_score *= 0.85  # 15% í˜ë„í‹°
        
        # ìµœì¢… ì ìˆ˜ í´ë¨í•‘
        return max(0.0, min(100.0, base_score))
    
    def _calculate_profitability_consistency_score(self, financial_data: Dict[str, Any]) -> Optional[float]:
        """ìˆ˜ìµì„± ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚° (ì˜ì—…ì´ìµ ì¤‘ì‹¬ ê°•í™” ë²„ì „)"""
        operating_growth = DataValidator.safe_float_optional(financial_data.get('operating_income_growth_rate'))
        net_growth = DataValidator.safe_float_optional(financial_data.get('net_income_growth_rate'))
        
        # ë‘ ì§€í‘œ ëª¨ë‘ ìˆì–´ì•¼ í‰ê°€ ê°€ëŠ¥
        if operating_growth is None or net_growth is None:
            return None
        
        # ì°¨ì´ ê³„ì‚°
        profit_diff = operating_growth - net_growth
        
        # ì˜ì—…ì´ìµê³¼ ìˆœì´ìµ ë°©í–¥ ì¼ì¹˜ì„± ì²´í¬
        same_direction = (operating_growth > 0 and net_growth > 0) or (operating_growth < 0 and net_growth < 0)
        
        # ë°©í–¥ì´ ë‹¤ë¥´ë©´ ë§¤ìš° ë‚®ì€ ì ìˆ˜
        if not same_direction:
            if abs(profit_diff) > 30:  # ë°©í–¥ì´ ë°˜ëŒ€ì´ê³  ì°¨ì´ê°€ 30% ì´ìƒ
                return 0.05  # ë§¤ìš° ë‚®ì€ ì¼ê´€ì„±
            else:
                return 0.15  # ë‚®ì€ ì¼ê´€ì„±
        
        # ë°©í–¥ì´ ê°™ì„ ë•Œì˜ ì°¨ì´ ì ìˆ˜ (ë” ì—„ê²©í•œ ê¸°ì¤€)
        if abs(profit_diff) <= 3:  # 3% ì´í•˜ ì°¨ì´
            return 1.0  # ì™„ë²½í•œ ì¼ê´€ì„±
        elif abs(profit_diff) <= 8:  # 8% ì´í•˜ ì°¨ì´
            return 0.85  # ë§¤ìš° ì–‘í˜¸í•œ ì¼ê´€ì„±
        elif abs(profit_diff) <= 15:  # 15% ì´í•˜ ì°¨ì´
            return 0.7  # ì–‘í˜¸í•œ ì¼ê´€ì„±
        elif abs(profit_diff) <= 25:  # 25% ì´í•˜ ì°¨ì´
            return 0.5  # ë³´í†µ ì¼ê´€ì„±
        elif abs(profit_diff) <= 40:  # 40% ì´í•˜ ì°¨ì´
            return 0.3  # ë‚®ì€ ì¼ê´€ì„±
        else:  # 40% ì´ˆê³¼ ì°¨ì´
            return 0.15  # ë§¤ìš° ë‚®ì€ ì¼ê´€ì„±
    
    def _calculate_valuation_penalty(self, financial_data: Dict[str, Any], per: Optional[float] = None, pbr: Optional[float] = None) -> Optional[float]:
        """ë°¸ë¥˜ì—ì´ì…˜ í˜ë„í‹° ê³„ì‚° (PER/PBR ê¸°ë°˜ ê³ í‰ê°€ ì°¨ë‹¨)"""
        # PER/PBR í˜ë„í‹°ëŠ” _calculate_per_pbr_penaltyì—ì„œ ì²˜ë¦¬
        return self._calculate_per_pbr_penalty(per, pbr)
    
    def _calculate_per_pbr_penalty(self, per: Optional[float], pbr: Optional[float]) -> Optional[float]:
        """PER/PBR ê¸°ë°˜ ë°¸ë¥˜ì—ì´ì…˜ í˜ë„í‹° ê³„ì‚° (ê³ í‰ê°€ ì¢…ëª© ì°¨ë‹¨)"""
        if per is None and pbr is None:
            return None
        
        penalty = 1.0  # ê¸°ë³¸ í˜ë„í‹° ì—†ìŒ
        
        # PER í˜ë„í‹°
        if per is not None:
            if per > 50:      # ë§¤ìš° ê³ í‰ê°€
                penalty *= 0.3
            elif per > 30:    # ê³ í‰ê°€
                penalty *= 0.5
            elif per > 20:    # ì•½ê°„ ê³ í‰ê°€
                penalty *= 0.7
            elif per > 15:    # ì ì •
                penalty *= 0.9
            # PER < 15ëŠ” í˜ë„í‹° ì—†ìŒ (ì €í‰ê°€)
        
        # PBR í˜ë„í‹°
        if pbr is not None:
            if pbr > 5:       # ë§¤ìš° ê³ í‰ê°€
                penalty *= 0.2
            elif pbr > 3:     # ê³ í‰ê°€
                penalty *= 0.4
            elif pbr > 2:     # ì•½ê°„ ê³ í‰ê°€
                penalty *= 0.6
            elif pbr > 1.5:   # ì ì •
                penalty *= 0.8
            # PBR < 1.5ëŠ” í˜ë„í‹° ì—†ìŒ (ì €í‰ê°€)
        
        # Configurable minimum penalty to avoid nuking the overall score twice
        min_penalty = safe_env_float("VAL_PENALTY_MIN", 0.3, 0.0)
        return max(min_penalty, penalty)
    
    def _calculate_scale_score(self, market_cap: Optional[float]) -> float:
        """ê·œëª¨ ì ìˆ˜ ê³„ì‚° (ì„¤ì •ê°’ ì‚¬ìš©)"""
        if market_cap is None:
            return 50.0  # default for unknown market cap
        t = self.config.scale_score_thresholds
        if market_cap >= t.get('mega_cap', 100000):
            return 100
        elif market_cap >= t.get('large_cap', 50000):
            return 80
        elif market_cap >= t.get('mid_large_cap', 10000):
            return 60
        elif market_cap >= t.get('mid_cap', 5000):
            return 40
        elif market_cap >= t.get('small_cap', 1000):
            return 20
        else:
            return 0

    # ---------- ì‹ ê·œ: ê°€ì¹˜íˆ¬ì ì ìˆ˜ ----------
    def _calculate_value_investing_score(
        self,
        financial_data: Dict[str, Any],
        price_data: Dict[str, Any],
        intrinsic_value: Optional[float]
    ) -> Optional[float]:
        """ì‚¬ì—…ì˜ ì§ˆ + ì•ˆì „ë§ˆì§„ì„ í†µí•©í•œ ê°€ì¹˜ ì ìˆ˜(0~100)."""
        
        # 1) ì•ˆì „ë§ˆì§„(MoS) ê³„ì‚°
        mos_score = None
        if price_data:
            cp = DataValidator.safe_float_optional(price_data.get('current_price'))
            iv = DataValidator.safe_float_optional(intrinsic_value)
            
            if cp is not None and cp > 0 and iv is not None and iv > 0:
                mos = max(0.0, min(1.0, (iv - cp) / iv))
                mos_score = (
                    100.0 if mos >= 0.5 else
                     85.0 if mos >= 0.35 else
                     70.0 if mos >= 0.2 else
                     50.0 if mos >= 0.1 else
                     25.0 if mos > 0 else
                     10.0
                )

        # 2) ì‚¬ì—…ì˜ ì§ˆ(í•´ì í”„ë¡ì‹œ): ROE/ìˆœì´ìµë§ˆì§„/ë¶€ì±„/ì¼ê´€ì„±
        fd = financial_data or {}
        roe = DataValidator.safe_float_optional(fd.get('roe'))
        npm = DataValidator.safe_float_optional(fd.get('net_profit_margin'))
        debt = DataValidator.safe_float_optional(fd.get('debt_ratio'))
        consistency = self._calculate_profitability_consistency_score(fd)

        q = 0.0; wsum = 0.0
        if roe is not None:
            q += (1.0 if roe >= 20 else 0.75 if roe >= 15 else 0.5 if roe >= 10 else 0.25 if roe >= 5 else 0.0) * 4; wsum += 4
        if npm is not None:
            q += (1.0 if npm >= 15 else 0.8 if npm >= 10 else 0.6 if npm >= 5 else 0.4 if npm >= 2 else 0.0) * 3; wsum += 3
        if debt is not None:
            q += (1.0 if debt <= 30 else 0.75 if debt <= 50 else 0.5 if debt <= 70 else 0.25 if debt <= 100 else 0.0) * 2; wsum += 2
        if consistency is not None:
            q += consistency * 1; wsum += 1
        quality_score = None if wsum == 0 else q / wsum * 100.0

        # 3) ìµœì¢… ì ìˆ˜ ê³„ì‚°
        if mos_score is None and quality_score is None:
            return None
        if mos_score is None:
            return quality_score  # ì‚¬ì—…ì˜ ì§ˆë§Œìœ¼ë¡œ í‰ê°€
        if quality_score is None:
            return mos_score      # MoSë§Œìœ¼ë¡œ í‰ê°€
        return 0.6 * mos_score + 0.4 * quality_score


    # ---------- ì‹ ê·œ: í•´ì(ì§ˆ) ì ìˆ˜/ë“±ê¸‰ ----------
    def _moat_quality_score(self, fd: Dict[str, Any]) -> Optional[float]:
        """ROE/ìˆœì´ìµë§ˆì§„/ë¶€ì±„/ì¼ê´€ì„±ìœ¼ë¡œ 0~100 ì ìˆ˜."""
        try:
            roe = DataValidator.safe_float_optional(fd.get('roe'))
            npm = DataValidator.safe_float_optional(fd.get('net_profit_margin'))
            debt = DataValidator.safe_float_optional(fd.get('debt_ratio'))
            consistency = self._calculate_profitability_consistency_score(fd)
            q = 0.0; w = 0.0
            if roe is not None: q += (1.0 if roe>=20 else 0.75 if roe>=15 else 0.5 if roe>=10 else 0.25 if roe>=5 else 0.0)*4; w+=4
            if npm is not None: q += (1.0 if npm>=15 else 0.8 if npm>=10 else 0.6 if npm>=5 else 0.4 if npm>=2 else 0.0)*3; w+=3
            if debt is not None: q += (1.0 if debt<=30 else 0.75 if debt<=50 else 0.5 if debt<=70 else 0.25 if debt<=100 else 0.0)*2; w+=2
            if consistency is not None: q += consistency*1; w+=1
            return None if w==0 else q/w*100.0
        except Exception:
            return None

    def _moat_grade_from_score(self, s: Optional[float]) -> str:
        if s is None: return "N/A"
        return "Wide" if s>=85 else "Narrow" if s>=70 else "Thin" if s>=55 else "None"

    
    def _calculate_price_position_score(self, price_position: Optional[float]) -> float:
        """
        52ì£¼ ìœ„ì¹˜ì— ë”°ë¥¸ ì ìˆ˜ ê³„ì‚° (ì €í‰ê°€ ê°€ì¹˜ì£¼ ë°œêµ´ ê°•í™”)
        
        ì „ëµì  ì˜ë„:
        - ê³ ìœ„ì¹˜(70%+) ê·¹ê°• ë²Œì : ê³ í‰ê°€ ì¢…ëª© ê°•ë ¥ ì°¨ë‹¨
        - ì¤‘ìœ„ì¹˜(30-70%) ì¤‘ë¦½: ì ì • ë°¸ë¥˜ì—ì´ì…˜ êµ¬ê°„
        - ì €ìœ„ì¹˜(30%-) ê°•ë ¥ ê°€ì : ì €í‰ê°€ êµ¬ê°„ ëŒ€í­ ê°€ì 
        
        ì €í‰ê°€ ê°€ì¹˜ì£¼ ë°œêµ´ì„ ìœ„í•œ ê·¹ê°•í™”ëœ ë°¸ë¥˜ì—ì´ì…˜ ë°˜ì˜
        """
        if price_position is None:
            return 50.0  # ì¤‘ë¦½ì 
        
        # ì €í‰ê°€ ê°€ì¹˜ì£¼ ë°œêµ´ì„ ìœ„í•œ ê·¹ê°•í™”ëœ ë§¤í•‘
        if price_position >= 90:
            # ê·¹ê³ ìœ„ì¹˜: ê·¹ê°• ë²Œì  (90-100% â†’ 0-5ì )
            score = max(0.0, 5.0 - (price_position - 90) * 0.5)
        elif price_position >= 80:
            # ê³ ìœ„ì¹˜: ê°•í•œ ë²Œì  (80-90% â†’ 5-15ì )
            score = max(0.0, 15.0 - (price_position - 80) * 1.0)
        elif price_position >= 70:
            # ìƒìœ„ì¹˜: ë²Œì  (70-80% â†’ 15-30ì )
            score = max(0.0, 30.0 - (price_position - 70) * 1.5)
        elif price_position >= 50:
            # ì¤‘ìœ„ì¹˜: ì¤‘ë¦½ (50-70% â†’ 30-60ì )
            score = 30.0 + (price_position - 50) * 1.5
        elif price_position >= 30:
            # í•˜ìœ„ì¹˜: ê°€ì  (30-50% â†’ 60-80ì )
            score = 60.0 + (price_position - 30) * 1.0
        else:
            # ì €ìœ„ì¹˜: ê°•ë ¥ ê°€ì  (0-30% â†’ 80-100ì  ì •í™•íˆ ë§¤í•‘)
            score = 80.0 + (30 - price_position) * (20.0/30.0)
        
        # ê²½ê³„ê°’ í´ë¨í•‘
        return max(0.0, min(100.0, score))
    
    def _calculate_price_position_penalty(self, price_position: Optional[float]) -> float:
        """52ì£¼ ìœ„ì¹˜ì— ë”°ë¥¸ í˜ë„í‹° ê³„ì‚° (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
        # ìƒˆë¡œìš´ ì •ê·œí™”ëœ ì ìˆ˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜
        return self._calculate_price_position_score(price_position)

# =============================================================================
# 5. ë©”ì¸ ë¶„ì„ í´ë˜ìŠ¤
# =============================================================================

class EnhancedIntegratedAnalyzer:
    """
    ë¦¬íŒ©í† ë§ëœ í–¥ìƒëœ í†µí•© ë¶„ì„ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
    - ë‹¨ì¼ ì¢…ëª© ë¶„ì„ (íˆ¬ìì˜ê²¬, ì¶”ì •ì‹¤ì , ì¬ë¬´ë¹„ìœ¨ í†µí•©)
    - ì „ì²´ ì‹œì¥ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)
    - ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ë¶„ì„
    - ì—…ì¢…ë³„ ë¶„í¬ ë¶„ì„
    - í–¥ìƒëœ ì ìˆ˜ ê³„ì‚° ë° ë“±ê¸‰ í‰ê°€
    
    ì£¼ìš” íŠ¹ì§•:
    - ì•ˆì „í•œ ë°ì´í„° ì ‘ê·¼ (ê°ì²´/ë”•ì…”ë„ˆë¦¬ í˜¼ìš© ëŒ€ì‘)
    - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    - í¬ê´„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬
    - TTL ìºì‹± ì‹œìŠ¤í…œ
    - ì‹¤ì‹œê°„ ë°ì´í„° í†µí•©
    """
    
    def __init__(self, config_file: str = "config.yaml", include_realtime: bool = True, include_external: bool = True):
        # ë¡œê¹…/í™˜ê²½ ìºì‹œ ì¤€ë¹„
        _refresh_env_cache()
        self.config_manager = ConfigManager(config_file)
        
        # ê°œì„ ëœ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”
        if IMPROVED_MODULES_AVAILABLE:
            self.rate_limiter = get_default_rate_limiter()
            self.exception_handler = get_global_handler()
            self.input_validator = get_global_validator()
            self.cache = get_global_cache("analyzer_cache")
            self.batch_processor = BatchProcessor(batch_size=50, max_wait_time=0.5)
            self.code_optimizer = CodeOptimizer()
            self.data_processor = DataProcessor()
            self.memory_optimizer = MemoryOptimizer()
            self.performance_monitor = PerformanceMonitor()
            self.performance_profiler = PerformanceProfiler(self.performance_monitor)
            self.price_enhancer = PriceDisplayEnhancer()
            self.value_investing = ValueInvestingPhilosophy()
        else:
            self.rate_limiter = TPSRateLimiter()
            self.exception_handler = None
            self.input_validator = None
            self.cache = None
            self.performance_monitor = None
            self.batch_processor = None
            self.code_optimizer = None
            self.data_processor = None
            self.memory_optimizer = None
        
        self.include_realtime = include_realtime
        self.include_external = include_external
        
        # âœ… í™˜ê²½ë³€ìˆ˜ ìºì‹± (í•«íŒ¨ìŠ¤ ìµœì í™”)
        self.env_cache = {
            'current_ratio_ambiguous_strategy': os.getenv("CURRENT_RATIO_AMBIGUOUS_STRATEGY", "as_is"),
            'current_ratio_force_percent': os.getenv("CURRENT_RATIO_FORCE_PERCENT", "false"),
            'market_cap_strict_mode': os.getenv("MARKET_CAP_STRICT_MODE", "true"),
            'max_sector_peers_base': safe_env_int("MAX_SECTOR_PEERS_BASE", 40, 5),
            'max_sector_peers_full': safe_env_int("MAX_SECTOR_PEERS_FULL", 200, 20),
            'sector_target_good': safe_env_int("SECTOR_TARGET_GOOD", 60, 10),
            'max_sector_cache_entries': safe_env_int("MAX_SECTOR_CACHE_ENTRIES", 64, 1),
            'max_sector_api_boost': safe_env_int("MAX_SECTOR_API_BOOST", 10, 0),
        }
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        self.metrics = MetricsCollector()
        
        # ===== ê°€ì¹˜íˆ¬ì ì •ì±…(ë°©ì£¼) ê¸°ë³¸ê°’ =====
        # (í™˜ê²½ë³€ìˆ˜/ì„¤ì •ì—ì„œ ì¬ì •ì˜ ê°€ëŠ¥)
        self.value_policy = {
            "min_mos_buy": float(os.getenv("VAL_MIN_MOS_BUY", "0.30")),     # 30% ì´ìƒì´ë©´ ë§¤ìˆ˜ ê³ ë ¤
            "min_mos_watch": float(os.getenv("VAL_MIN_MOS_WATCH", "0.10")), # 10%~30%ëŠ” ê´€ì°°
            "min_quality_for_buy": int(os.getenv("VAL_MIN_QUALITY", "70")), # í•´ì/ì§ˆ ì ìˆ˜ ê¸°ì¤€
            "max_price_pos_for_buy": float(os.getenv("VAL_MAX_PRICEPOS", "60")), # 52ì£¼ ìœ„ì¹˜ ìƒë‹¨ ê³¼ì—´ íšŒí”¼
            "reeval_cooldown_min": int(os.getenv("VAL_REEVAL_COOLDOWN_MIN", "1440")), # ì¬í‰ê°€ ìµœì†Œ ê°„ê²©(ë¶„)
            # ë³´ìˆ˜ì  ë‚´ì¬ê°€ì¹˜ ì¶”ì • íŒŒë¼ë¯¸í„°
            "fcf_growth_cap": float(os.getenv("VAL_FCF_GROWTH_CAP", "0.06")),     # ì¥ê¸° ì„±ì¥ë¥  ìƒí•œ 6%
            "discount_floor": float(os.getenv("VAL_DISCOUNT_FLOOR", "0.12")),     # í• ì¸ìœ¨ í•˜í•œ 12%
            "terminal_mult_cap": float(os.getenv("VAL_TERM_MULT_CAP", "12.0")),   # í„°ë¯¸ë„ ë©€í‹°í”Œ ìƒí•œ
            "eps_mult_base": float(os.getenv("VAL_EPS_MULT_BASE", "10.0")),       # EPS ë³´ìˆ˜ì  ë©€í‹°í”Œ
            "eps_mult_bonus": float(os.getenv("VAL_EPS_MULT_BONUS", "2.0")),      # ì§ˆ ì–‘í˜¸ ì‹œ ë³´ë„ˆìŠ¤
        }

        # ë§ˆì§€ë§‰ ì‹œê·¸ë„ ì‹œê°„ ìºì‹œ(Temperament Guard)
        self._last_signal_ts: Dict[str, float] = {}

        # í™˜ê²½ë³€ìˆ˜ í•«ë¦¬ë¡œë“œ ë“±ë¡
        _register_analyzer_for_env_reload(self)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._initialize_components()

    # ---------- ì‹ ê·œ: ì›Œì¹˜ë¦¬ìŠ¤íŠ¸/ì‹œê·¸ë„ ----------
    def _compute_watchlist_signal(self, symbol: str, current_price: Optional[float], intrinsic_value: Optional[float], quality_score: Optional[float], price_position: Optional[float], overall_score: Optional[float] = None) -> Tuple[str, Optional[float]]:
        """
        BUY / WATCH / PASS ì™€ ëª©í‘œë§¤ìˆ˜ê°€(= IV * (1 - min_mos_buy))
        Temperament Guard: ê³¼ë¹ˆë„ ì•Œë¦¼ ì–µì œ
        """
        cp = DataValidator.safe_float_optional(current_price)
        iv = DataValidator.safe_float_optional(intrinsic_value)
        pp = DataValidator.safe_float_optional(price_position)
        q = quality_score

        if cp is None or iv is None or iv <= 0:
            return ("PASS", None)
        mos = max(0.0, min(1.0, (iv - cp) / iv))
        target_buy = iv * (1.0 - self.value_policy["min_mos_buy"])

        # ê³¼ì—´ êµ¬ê°„ íšŒí”¼
        if pp is not None and pp > self.value_policy["max_price_pos_for_buy"] + 20:
            return ("PASS", target_buy)

        # í’ˆì§ˆ ë¯¸ë‹¬ ì‹œ íšŒí”¼
        if q is not None and q < self.value_policy["min_quality_for_buy"] - 10:
            return ("PASS", target_buy)

        # ì¢…í•© ì ìˆ˜ ì¡°ê±´ ì¶”ê°€ (ê¸°ë³¸ 60ì  ì´ìƒ)
        min_overall_score = float(os.getenv("VAL_MIN_OVERALL_SCORE", "60.0"))
        overall_ok = overall_score is None or overall_score >= min_overall_score
        
        if mos >= self.value_policy["min_mos_buy"] and (q is None or q >= self.value_policy["min_quality_for_buy"]) and (pp is None or pp <= self.value_policy["max_price_pos_for_buy"]) and overall_ok:
            # Temperament Guard
            import time
            now = time.time()
            last = self._last_signal_ts.get(symbol, 0.0)
            if now - last >= self.value_policy["reeval_cooldown_min"]*60:
                self._last_signal_ts[symbol] = now
            return ("BUY", target_buy)
        elif mos >= self.value_policy["min_mos_watch"]:
            return ("WATCH", target_buy)
        else:
            return ("PASS", target_buy)

    # ---------- ì‹ ê·œ: í”Œë ˆì´ë¶ ì¶œë ¥ ----------
    def _value_investing_playbook(self, symbol: str, iv: Optional[float], target_buy: Optional[float], moat_grade: str) -> List[str]:
        tips = []
        tips.append("â‘  ë¦¬ìŠ¤íŠ¸: ì—­ëŸ‰ ë²”ìœ„ ë‚´ ìš°ëŸ‰ ê¸°ì—…ì„ ëª©ë¡í™”")
        if iv:
            tips.append(f"â‘¡ ë‚´ì¬ê°€ì¹˜(ë³´ìˆ˜ì ): ì£¼ë‹¹ ì•½ {iv:,.0f}")
        if target_buy:
            tips.append(f"â‘¢ ë§¤ìˆ˜ê°€(ì•ˆì „ë§ˆì§„ ë°˜ì˜): â‰¤ {target_buy:,.0f}")
        tips.append("â‘£ ê¸°ë‹¤ë¦¼: ë¯¸ìŠ¤í„° ë§ˆì¼“ì´ ê³µí¬ì¼ ë•Œë§Œ ì§‘í–‰")
        tips.append(f"â‘¤ ì§‘í–‰: í•´ìë“±ê¸‰({moat_grade}) í›¼ì† ì—†ìœ¼ë©´ ì¥ê¸° ë³´ìœ  ì „ì œ")
        return tips

    # ---------- ì‹ ê·œ: ë‚´ì¬ê°€ì¹˜ ë³´ìˆ˜ì  ì¶”ì • ----------
    def _estimate_intrinsic_value(self, symbol: str, financial_data: Dict[str, Any], price_data: Dict[str, Any]) -> Optional[float]:
        """
        ë‘ ëª¨ë¸ ì¤‘ ë” ë³´ìˆ˜ì ì¸(ë‚®ì€) ê°’ì„ ì±„íƒ:
        (A) ë‹¨ê¸° ë‹¨ìˆœ FCF ì „ê°œ + í• ì¸ / (B) EPS Ã— ë³´ìˆ˜ì  ë©€í‹°í”Œ
        """
        try:
            policy = self.value_policy
            # ë°ì´í„° í™•ë³´(ì‚¬ì—…ì„ ì‚¬ë¼: í•µì‹¬ ë°ì´í„° ì—†ìœ¼ë©´ ì¶”ì • ë³´ë¥˜)
            fcf = DataValidator.safe_float_optional(financial_data.get("free_cash_flow_per_share"))
            eps = DataValidator.safe_float_optional(financial_data.get("eps"))
            shares = DataValidator.safe_float_optional(financial_data.get("shares_outstanding"))
            quality = self.score_calculator._moat_quality_score(financial_data)

            iv_a = None
            if fcf is not None and fcf > 0:
                g = min(policy["fcf_growth_cap"], max(-0.05, DataValidator.safe_float_optional(financial_data.get("fcf_growth", 0.0)) or 0.0))
                r = max(policy["discount_floor"], DataValidator.safe_float_optional(financial_data.get("discount_rate", policy["discount_floor"])) or policy["discount_floor"])
                term_mult = min(policy["terminal_mult_cap"], 12.0 + (quality - 70) * 0.1 if quality is not None else 10.0)
                # 5ë…„ ë‹¨ìˆœ ì „ê°œ(ë³´ìˆ˜ì ) + í„°ë¯¸ë„ ë°¸ë¥˜
                horizon = 5
                pv = 0.0
                cf = fcf
                for t in range(1, horizon + 1):
                    cf = cf * (1 + g)
                    pv += cf / ((1 + r) ** t)
                terminal = (cf * term_mult) / ((1 + r) ** horizon)
                iv_a = (pv + terminal)

            iv_b = None
            if eps is not None and eps > 0:
                mult = policy["eps_mult_base"] + (policy["eps_mult_bonus"] if (quality is not None and quality >= 80) else 0.0)
                iv_b = eps * mult

            candidates = [v for v in [iv_a, iv_b] if v is not None and v > 0]
            if not candidates:
                return None
            per_share_iv = min(candidates)
            # ë§Œì•½ ì£¼ì‹ìˆ˜ ì œê³µë˜ë©´ ì£¼ë‹¹ ê¸°ì¤€ì´ ì´ë¯¸ per-shareì¼ ìˆ˜ ìˆìŒ â†’ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return per_share_iv
        except Exception as e:
            logging.warning(f"[{symbol}] intrinsic value estimate failed: {e}")
            return None

    def _initialize_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.opinion_analyzer = InvestmentOpinionAnalyzer()
        self.estimate_analyzer = EstimatePerformanceAnalyzer()
        self.provider = KISDataProvider()
        self.data_provider = FinancialDataProvider(self.provider, self.rate_limiter, metrics=self.metrics)
        # í”Œë˜ê·¸ ì „ë‹¬
        self.data_provider.include_realtime = self.include_realtime
        
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_analysis_config()
        self.score_calculator = EnhancedScoreCalculator(self.config)
        self._validate_config()
        
        # âœ… ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½ ì¶”ê°€
        self._sector_warned_lock = RLock()
        self._sector_warned: Set[str] = set()
        
        # KOSPI ë°ì´í„° ë¡œë“œ
        self.kospi_data = None
        self._kospi_loading_failed = False
        self._load_kospi_data()
        
        # ì„¹í„° ë²¡í„° ìºì‹œ ì œê±°ë¨ (ë¯¸ì‚¬ìš©)
        
        # ì„¹í„° íŠ¹ì„± ìºì‹œ (TTL 30ë¶„, ë™ì  ì¡°ì •)
        self._sector_char_cache = OrderedDict()
        self._sector_char_cache_ttl = safe_env_int("SECTOR_CHAR_CACHE_TTL", 1800, 300)  # ê¸°ë³¸ 30ë¶„, ìµœì†Œ 5ë¶„
        self._sector_char_cache_lock = RLock()
        self._sector_char_cache_max_size = safe_env_int("SECTOR_CHAR_CACHE_MAX_SIZE", 256, 64)  # ê¸°ë³¸ 256ê°œ, ìµœì†Œ 64ê°œ
        
        # ì™¸ë¶€ ë¶„ì„ê¸° ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½ (ë¶„ë¦¬)
        self._opinion_lock = RLock()
        self._estimate_lock = RLock()
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
        self._memory_threshold = safe_env_float("MEMORY_THRESHOLD_MB", 1024.0, 256.0)  # ê¸°ë³¸ 1GB
        self._gc_interval = safe_env_int("GC_INTERVAL", 100, 10)  # ê¸°ë³¸ 100íšŒ ë¶„ì„ë§ˆë‹¤ GC
        self._analysis_count = 0
    
    def _check_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜"""
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            if memory_mb > self._memory_threshold:
                logging.warning(f"High memory usage: {memory_mb:.1f}MB (threshold: {self._memory_threshold}MB)")
                import gc
                gc.collect()
                logging.info("Garbage collection performed")
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¬í™•ì¸
                new_memory_mb = process.memory_info().rss / 1024 / 1024
                logging.info(f"Memory after GC: {new_memory_mb:.1f}MB (freed: {memory_mb - new_memory_mb:.1f}MB)")
        except ImportError:
            # psutilì´ ì—†ëŠ” ê²½ìš° ê°„ë‹¨í•œ GCë§Œ ìˆ˜í–‰
            if self._analysis_count % self._gc_interval == 0:
                import gc
                gc.collect()
                logging.debug(f"Periodic garbage collection (count: {self._analysis_count})")
        except Exception as e:
            logging.debug(f"Memory check failed: {e}")
    
    def _increment_analysis_count(self):
        """ë¶„ì„ ì¹´ìš´íŠ¸ ì¦ê°€ ë° ë©”ëª¨ë¦¬ ì²´í¬"""
        self._analysis_count += 1
        if self._analysis_count % self._gc_interval == 0:
            self._check_memory_usage()
    
    def close(self):
        """ëª…ì‹œì  ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë° í™˜ê²½ë³€ìˆ˜ í•«ë¦¬ë¡œë“œ ë“±ë¡ í•´ì œ"""
        try:
            _unregister_analyzer_for_env_reload(self)
            
            # ê°œì„ ëœ ìºì‹œ ì •ë¦¬
            if IMPROVED_MODULES_AVAILABLE and self.cache:
                try:
                    self.cache.close()
                    logging.debug("[analyzer] Memory-safe cache closed")
                except Exception as e:
                    logging.debug(f"[analyzer] cache.close() error: {e}")
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if IMPROVED_MODULES_AVAILABLE:
                try:
                    optimize_memory()
                    logging.debug("[analyzer] Memory optimization completed")
                except Exception as e:
                    logging.debug(f"[analyzer] Memory optimization error: {e}")
                
                # ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
                try:
                    if hasattr(self, 'performance_monitor') and self.performance_monitor:
                        report_path = export_performance_report()
                        logging.info(f"[analyzer] Performance report generated: {report_path}")
                except Exception as e:
                    logging.debug(f"[analyzer] Performance report generation error: {e}")
            
            # graceful shutdown - ëª¨ë“  ìì› ì •ë¦¬
            for obj_name in ("provider", "data_provider", "opinion_analyzer", "estimate_analyzer"):
                obj = getattr(self, obj_name, None)
                try:
                    if hasattr(obj, "close"):
                        obj.close()
                except Exception as e:
                    logging.debug(f"[analyzer] {obj_name}.close() error: {e}")
            
            # ì„¹í„° ìºì‹œ ì •ë¦¬
            if hasattr(self, '_sector_char_cache'):
                import threading
                with getattr(self, '_sector_char_cache_lock', threading.RLock()):
                    self._sector_char_cache.clear()
            
            logging.debug(f"[analyzer] {self.__class__.__name__} closed")
        except Exception as e:
            logging.debug(f"[analyzer] close() error: {e}")
    
    def __del__(self):
        """ì¸ìŠ¤í„´ìŠ¤ ì†Œë©¸ ì‹œ í™˜ê²½ë³€ìˆ˜ í•«ë¦¬ë¡œë“œ ë“±ë¡ í•´ì œ (fallback)"""
        try:
            _unregister_analyzer_for_env_reload(self)
        except Exception:
            pass
    
    # _result_to_dict ë©”ì„œë“œ ì œê±°ë¨ - AnalysisResult.to_dict() ì‚¬ìš©
    
    def _load_analysis_config(self) -> AnalysisConfig:
        """ë¶„ì„ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        config = self.config_manager.load_config()
        enhanced_config = config.get('enhanced_integrated_analysis', {})
        
        return AnalysisConfig(
            weights=enhanced_config.get('weights', {
                'opinion_analysis': 15,
                'estimate_analysis': 20,
                'financial_ratios': 25,
                'growth_analysis': 10,
                'scale_analysis': 5,
                'price_position': 25
            }),
            financial_ratio_weights=enhanced_config.get('financial_ratio_weights', {
                'roe_score': 8,
                'roa_score': 5,
                'debt_ratio_score': 7,
                'net_profit_margin_score': 5,
                'current_ratio_score': 3,
                'growth_score': 2
            }),
            estimate_analysis_weights=enhanced_config.get('estimate_analysis_weights', {
                'financial_health': 15,
                'valuation': 15
            }),
            grade_thresholds=enhanced_config.get('grade_thresholds', {
                'A_plus': 80,
                'A': 70,
                'B_plus': 60,
                'B': 50,
                'C_plus': 40,
                'C': 30,
                'D_plus': 20,
                'D': 10,
                'F': 0
            }),
            growth_score_thresholds=enhanced_config.get('growth_score_thresholds', {
                'excellent': 20,
                'good': 10,
                'average': 0,
                'poor': -10,
                'very_poor': -100
            }),
            scale_score_thresholds=enhanced_config.get('scale_score_thresholds', {
                'mega_cap': 100000,
                'large_cap': 50000,
                'mid_large_cap': 10000,
                'mid_cap': 5000,
                'small_cap': 1000,
                'micro_cap': 0
            }),
        )
    
    def _validate_config(self) -> None:
        """ì„¤ì • ê°€ì¤‘ì¹˜/ì„ê³„ê°’ sanity-check (ê²½ê³ ë§Œ)"""
        try:
            w = self.config.weights
            total = sum(float(w.get(k,0)) for k in w)
            if total <= 0:
                logging.warning("[config] weights í•©ì´ 0 ì´í•˜ì…ë‹ˆë‹¤. ê¸°ë³¸ ê°€ì¤‘ì¹˜ ê¶Œì¥")
            for name, thr in self.config.scale_score_thresholds.items():
                if not isinstance(thr, (int,float)):
                    logging.warning(f"[config] scale threshold '{name}'ì´ ìˆ«ìê°€ ì•„ë‹˜")
        except Exception as e:
            logging.debug(f"[config] validate ì‹¤íŒ¨: {e}")
    
    def _load_kospi_data(self):
        """KOSPI ë§ˆìŠ¤í„° ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤ (xlsx/csv ì§€ì›, ë©”ëª¨ë¦¬ ìµœì í™”)."""
        try:
            # âœ… CSV ì§€ì› ì˜µì…˜ ì¶”ê°€ (I/O ê°ì†Œ)
            kospi_csv = 'kospi_code.csv'
            kospi_xlsx = 'kospi_code.xlsx'
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
            required_columns = ['ë‹¨ì¶•ì½”ë“œ', 'í•œê¸€ëª…', 'ì‹œê°€ì´ì•¡']
            optional_columns = ['ì—…ì¢…', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì—…ì¢…ëª…', 'ì„¹í„°']
            
            if os.path.exists(kospi_csv):
                # CSV ìš°ì„  ë¡œë“œ (ë” ë¹ ë¥¸ I/O)
                try:
                    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ
                    self.kospi_data = pd.read_csv(
                        kospi_csv, 
                        encoding='utf-8-sig',
                        usecols=lambda x: x in required_columns + optional_columns,
                        dtype={'ë‹¨ì¶•ì½”ë“œ': 'string', 'í•œê¸€ëª…': 'string'}  # ë©”ëª¨ë¦¬ ìµœì í™”
                    )
                    # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œë¡œ fallback
                    if self.kospi_data.empty or not any(col in self.kospi_data.columns for col in required_columns):
                        logging.warning("í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ CSV ë¡œë“œ ì‹œë„")
                        self.kospi_data = pd.read_csv(kospi_csv, encoding='utf-8-sig')
                    logging.info(f"KOSPI ë°ì´í„° ë¡œë“œ ì™„ë£Œ (CSV): {kospi_csv}")
                except Exception as e:
                    logging.warning(f"CSV ì½ê¸° ì‹¤íŒ¨: {e}")
                    self.kospi_data = pd.DataFrame()
                    return
            elif os.path.exists(kospi_xlsx):
                try:
                    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ
                    self.kospi_data = pd.read_excel(
                        kospi_xlsx, 
                        engine="openpyxl",
                        usecols=lambda x: x in required_columns + optional_columns,
                        dtype={'ë‹¨ì¶•ì½”ë“œ': 'string', 'í•œê¸€ëª…': 'string'}  # ë©”ëª¨ë¦¬ ìµœì í™”
                    )
                    # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œë¡œ fallback
                    if self.kospi_data.empty or not any(col in self.kospi_data.columns for col in required_columns):
                        logging.warning("í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ Excel ë¡œë“œ ì‹œë„")
                        self.kospi_data = pd.read_excel(kospi_xlsx, engine="openpyxl")
                    logging.info(f"KOSPI ë°ì´í„° ë¡œë“œ ì™„ë£Œ (Excel): {kospi_xlsx}")
                except ImportError:
                    try:
                        self.kospi_data = pd.read_excel(kospi_xlsx)  # íŒë‹¤ìŠ¤ ê¸°ë³¸ ì—”ì§„ ì‹œë„
                    except Exception as e:
                        logging.warning(f"xlsx ì½ê¸° ì‹¤íŒ¨: openpyxl ì„¤ì¹˜ ê¶Œì¥. ì›ì¸: {e}")
                        self.kospi_data = pd.DataFrame()
                        return
            else:
                logging.warning("KOSPI ë§ˆìŠ¤í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (kospi_code.csv ë˜ëŠ” kospi_code.xlsx)")
                self.kospi_data = pd.DataFrame()
                return
            
            # ê³µí†µ ë°ì´í„° ì²˜ë¦¬ (CSV/Excel ê³µí†µ)
            if not self.kospi_data.empty:
                # âœ… KOSPI ìŠ¤í‚¤ë§ˆ ë³„ì¹­ ì§€ì› (ë‹¤ì–‘í•œ í™˜ê²½ ëŒ€ì‘)
                column_aliases = {
                    'ì¢…ëª©ëª…': 'í•œê¸€ëª…',
                    'ì¢…ëª©ì½”ë“œ': 'ë‹¨ì¶•ì½”ë“œ',
                    'ì½”ë“œ': 'ë‹¨ì¶•ì½”ë“œ',
                    'ì‹œì´': 'ì‹œê°€ì´ì•¡',
                    'market_cap': 'ì‹œê°€ì´ì•¡',
                    'name': 'í•œê¸€ëª…',
                    'symbol': 'ë‹¨ì¶•ì½”ë“œ'
                }
                
                # ë³„ì¹­ ì ìš©
                for alias, standard in column_aliases.items():
                    if alias in self.kospi_data.columns and standard not in self.kospi_data.columns:
                        self.kospi_data[standard] = self.kospi_data[alias]
                        logging.info(f"ì»¬ëŸ¼ ë³„ì¹­ ì ìš©: '{alias}' â†’ '{standard}'")
                
                self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] = (
                    self.kospi_data['ë‹¨ì¶•ì½”ë“œ']
                        .astype(str)
                        .str.replace(r'\.0$', '', regex=True)
                        .str.zfill(6)
                )
                
                # ìŠ¤í‚¤ë§ˆ ê²€ì¦
                required_cols = {"ë‹¨ì¶•ì½”ë“œ", "í•œê¸€ëª…", "ì‹œê°€ì´ì•¡"}
                if not required_cols.issubset(self.kospi_data.columns):
                    # ìŠ¤í‚¤ë§ˆ ì •ë³´ ë¡œê¹… (ìš´ì˜ ì§€ì›)
                    detected_cols = list(self.kospi_data.columns)[:10]  # ì²˜ìŒ 10ê°œ ì»¬ëŸ¼ë§Œ
                    logging.error(f"KOSPI ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜: í•„ìš”ì»¬ëŸ¼ {required_cols}, ê°ì§€ëœ ì»¬ëŸ¼ {detected_cols}")
                    raise ValueError(f"KOSPI ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜: í•„ìš”ì»¬ëŸ¼ {required_cols}, ì‹¤ì œ {set(self.kospi_data.columns)}")
                
                # ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì •ë¦¬ (í˜¼í•© íƒ€ì… ì²˜ë¦¬)
                if 'ì‹œê°€ì´ì•¡' in self.kospi_data.columns:
                    self.kospi_data['ì‹œê°€ì´ì•¡'] = pd.to_numeric(
                        self.kospi_data['ì‹œê°€ì´ì•¡'].astype(str).str.replace(',', ''), errors='coerce'
                    )  # no fillna - keep NaN for unknown market caps
                
                # ìœ íš¨í•œ 6ìë¦¬ ì¢…ëª© ì½”ë“œë§Œ í•„í„°ë§
                original_count = len(self.kospi_data)
                self.kospi_data = self.kospi_data[
                    self.kospi_data['ë‹¨ì¶•ì½”ë“œ'].str.match(r'^\d{6}$', na=False)
                ]
                filtered_count = len(self.kospi_data)
                
                logging.info(f"KOSPI ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {original_count}ê°œ â†’ {filtered_count}ê°œ ìœ íš¨ ì¢…ëª©")
                
                # âœ… pandas filtering ìµœì í™”: ì¸ë±ìŠ¤ ì„¤ì •
                if not self.kospi_data.empty and 'ë‹¨ì¶•ì½”ë“œ' in self.kospi_data.columns:
                    self.kospi_data.set_index('ë‹¨ì¶•ì½”ë“œ', inplace=True)
                    logging.debug("KOSPI ë°ì´í„° ì¸ë±ìŠ¤ ì„¤ì • ì™„ë£Œ (ë‹¨ì¶•ì½”ë“œ)")
        except Exception as e:
            log_error("KOSPI ë°ì´í„° ë¡œë“œ", error=e, level="error")
            self.kospi_data = pd.DataFrame()
            # KOSPI ë¡œë”© ì‹¤íŒ¨ í”Œë˜ê·¸ ì„¤ì •
            self._kospi_loading_failed = True
    
    @timed_operation("analyze_single_stock")
    @handle_errors(severity=ErrorSeverity.HIGH, category=ErrorCategory.BUSINESS)
    @retry_on_failure(max_attempts=2, base_delay=1.0)
    @measure_performance
    @monitor_memory
    @profile_function("analyze_single_stock")
    def analyze_single_stock(self, symbol: str, name: str, days_back: int = 30) -> AnalysisResult:
        """
        ë‹¨ì¼ ì¢…ëª© ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            symbol (str): ì¢…ëª© ì½”ë“œ (6ìë¦¬ ìˆ«ì)
            name (str): ì¢…ëª©ëª…
            days_back (int): íˆ¬ìì˜ê²¬ ë¶„ì„ ê¸°ê°„ (ì¼)
            
        Returns:
            AnalysisResult: ë¶„ì„ ê²°ê³¼ ê°ì²´
            
        Raises:
            ValueError: ì¢…ëª© ì½”ë“œê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
            ValueError: ì¢…ëª©ëª…ì´ ì—†ëŠ” ê²½ìš°
        """
        start_time = _monotonic()
        
        # ê°œì„ ëœ ì…ë ¥ ê²€ì¦
        if IMPROVED_MODULES_AVAILABLE and self.input_validator:
            validation_results = self.input_validator.validate_stock_data({
                'symbol': symbol,
                'name': name,
                'days_back': days_back
            })
            
            # ì‹¬ê°í•œ ê²€ì¦ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ì¡°ê¸° ë°˜í™˜
            for result in validation_results:
                if result.severity.value in ['error', 'critical']:
                    if self.exception_handler:
                        from standardized_exception_handler import ErrorContext
                        context = ErrorContext(
                            category=ErrorCategory.VALIDATION,
                            severity=ErrorSeverity.HIGH,
                            operation="analyze_single_stock",
                            symbol=symbol,
                            metadata={'validation_error': result.message}
                        )
                        self.exception_handler.handle_error(ValueError(result.message), context)
                    
                    return AnalysisResult(
                        symbol=symbol,
                        name=name,
                        status=AnalysisStatus.ERROR,
                        error_message=f"ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨: {result.message}",
                        analysis_time=_monotonic() - start_time
                    )
        
        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            self._increment_analysis_count()
            
            # KOSPI ë¡œë”© ì‹¤íŒ¨ í™•ì¸ ë° ê²½ê³ 
            if getattr(self, '_kospi_loading_failed', False):
                logging.warning(f"KOSPI ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ë¡œ ì¸í•´ ê·œëª¨/ì•ˆì •ì„± ì ìˆ˜ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤: {symbol}({name})")
            
            # ê¸°ì¡´ ì…ë ¥ ê²€ì¦ (í•˜ìœ„ í˜¸í™˜ì„±)
            if not DataValidator.is_valid_symbol(symbol):
                return AnalysisResult(
                    symbol=symbol,
                    name=name,
                    status=AnalysisStatus.ERROR,
                    error=f"ìœ íš¨í•˜ì§€ ì•Šì€ ì¢…ëª© ì½”ë“œ: {symbol}"
                )
            
            if not name or not isinstance(name, str):
                return AnalysisResult(
                    symbol=symbol,
                    name=name or "Unknown",
                    status=AnalysisStatus.ERROR,
                    error="ì¢…ëª©ëª…ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ"
                )
            
            # ìš°ì„ ì£¼ í™•ì¸
            if self._is_preferred_stock(name):
                logging.info(f"ìš°ì„ ì£¼ ì œì™¸: {name} ({symbol})")
                return AnalysisResult(
                    symbol=symbol,
                    name=name,
                    status=AnalysisStatus.SKIPPED_PREF,
                    enhanced_score=0,
                    enhanced_grade='F',
                    error="preferred stock filtered"
                )
            
            # ê° ë¶„ì„ ìˆ˜í–‰
            opinion_analysis = self._analyze_opinion(symbol, days_back, name=name)
            estimate_analysis = self._analyze_estimate(symbol, name=name)
            financial_data = self.data_provider.get_financial_data(symbol)
            price_data = self.data_provider.get_price_data(symbol)
            
            # ë°ì´í„° ë¶€ì¡± ìƒíƒœ í™•ì¸
            if not financial_data and not price_data:
                return AnalysisResult(
                    symbol=symbol,
                    name=name,
                    status=AnalysisStatus.NO_DATA,
                    error="no price & financial data"
                )
            
            # ì‹œê°€ì´ì•¡ ì¡°íšŒ
            market_cap = self._get_market_cap(symbol)

            # --- ê°€ì¹˜íˆ¬ì: ë‚´ì¬ê°€ì¹˜/ì•ˆì „ë§ˆì§„/í•´ì ì¶”ì • ---
            current_price = DataValidator.safe_float_optional(price_data.get('current_price')) if price_data else None
            intrinsic_value = None
            moat_grade = None
            try:
                if False:  # IMPROVED_MODULES_AVAILABLE: ì™¸ë¶€ ëª¨ë“ˆ ì—ëŸ¬ ë°©ì§€
                    # ì™¸ë¶€ ì² í•™ ëª¨ë“ˆì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                    try:
                        # ê°€ì¹˜íˆ¬ì ëª¨ë“ˆ í˜¸ì¶œ ì‹œ ì•ˆì „í•œ ì²˜ë¦¬
                        try:
                            bm = analyze_business_model(symbol)  # í•„ìš” ì‹œ ë‚´ë¶€ì ìœ¼ë¡œ KRX/ê³µì‹œ/ë©”íƒ€ í™œìš©
                            # bmì´ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                            if isinstance(bm, dict):
                                moat_grade = bm.get('moat_grade', None)
                            else:
                                moat_grade = None
                        except Exception as bm_error:
                            logging.warning(f"ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨, ë°±ì—… ë¡œì§ ì‚¬ìš©: {bm_error}")
                            bm = None
                            moat_grade = None
                        
                        try:
                            intrinsic_value = calculate_intrinsic_value(symbol, price_data=price_data, financial_data=financial_data)
                        except Exception as iv_error:
                            logging.debug(f"ë‚´ì¬ê°€ì¹˜ ê³„ì‚° ì‹¤íŒ¨: {iv_error}")
                            intrinsic_value = None
                    except Exception as e:
                        logging.warning(f"ê°€ì¹˜íˆ¬ì ëª¨ë“ˆ í˜¸ì¶œ ì‹¤íŒ¨, ë°±ì—… ë¡œì§ ì‚¬ìš©: {e}")
                        # ë°±ì—… ë¡œì§ìœ¼ë¡œ ë„˜ì–´ê°
                        bm = None
                        intrinsic_value = None
                        moat_grade = None
                else:
                    # ë°±ì—… ë¡œì§ìœ¼ë¡œ ë„˜ì–´ê°
                    bm = None
                    intrinsic_value = None
                    moat_grade = None
                
                # ë°±ì—… ë¡œì§: ë³´ìˆ˜ì  ê·¸ë ˆì´ì—„ì‹ ê³„ì‚°
                if intrinsic_value is None:
                    eps = DataValidator.safe_float_optional(price_data.get('eps') if price_data else None)
                    g = DataValidator.safe_float_optional(financial_data.get('revenue_growth_rate') if financial_data else None)
                    g = 0.0 if g is None else max(-5.0, min(15.0, g))  # ë³´ìˆ˜ì  ìº¡
                    Y = 6.0  # ì¥ê¸° ë¬´ìœ„í—˜ìˆ˜ìµë¥  ê·¼ì‚¬(%) ë³´ìˆ˜ì 
                    if eps and eps > 0:
                        intrinsic_value = eps * (8.5 + 2 * (g/1.0)) * 4.4 / max(1.0, Y)
            except Exception as e:
                logging.warning(f"ê°€ì¹˜íˆ¬ì ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                intrinsic_value = None
                moat_grade = None
            
            # ì™¸ë¶€ ì œê³µ ì—†ìœ¼ë©´ ë³´ìˆ˜ì  ì¶”ì • ì‹œë„
            if intrinsic_value is None:
                intrinsic_value = self._estimate_intrinsic_value(symbol, financial_data, price_data)

            # í•´ì(ì§ˆ) ì ìˆ˜/ë“±ê¸‰ ê³„ì‚°
            moat_quality = self.score_calculator._moat_quality_score(financial_data)
            moat_grade = self.score_calculator._moat_grade_from_score(moat_quality)

            # ì•ˆì „ë§ˆì§„ ê³„ì‚°
            mos = None
            if intrinsic_value and current_price and intrinsic_value > 0:
                mos = max(0.0, min(1.0, (intrinsic_value - current_price) / intrinsic_value))
            
            # ì„¹í„° ë¶„ì„ ìˆ˜í–‰ (ì¤‘ë³µ í˜ì¹˜ ë°©ì§€)
            sector_analysis = self._analyze_sector(symbol, name, price_data=price_data, financial_data=financial_data)
            
            # í†µí•© ì ìˆ˜ ê³„ì‚°
            analysis_data = {
                'opinion_analysis': opinion_analysis,
                'estimate_analysis': estimate_analysis,
                'financial_data': financial_data,
                'market_cap': market_cap,
                'current_price': price_data.get('current_price', 0),
                'price_position': self._calculate_price_position(price_data),
                'sector_info': self._get_sector_characteristics(symbol),
                'sector_analysis': sector_analysis,
                'price_data': price_data,
                'intrinsic_value': intrinsic_value,
            }
            
            # ìŠ¤ì½”ì–´ëŸ¬ì— ëª…ì‹œì  íŒŒë¼ë¯¸í„° ì „ë‹¬ (ìˆœìˆ˜ í•¨ìˆ˜)
            enhanced_score, all_breakdown = self.score_calculator.calculate_score(
                analysis_data, 
                sector_info=analysis_data['sector_info'], 
                price_data=analysis_data['price_data']
            )
            enhanced_grade = self._get_grade(enhanced_score)
            
            # breakdown ë¶„ë¦¬ (ê°€ì¤‘ì¹˜ ì ìš©ëœ ì ìˆ˜ì™€ ì›ì ìˆ˜ ë¶„ë¦¬)
            score_breakdown = {k: v for k, v in all_breakdown.items() if not k.endswith('_raw')}
            raw_breakdown = {k: v for k, v in all_breakdown.items() if k.endswith('_raw')}
            
            # ì›Œì¹˜ë¦¬ìŠ¤íŠ¸ ì‹œê·¸ë„ ë° ëª©í‘œë§¤ìˆ˜ê°€ ê³„ì‚° (enhanced_score ê³„ì‚° í›„)
            watchlist_signal, target_buy = self._compute_watchlist_signal(
                symbol=symbol,
                current_price=current_price,
                intrinsic_value=intrinsic_value,
                quality_score=moat_quality,
                price_position=self._calculate_price_position(price_data),
                overall_score=enhanced_score,  # ì¢…í•© ì ìˆ˜ ì „ë‹¬
            )
            
            # ê¸°ì¡´ í†µí•© ë¶„ì„
            integrated_analysis = create_integrated_analysis(opinion_analysis, estimate_analysis)
            
            return AnalysisResult(
                symbol=symbol,
                name=name,
                status=AnalysisStatus.SUCCESS,
                enhanced_score=enhanced_score,
                enhanced_grade=enhanced_grade,
                market_cap=market_cap,
                current_price=price_data.get('current_price', 0),
                price_position=analysis_data['price_position'],
                price_band_outside=self._is_price_outside_52w_band(price_data),  # 52ì£¼ ë°´ë“œ ë°– ì—¬ë¶€
                financial_data=financial_data,
                opinion_analysis=opinion_analysis,
                estimate_analysis=estimate_analysis,
                integrated_analysis=integrated_analysis,
                score_breakdown=score_breakdown,
                raw_breakdown=raw_breakdown,
                price_data=price_data,  # ê°€ê²© ë°ì´í„° ìºì‹±
                sector_analysis=sector_analysis,  # ì„¹í„° ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                intrinsic_value=intrinsic_value,
                margin_of_safety=mos,
                moat_grade=moat_grade,
                watchlist_signal=watchlist_signal,
                target_buy=target_buy,
                playbook=self._value_investing_playbook(symbol, intrinsic_value, target_buy, moat_grade),
            )
            
        except Exception as e:
            log_error("ì¢…ëª© ë¶„ì„", f"{name}({symbol})", e, "error")
            return AnalysisResult(
                symbol=symbol,
                name=name,
                status=AnalysisStatus.ERROR,
                error=str(e)
            )
        finally:
            # ë¶„ì„ ì†Œìš” ì‹œê°„ ê¸°ë¡
            if hasattr(self, "metrics") and self.metrics:
                self.metrics.record_analysis_duration(_monotonic() - start_time)
    
    def analyze_with_value_philosophy(self, symbol: str, name: str) -> Dict[str, Any]:
        """ê°€ì¹˜ íˆ¬ì ì² í•™ ê¸°ë°˜ ì¢…í•© ë¶„ì„"""
        try:
            # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
            basic_result = self.analyze_single_stock(symbol, name)
            
            if basic_result.status != AnalysisStatus.SUCCESS:
                return {
                    'success': False,
                    'error': basic_result.error,
                    'basic_result': basic_result
                }
            
            # ê°€ì¹˜ íˆ¬ì ì² í•™ ë¶„ì„
            if IMPROVED_MODULES_AVAILABLE and hasattr(self, 'value_investing'):
                # ê´€ì‹¬ ì¢…ëª© ëª©ë¡ì— ì¶”ê°€
                stock_data = {
                    'symbol': symbol,
                    'name': name,
                    'current_price': basic_result.current_price,
                    'market_cap': basic_result.market_cap,
                    'price_data': basic_result.price_data,
                    'financial_data': basic_result.financial_data,
                    'sector_analysis': basic_result.sector_analysis
                }
                
                watchlist_item = self.value_investing.add_to_watchlist(symbol, name, stock_data)
                
                # ê°€ì¹˜ íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„±
                value_report = self.value_investing.generate_investment_report(symbol)
                
                return {
                    'success': True,
                    'basic_result': basic_result,
                    'value_analysis': watchlist_item,
                    'value_report': value_report,
                    'buy_signal': watchlist_item.margin_of_safety.safety_level.value in ['ìš°ìˆ˜', 'ì–‘í˜¸']
                }
            else:
                return {
                    'success': True,
                    'basic_result': basic_result,
                    'value_analysis': None,
                    'value_report': "ê°€ì¹˜ íˆ¬ì ì² í•™ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'buy_signal': False
                }
                
        except Exception as e:
            logger.error(f"ê°€ì¹˜ íˆ¬ì ì² í•™ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'basic_result': None
            }
    
    def _is_preferred_stock(self, name: str) -> bool:
        """ìš°ì„ ì£¼ ì—¬ë¶€ í™•ì¸"""
        return DataValidator.is_preferred_stock(name)
    
    def _analyze_opinion(self, symbol: str, days_back: int, name: str = "") -> Dict[str, Any]:
        """íˆ¬ìì˜ê²¬ ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ ë³´ê°•)"""
        if not self.include_external:
            return {}
        try:
            with self._opinion_lock:
                cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                return _with_retries(
                    lambda: self.opinion_analyzer.analyze_single_stock(symbol, days_back=days_back),
                    metrics_attempt=cb_attempt,
                    metrics_final=cb_final
                )
        except Exception as e:
            # _with_retriesê°€ ìµœì¢… ì‹¤íŒ¨ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìŒ. ì—¬ê¸°ì„  ë¡œê·¸ë§Œ.
            log_error("íˆ¬ìì˜ê²¬ ë¶„ì„", f"{symbol}({name})", e)
            return {}
    
    def _analyze_estimate(self, symbol: str, name: str = "") -> Dict[str, Any]:
        """ì¶”ì •ì‹¤ì  ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ ë³´ê°•)"""
        if not self.include_external:
            return {}
        try:
            with self._estimate_lock:
                cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                return _with_retries(
                    lambda: self.estimate_analyzer.analyze_single_stock(symbol),
                    metrics_attempt=cb_attempt,
                    metrics_final=cb_final
                )
        except Exception as e:
            # _with_retriesê°€ ìµœì¢… ì‹¤íŒ¨ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìŒ. ì—¬ê¸°ì„  ë¡œê·¸ë§Œ.
            log_error("ì¶”ì •ì‹¤ì  ë¶„ì„", f"{symbol}({name})", e)
            return {}
    
    def _analyze_sector(self, symbol: str, name: str = "", *, price_data: Dict[str, Any] = None, financial_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì„¹í„° ë¶„ì„ ìˆ˜í–‰ (ì¤‘ë³µ í˜ì¹˜ ë°©ì§€)"""
        try:
            # --- ê³µìš© í—¬í¼ë¥¼ í•¨ìˆ˜ ìƒë‹¨ì— ì •ì˜ (ìŠ¤ì½”í”„ ë²„ê·¸ ë°©ì§€) ---
            def _delta(score_0_100, weight):
                # 0~100 â†’ -50~+50 ë¡œ ë°”ê¾¼ ë’¤ weight%ë¥¼ ê³±í•´ì„œ ê°€/ê°ì 
                s = 0.0 if score_0_100 is None else max(0.0, min(100.0, float(score_0_100)))
                return (s - 50.0) * (weight / 100.0)
            # --------------------------------------------------------------------

            # ê¸°ë³¸ ì„¹í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            sector_info = self._get_sector_characteristics(symbol)
            sector_name = sector_info.get('name', 'ê¸°íƒ€')
            
            # ì „ë‹¬ë°›ì€ ë°ì´í„° ì‚¬ìš© ë˜ëŠ” ìƒˆë¡œ í˜ì¹˜
            price_data = price_data or self.data_provider.get_price_data(symbol)
            financial_data = financial_data or self.data_provider.get_financial_data(symbol)
            
            if not price_data or not financial_data:
                return {'grade': 'C', 'total_score': 50.0,
                        'breakdown': {'ì¬ë¬´_ê±´ì „ì„±': 50.0, 'ì„±ì¥ì„±': 50.0, 'ì•ˆì •ì„±': 50.0},
                        'is_leader': False, 'leader_bonus': 0.0}
            
            # PER, PBR, ROE ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (ê²°ì¸¡=0ìœ¼ë¡œ ì˜¤ì—¼ ë°©ì§€: safe_float_optional ì‚¬ìš©)
            per = DataValidator.safe_float_optional(price_data.get('per'))
            pbr = DataValidator.safe_float_optional(price_data.get('pbr'))
            roe = DataValidator.safe_float_optional(financial_data.get('roe'))
            market_cap_pd = normalize_market_cap_ekwon(DataValidator.safe_float_optional(price_data.get('market_cap', 0)))
            
            # ì„¹í„° ë°±ë¶„ìœ„ ê¸°ë°˜ ìŠ¤ì½”ì–´ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ê¸°ì¡´ ì„ í˜• ë§¤í•‘ ì‚¬ìš©
            sector_val = self._evaluate_valuation_by_sector(
                symbol,
                per=per if per is not None else float('nan'),
                pbr=pbr if pbr is not None else float('nan'),
                roe=roe if roe is not None else float('nan'),
                market_cap=market_cap_pd,
                price_data=price_data,
                financial_data=financial_data
            )
            
            # ì¬ë¬´_ê±´ì „ì„± ì ìˆ˜
            if sector_val and sector_val.get('total_score') is not None:
                financial_score = float(sector_val['total_score'])
            else:
                # ì„¹í„° ë°ì´í„° ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ë°˜í™˜í•˜ì—¬ ìƒìœ„ half-weight ë¡œì§ í•œ ë²ˆë§Œ ì ìš©
                financial_score = None

            # ì„±ì¥ì„± ì ìˆ˜ (ROE ê¸°ë°˜ ê°€/ê°ì )
            growth_score = 50.0
            if roe is not None and roe > 0:
                roe_score = self._calculate_metric_score(roe, min_val=5, max_val=20, reverse=False)
                if roe_score is not None:
                    growth_score += _delta(roe_score, 25)

            # ì•ˆì •ì„± ì ìˆ˜ (ì‹œì´ ê¸°ë°˜ ê°€/ê°ì )
            stability_score = 50.0
            market_cap_file = self._get_market_cap(symbol)  # ì–µì› ë‹¨ìœ„(íŒŒì¼ ê¸°ì¤€)
            mc = market_cap_file if market_cap_file else (market_cap_pd or 0)
            if mc > 100000: stability_score += 20
            elif mc > 50000: stability_score += 10

            # ê° ìŠ¤ì½”ì–´/ìµœì¢… í´ë¨í”„ (None ì•ˆì „ ì²˜ë¦¬)
            def _clamp_0_100(x, default=50.0):
                """ê°’ì„ 0-100 ë²”ìœ„ë¡œ í´ë¨í”„í•˜ë˜, Noneì´ë©´ ê¸°ë³¸ê°’ ë°˜í™˜"""
                if x is None:
                    return default
                try:
                    return max(0.0, min(100.0, float(x)))
                except (ValueError, TypeError):
                    return default
            
            financial_score = _clamp_0_100(financial_score, 50.0)
            growth_score    = _clamp_0_100(growth_score, 50.0)
            stability_score = _clamp_0_100(stability_score, 50.0)
            total_score     = _clamp_0_100((financial_score + growth_score + stability_score) / 3.0, 50.0)
            
            # í‘œë³¸ìˆ˜ ë¶€ì¡± ì‹œ ì‹ ë¢°ë„ ë°˜ì˜ (ì„ í˜• ì¶•ì†Œ)
            confidence = 1.0
            try:
                peers = sector_val.get('peer_count', 0) if sector_val else 0
                target = self.env_cache.get('sector_target_good', 60)
                confidence = max(0.5, min(1.0, peers / max(1, target)))  # ìµœì†Œ 0.5
            except Exception:
                pass
            total_score *= confidence
            
            # ë“±ê¸‰ ê²°ì •
            if total_score >= 80:
                grade = 'A+'
            elif total_score >= 75:
                grade = 'A'
            elif total_score >= 70:
                grade = 'B+'
            elif total_score >= 65:
                grade = 'B'
            elif total_score >= 60:
                grade = 'C+'
            elif total_score >= 55:
                grade = 'C'
            else:
                grade = 'D'
            
            # ë¦¬ë” ë³´ë„ˆìŠ¤(0~10) ê³„ì‚°: ì´ì ì—ëŠ” ë°˜ì˜í•˜ì§€ ì•Šê³  ë³„ë„ ì œê³µ
            try:
                leader_bonus = self._calculate_leader_bonus(
                    symbol=symbol,
                    sector=sector_name,
                    market_cap=market_cap_pd,
                    price_data=price_data,
                    financial_data=financial_data
                )
            except Exception:
                leader_bonus = 0.0

            # í‰ë©´ ìŠ¤í‚¤ë§ˆë¡œ ë°˜í™˜ (ì •ê·œí™” í—¬í¼ì—ì„œ ê·¸ëŒ€ë¡œ ì†Œë¹„)
            return {
                'grade': grade,
                'total_score': float(total_score),
                'breakdown': {
                    'ì¬ë¬´_ê±´ì „ì„±': float(financial_score),
                    'ì„±ì¥ì„±': float(growth_score),
                    'ì•ˆì •ì„±': float(stability_score),
                },
                'is_leader': self._is_sector_leader(symbol, sector_name),
                'leader_bonus': float(leader_bonus)
            }
            
        except Exception as e:
            logging.debug(f"ì„¹í„° ë¶„ì„ ì‹¤íŒ¨ {symbol}: {e}")
            return {'grade': 'C', 'total_score': 50.0,
                    'breakdown': {'ì¬ë¬´_ê±´ì „ì„±': 50.0, 'ì„±ì¥ì„±': 50.0, 'ì•ˆì •ì„±': 50.0},
                    'is_leader': False, 'leader_bonus': 0.0}
    

    def _get_market_cap(self, symbol: str) -> Optional[float]:
        """ì‹œê°€ì´ì•¡ ì¡°íšŒ (ì–µì› ë‹¨ìœ„)
        
        Note: KOSPI íŒŒì¼ì˜ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ì€ ì–µì› ë‹¨ìœ„ë¡œ ê°€ì •í•©ë‹ˆë‹¤.
        ë‹¤ë¥¸ ë‹¨ìœ„(ì›/ë°±ë§Œ/ì‹­ì–µ)ì¸ ê²½ìš° ì¼ê´€ì„±ì„ ìœ„í•´ ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.
        """
        if self.kospi_data is not None and not self.kospi_data.empty:
            # ì¸ë±ìŠ¤ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ loc ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ì¡´ ë°©ì‹
            if _is_indexed_by_code(self.kospi_data):
                try:
                    stock_info = self.kospi_data.loc[[str(symbol)]]
                except KeyError:
                    stock_info = pd.DataFrame()
            else:
                stock_info = self.kospi_data[self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] == str(symbol)]
            if not stock_info.empty:
                mc = stock_info.iloc[0]['ì‹œê°€ì´ì•¡']
                if pd.isna(mc):
                    return None  # unknown market cap
                mc = float(mc)
                # ì•ˆì „ì¥ì¹˜: ì› ë‹¨ìœ„ë¡œ ë“¤ì–´ì˜¨ ê²½ìš° ì–µì›ìœ¼ë¡œ ë³€í™˜ (MARKET_CAP_STRICT_MODE ê³ ë ¤)
                strict_mode = _ENV_CACHE['market_cap_strict_mode'].lower() == "true"
                if mc > 1e11:  # 1ì¡°ì› ì´ìƒì´ë©´ ì› ë‹¨ìœ„ë¡œ ì˜¤ì¸ ê°€ëŠ¥ì„± ë†’ìŒ
                    if not strict_mode:
                        mc = mc / 1e8  # ì–µì› ë³€í™˜
                        logging.debug(f"[unit] KOSPI market_cap unit correction: {stock_info.iloc[0]['ì‹œê°€ì´ì•¡']} -> {mc} ì–µì›")
                    else:
                        logging.debug(f"[unit] KOSPI market_cap ambiguous (strict mode): {stock_info.iloc[0]['ì‹œê°€ì´ì•¡']} -> None")
                        return None
                return mc
        return None
    
    def _calculate_price_position(self, price_data: Dict[str, Any]) -> Optional[float]:
        """52ì£¼ ìœ„ì¹˜ ê³„ì‚° (NaN/0-division ë°©ì§€, ë°´ë“œ ë°–ë„ í´ë¨í”„)"""
        cp = DataValidator.safe_float_optional(price_data.get('current_price'))
        hi = DataValidator.safe_float_optional(price_data.get('w52_high'))
        lo = DataValidator.safe_float_optional(price_data.get('w52_low'))
        
        if cp is None or hi is None or lo is None:
            logging.debug("Missing 52w inputs for price position")
            return None
        if not (cp > 0 and hi > 0 and lo > 0):
            return None
        band = hi - lo
        # âœ… 52ì£¼ ë°´ë“œ ì„ê³„ì¹˜ í™˜ê²½ë³€ìˆ˜í™” (ê¸°ë³¸ 0.1%)
        tiny_band_threshold = safe_env_float("POS_TINY_BAND_THRESHOLD", 0.001, 0.0)  # 0.1%
        
        # ìƒëŒ€Â·ì ˆëŒ€ ë™ì‹œ ì²´í¬ë¡œ float ì˜¤ì°¨ ë° ê·¹ë¯¸/í‡´í™” ì¼€ì´ìŠ¤ ë°©ì§€
        if band <= 0:
            logging.debug(f"Non-positive 52w band: hi={hi}, lo={lo}, cp={cp}")
            # í‡´í™” ì¼€ì´ìŠ¤ ë©”íŠ¸ë¦­ ê¸°ë¡ (ìš´ì˜ ëª¨ë‹ˆí„°ë§ìš©) â€“ API ì‹¤íŒ¨ë¡œ ì§‘ê³„í•˜ì§€ ì•ŠìŒ
            if self.metrics:
                self.metrics.record_flag_error(f"{ErrorType.INVALID_52W_BAND}:nonpos_band")
            return None
        elif band/hi <= tiny_band_threshold or band <= 1e-6:
            logging.debug(f"Tiny 52w band: hi={hi}, lo={lo}, cp={cp}")
            # í‡´í™” ì¼€ì´ìŠ¤ ë©”íŠ¸ë¦­ ê¸°ë¡ (ìš´ì˜ ëª¨ë‹ˆí„°ë§ìš©) â€“ API ì‹¤íŒ¨ë¡œ ì§‘ê³„í•˜ì§€ ì•ŠìŒ
            if self.metrics:
                self.metrics.record_flag_error(f"{ErrorType.INVALID_52W_BAND}:tiny_band")
            return None
        
        raw = (cp - lo) / band * 100.0
        return max(0.0, min(100.0, raw))
    
    def _is_price_outside_52w_band(self, price_data: Dict[str, Any]) -> bool:
        """í˜„ì¬ê°€ê°€ 52ì£¼ ë°´ë“œ ë°–ì¸ì§€ í™•ì¸ (UI ê²½ê³ ìš©)"""
        cp = DataValidator.safe_float_optional(price_data.get('current_price'))
        hi = DataValidator.safe_float_optional(price_data.get('w52_high'))
        lo = DataValidator.safe_float_optional(price_data.get('w52_low'))
        
        if cp is None or hi is None or lo is None or not (cp > 0 and hi > 0 and lo > 0):
            return False
        return cp < lo or cp > hi
    
    def _analyze_profit_trend(self, financial_data: Dict[str, Any]) -> str:
        """ì´ìµë¥  ì¶”ì„¸ ë¶„ì„ (ì¤‘ë³µ API í˜¸ì¶œ ì œê±°)"""
        try:
            if not financial_data:
                return "unknown"
            current_roe = DataValidator.safe_float(financial_data.get('roe', 0))
            if current_roe <= 0:
                return "unknown"
            return "stable"
        except Exception as e:
            log_error("ì´ìµë¥  ì¶”ì„¸ ë¶„ì„", error=e)
            return "unknown"
    
    def _get_sector_characteristics(self, symbol: str) -> Dict[str, Any]:
        """ì—…ì¢…ë³„ íŠ¹ì„± ì •ë³´ ë°˜í™˜ (ìºì‹œ ì ìš©)"""
        now = _monotonic()
        
        # ìºì‹œ í™•ì¸ (ì„¹í„°ëª… ê¸°ì¤€ ìºì‹œ ìš°ì„  ì‹œë„)
        with self._sector_char_cache_lock:
            # 1) ì‹¬ë³¼â†’ì„¹í„°ëª… ìºì‹œ (ì–•ì€ ìºì‹œ) - ì¼ê´€ì„±ì„ ìœ„í•´ str(symbol) ì‚¬ìš©
            sym_hit = self._sector_char_cache.get(f"sym:{str(symbol)}")
            if sym_hit and now - sym_hit[0] < self._sector_char_cache_ttl:
                sector = sym_hit[1]['name']
                sec_hit = self._sector_char_cache.get(f"sec:{sector}")
                if sec_hit and now - sec_hit[0] < self._sector_char_cache_ttl:
                    return sec_hit[1]
            
            # ë ˆê±°ì‹œ í‚¤ ê²½ë¡œ ì œê±°: ëª¨ë“  ìºì‹œëŠ” 'sym:'/'sec:' ì ‘ë‘ ì‚¬ìš©
        
        try:
            # í•˜ë“œì½”ë”©ëœ ì—…ì¢… ë§¤í•‘ (ìš°ì„  ì ìš©)
            sector_mapping = {
                '005930': 'ê¸°ìˆ ì—…',  # ì‚¼ì„±ì „ì
                '000660': 'ê¸°ìˆ ì—…',  # SKí•˜ì´ë‹‰ìŠ¤
                '207940': 'ë°”ì´ì˜¤/ì œì•½',  # ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤
                '000270': 'ì œì¡°ì—…',  # ê¸°ì•„
                '329180': 'ì œì¡°ì—…',  # HDí˜„ëŒ€ì¤‘ê³µì—…
                '105560': 'ê¸ˆìœµì—…',  # KBê¸ˆìœµ
                '005380': 'ì œì¡°ì—…',  # í˜„ëŒ€ì°¨
                '012330': 'ì œì¡°ì—…',  # í˜„ëŒ€ëª¨ë¹„ìŠ¤
                '035420': 'ê¸°ìˆ ì—…',  # NAVER
                '035720': 'ê¸°ìˆ ì—…',  # ì¹´ì¹´ì˜¤
            }
            
            result = None
            
            # í•˜ë“œì½”ë”©ëœ ë§¤í•‘ì—ì„œ ë¨¼ì € ì°¾ê¸°
            if str(symbol) in sector_mapping:
                sector = sector_mapping[str(symbol)]
                result = self._get_sector_benchmarks(sector)
            else:
                # KOSPI ë°ì´í„°ì—ì„œ ì—…ì¢… ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì—¬ëŸ¬ ì»¬ëŸ¼ í›„ë³´ í™•ì¸)
                if hasattr(self, 'kospi_data') and not self.kospi_data.empty:
                    # ì¸ë±ìŠ¤ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ loc ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ì¡´ ë°©ì‹
                    if _is_indexed_by_code(self.kospi_data):
                        try:
                            stock_info = self.kospi_data.loc[[str(symbol)]]
                        except KeyError:
                            stock_info = pd.DataFrame()
                    else:
                        stock_info = self.kospi_data[self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] == str(symbol)]
                    if not stock_info.empty:
                        for col in ('ì—…ì¢…', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì—…ì¢…ëª…', 'ì„¹í„°'):
                            if col in stock_info.columns:
                                sector = str(stock_info.iloc[0].get(col) or 'ê¸°íƒ€')
                                if sector and sector != 'ê¸°íƒ€':
                                    result = self._get_sector_benchmarks(sector)
                                    break
                
                if result is None:
                    # ìš´ì˜ ì•ˆì „ì„ ìœ„í•œ ê°•ì œ í´ë°± ì˜µì…˜
                    force_fallback = os.getenv("SECTOR_FORCE_FALLBACK", "false").lower() == "true"
                    if force_fallback:
                        logging.warning(f"ì„¹í„° ì •ë³´ ì—†ìŒ, ê°•ì œ í´ë°± ì ìš©: {symbol}")
                    result = self._get_sector_benchmarks('ê¸°íƒ€')
            
            # ìºì‹œì— ì €ì¥ (ì„¹í„°ëª… ê¸°ì¤€ ìºì‹œ + ì‹¬ë³¼â†’ì„¹í„°ëª… ë§¤í•‘)
            with self._sector_char_cache_lock:
                sector = str(result.get('name', 'ê¸°íƒ€')).strip()  # âœ… ì„¹í„°ëª… ì •ê·œí™”
                sym_key = str(symbol).strip()  # âœ… ì‹¬ë³¼ í‚¤ ë¬¸ìì—´í™” ë° ì •ê·œí™”
                self._sector_char_cache[f"sym:{sym_key}"] = (now, {"name": sector})
                self._sector_char_cache[f"sec:{sector}"] = (now, result)
                # âœ… ë ˆê±°ì‹œ í‚¤ ì œê±°: ì¶©ëŒ ë°©ì§€ ë° ìºì‹œ í¬ê¸° ìµœì í™”
                # ìºì‹œ í¬ê¸° ì œí•œ (LRU ë°©ì‹) - ì•ˆì „í•œ ë‹¨ì¼ pop ë°©ì‹
                while len(self._sector_char_cache) > self._sector_char_cache_max_size:
                    self._sector_char_cache.popitem(last=False)
            
            return result
            
        except Exception as e:
            log_error("ì—…ì¢… íŠ¹ì„± ë¶„ì„", symbol, e)
            result = self._get_sector_benchmarks('ê¸°íƒ€')
            # ì—ëŸ¬ ì¼€ì´ìŠ¤ë„ ìºì‹œì— ì €ì¥ (ì§§ì€ TTL ìœ ì‚¬ íš¨ê³¼ë¥¼ ìœ„í•´ 'now' ë³´ì •)
            now = _monotonic()
            with self._sector_char_cache_lock:
                sector = result.get('name', 'ê¸°íƒ€')
                sym_key = str(symbol)  # âœ… ì‹¬ë³¼ í‚¤ ë¬¸ìì—´í™”: íƒ€ì… ì•ˆì „ì„± ë³´ì¥ (sym:, sec: í‚¤ë§Œ ì‚¬ìš©)
                self._sector_char_cache[f"sym:{sym_key}"] = (now, {"name": sector})
                self._sector_char_cache[f"sec:{sector}"] = (now, result)
                # âœ… ë ˆê±°ì‹œ í‚¤ ì œê±°: ì¶©ëŒ ë°©ì§€ ë° ìºì‹œ í¬ê¸° ìµœì í™”
            return result
    
    def _sanitize_leaders(self, leaders):
        """ì„¹í„° ë¦¬ë” ëª©ë¡ ì •í•©ì„± ê²€ì¦ (KOSPI ë°ì´í„° ê¸°ì¤€)"""
        if self.kospi_data is None or self.kospi_data.empty:
            return leaders
        
        # ì¸ë±ìŠ¤ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©, ì•„ë‹ˆë©´ ì»¬ëŸ¼ ì‚¬ìš©
        if _is_indexed_by_code(self.kospi_data):
            codes = set(self.kospi_data.index.astype(str))
        else:
            codes = set(self.kospi_data['ë‹¨ì¶•ì½”ë“œ'].astype(str))
        return [c for c in leaders if c in codes]
    
    def _get_sector_benchmarks(self, sector: str) -> Dict[str, Any]:
        """ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€ ë°˜í™˜"""
        SECTOR_ALIASES = {
            'it': 'ê¸°ìˆ ì—…', 'ì •ë³´ê¸°ìˆ ': 'ê¸°ìˆ ì—…', 'ì†Œí”„íŠ¸ì›¨ì–´': 'ê¸°ìˆ ì—…',
            'ë°”ì´ì˜¤': 'ë°”ì´ì˜¤/ì œì•½', 'ì œì•½': 'ë°”ì´ì˜¤/ì œì•½', 'ìƒëª…ê³¼í•™': 'ë°”ì´ì˜¤/ì œì•½',
            'ìë™ì°¨': 'ì œì¡°ì—…', 'ì „ì': 'ì œì¡°ì—…', 'í™”í•™': 'ì œì¡°ì—…',
            'ì€í–‰': 'ê¸ˆìœµì—…', 'ì¦ê¶Œ': 'ê¸ˆìœµì—…', 'ë³´í—˜': 'ê¸ˆìœµì—…',
            'ê±´ì„¤': 'ê±´ì„¤ì—…', 'ë¶€ë™ì‚°': 'ê±´ì„¤ì—…',
            'ìœ í†µ': 'ì†Œë¹„ì¬', 'ì‹í’ˆ': 'ì†Œë¹„ì¬', 'ì˜ë¥˜': 'ì†Œë¹„ì¬',
            'ì—ë„ˆì§€': 'ì—ë„ˆì§€/í™”í•™', 'ì„ìœ ': 'ì—ë„ˆì§€/í™”í•™',
            'í†µì‹ ': 'í†µì‹ ì—…', 'ë¯¸ë””ì–´': 'í†µì‹ ì—…'
        }
        normalized_sector = SECTOR_ALIASES.get(str(sector).lower(), str(sector)) if sector else "ê¸°íƒ€"

        benchmarks = {
            'ê¸ˆìœµì—…': {
                'per_range': (5, 15), 'pbr_range': (0.5, 2.0), 'roe_range': (8, 20),
                'description': 'ì•ˆì •ì  ìˆ˜ìµì„±, ë‚®ì€ PBR',
                'leaders': ['105560', '055550', '086790']
            },
            'ê¸°ìˆ ì—…': {
                'per_range': (15, 50), 'pbr_range': (1.5, 8.0), 'roe_range': (10, 30),
                'description': 'ë†’ì€ ì„±ì¥ì„±, ë†’ì€ PER',
                'leaders': ['005930', '000660', '035420', '035720']
            },
            'ì œì¡°ì—…': {
                'per_range': (8, 25), 'pbr_range': (0.8, 3.0), 'roe_range': (8, 20),
                'description': 'ì•ˆì •ì  ìˆ˜ìµì„±, ì ì • PER',
                'leaders': ['005380', '000270', '012330', '329180']
            },
            'ë°”ì´ì˜¤/ì œì•½': {
                'per_range': (20, 100), 'pbr_range': (2.0, 10.0), 'roe_range': (5, 25),
                'description': 'ë†’ì€ ë¶ˆí™•ì‹¤ì„±, ë†’ì€ PER',
                'leaders': ['207940', '068270', '006280']
            },
            'ì—ë„ˆì§€/í™”í•™': {
                'per_range': (5, 20), 'pbr_range': (0.5, 2.5), 'roe_range': (5, 15),
                'description': 'ì‚¬ì´í´ íŠ¹ì„±, ë³€ë™ì„± í° ìˆ˜ìµ',
                'leaders': ['034020', '010140']
            },
            'ì†Œë¹„ì¬': {
                'per_range': (10, 30), 'pbr_range': (1.0, 4.0), 'roe_range': (8, 18),
                'description': 'ì•ˆì •ì  ìˆ˜ìš”, ì ì • ìˆ˜ìµì„±',
                'leaders': []
            },
            'í†µì‹ ì—…': {
                'per_range': (8, 20), 'pbr_range': (0.8, 3.0), 'roe_range': (6, 15),
                'description': 'í˜„ê¸ˆíë¦„ ì•ˆì •',
                'leaders': ['017670']
            },
            'ê±´ì„¤ì—…': {
                'per_range': (5, 15), 'pbr_range': (0.5, 2.0), 'roe_range': (5, 12),
                'description': 'ì‚¬ì´í´ ë¯¼ê°, ë³´ìˆ˜ì  ë°¸ë¥˜ì—ì´ì…˜',
                'leaders': ['000720', '051600']
            },
            'ê¸°íƒ€': {
                'per_range': (5, 40), 'pbr_range': (0.5, 6.0), 'roe_range': (5, 20),
                'description': 'ì¼ë°˜ì  ê¸°ì¤€ (í´ë°±)',
                'leaders': []
            }
        }

        entry = benchmarks.get(normalized_sector, benchmarks['ê¸°íƒ€'])
        # ë¦¬ë” ëª©ë¡ ì •í•©ì„± ë³´ì •
        entry = dict(entry)
        entry['leaders'] = self._sanitize_leaders(entry.get('leaders', []))
        entry['name'] = normalized_sector
        return entry
    
    def _is_sector_leader(self, symbol: str, sector_name: str) -> bool:
        """ì‹¬ë³¼ì´ ì„¹í„° ë¦¬ë” í›„ë³´ì— ì†í•˜ëŠ”ì§€ íŒë‹¨."""
        try:
            bm = self._get_sector_benchmarks(sector_name)
            leaders = set(bm.get('leaders') or [])
            return str(symbol) in leaders
        except Exception:
            return False
    
    def _calculate_leader_bonus(self, *, symbol: str, sector: str, market_cap: Optional[float], price_data: Dict[str, Any], financial_data: Dict[str, Any]) -> float:
        """ì„¹í„° ë¦¬ë”ì‹­ ë³´ë„ˆìŠ¤ 0~10. ë¦¬ë” ì—¬ë¶€/ì‹œì´/ê°€ê²©ìœ„ì¹˜ ì»¨í…ìŠ¤íŠ¸ ë°˜ì˜."""
        bonus = 0.0
        try:
            if self._is_sector_leader(symbol, sector):
                bonus += 5.0
            mc = market_cap or self._get_market_cap(symbol) or 0.0
            if mc >= 100000:   # ë©”ê°€ìº¡
                bonus += 3.0
            elif mc >= 50000:  # ë¼ì§€ìº¡
                bonus += 2.0
            # ê°€ê²©ìœ„ì¹˜(ì €ìœ„ì¹˜ì¼ìˆ˜ë¡ ê°€ì ) ì•½ê°„ ë°˜ì˜
            pp = self._calculate_price_position(price_data) if price_data else None
            if pp is not None and pp <= 30:
                bonus += 2.0
        except Exception:
            pass
        return max(0.0, min(10.0, bonus))
    
    def _evaluate_valuation_by_sector(
        self,
        symbol: str,
        *,
        per: float = float('nan'),
        pbr: float = float('nan'),
        roe: float = float('nan'),
        market_cap: Optional[float],
        price_data: Dict[str, Any],
        financial_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì„¹í„° í”¼ì–´ ê¸°ë°˜ ë°¸ë¥˜ì—ì´ì…˜ í‰ê°€:
        - ê¸°ë³¸: (PER, PBR, ROE) ê°ê° ì„¹í„° ê¸°ì¤€ë²”ìœ„ì— ì„ í˜• ë§¤í•‘ â†’ ê°€ì¤‘ í‰ê· 
        - ë°ì´í„° ë¶€ì¡±/ê²°ì¸¡ ì‹œ ë³´ìˆ˜ì  ê¸°ë³¸ì¹˜ ì‚¬ìš©(50) + metricsì— ìƒ˜í”Œ ë¶€ì¡± ì§‘ê³„
        """
        bm = self._get_sector_benchmarks(self._get_sector_characteristics(symbol).get('name', 'ê¸°íƒ€'))
        per_lo, per_hi   = bm['per_range']
        pbr_lo, pbr_hi   = bm['pbr_range']
        roe_lo, roe_hi   = bm['roe_range']

        # ìŠ¤ì½”ì–´ ê°œë³„ ê³„ì‚° (ê²°ì¸¡ì€ None)
        per_s = self._calculate_metric_score(per, min_val=per_lo, max_val=per_hi, reverse=True)
        pbr_s = self._calculate_metric_score(pbr, min_val=pbr_lo, max_val=pbr_hi, reverse=True)
        roe_s = self._calculate_metric_score(roe, min_val=roe_lo, max_val=roe_hi, reverse=False)

        # ê°€ì¤‘ì¹˜: ROE 0.4, PER 0.35, PBR 0.25 (í•©=1)
        parts, weights = [], []
        if per_s is not None: parts.append(per_s); weights.append(0.35)
        if pbr_s is not None: parts.append(pbr_s); weights.append(0.25)
        if roe_s is not None: parts.append(roe_s); weights.append(0.40)

        if not parts:
            # í”¼ì–´/ì…ë ¥ ê²°ì¸¡ â†’ ë³´ìˆ˜ì  ê¸°ë³¸ê°’
            if hasattr(self, "metrics") and self.metrics:
                self.metrics.record_sector_sample_insufficient(sector_name=bm.get('description', 'unknown'))
            total = 50.0
        else:
            wsum = sum(weights) or 1.0
            total = sum(s * (w / wsum) for s, w in zip(parts, weights))

        # ë¸Œë ˆì´í¬ë‹¤ìš´ (ê²°ì¸¡ì€ 50ìœ¼ë¡œ í‘œê¸°í•´ UIê°€ ìì—°ìŠ¤ëŸ½ë„ë¡)
        breakdown = {
            'PER': 50.0 if per_s is None else float(per_s),
            'PBR': 50.0 if pbr_s is None else float(pbr_s),
            'ROE': 50.0 if roe_s is None else float(roe_s),
        }
        grade = 'A+' if total >= 85 else 'A' if total >= 75 else 'B+' if total >= 70 else \
                'B' if total >= 65 else 'C+' if total >= 60 else 'C' if total >= 55 else 'D'
        return {'total_score': float(max(0.0, min(100.0, total))), 'grade': grade, 'breakdown': breakdown}
    
    def _calculate_metric_score(self, value: Optional[float], *, min_val: float, max_val: float, reverse: bool=False) -> Optional[float]:
        """ì—°ì†ê°’ì„ 0~100ìœ¼ë¡œ ì„ í˜• ë§¤í•‘. reverse=Trueë©´ ë‚®ì„ìˆ˜ë¡ ê³ ë“ì ."""
        return self._score_linear(value, min_val=min_val, max_val=max_val, reverse=reverse)
    
    def _score_linear(self, x: Optional[float], *, min_val: float, max_val: float, reverse: bool=False) -> Optional[float]:
        """ì•ˆì „í•œ ì„ í˜• ìŠ¤ì½”ì–´ë§ í—¬í¼"""
        if x is None: 
            return None
        try:
            v = float(x)
        except Exception:
            return None
        lo, hi = (min_val, max_val) if not reverse else (max_val, min_val)
        if hi == lo: 
            return None
        t = (v - lo) / (hi - lo)
        t = max(0.0, min(1.0, t))
        return t * 100.0
    
    def _get_grade(self, score: float) -> str:
        """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        thresholds = self.config.grade_thresholds
        
        if score >= thresholds.get('A_plus', 80):
            return 'A+'
        elif score >= thresholds.get('A', 70):
            return 'A'
        elif score >= thresholds.get('B_plus', 60):
            return 'B+'
        elif score >= thresholds.get('B', 50):
            return 'B'
        elif score >= thresholds.get('C_plus', 40):
            return 'C+'
        elif score >= thresholds.get('C', 30):
            return 'C'
        elif score >= thresholds.get('D_plus', 20):
            return 'D+'
        elif score >= thresholds.get('D', 10):
            return 'D'
        else:
            return 'F'
    
    def _resolve_price_and_position(self, stock_dict):
        """ê°€ê²©Â·52ì£¼ ì •ë³´ ê³„ì‚° ê²½ë¡œ í†µí•© í—¬í¼"""
        def _pick_price(d):
            if not d:
                return {}
            # dictì´ë©´ ê·¸ëŒ€ë¡œ, ê°ì²´ì´ë©´ price_data ìš°ì„  ì ‘ê·¼
            if isinstance(d, dict):
                return d.get('price_data', d) or {}
            return getattr(d, 'price_data', {}) or {}
        
        # 1) enhanced(price_data) -> 2) basic(price_data) -> 3) (í•„ìš” ì‹œ) ì‹¤ì‹œê°„/ì—‘ì…€
        p = _pick_price(stock_dict.get('enhanced_result') or {}) \
            or _pick_price(stock_dict.get('basic_result') or {})  # legacy
        current = p.get('current_price')
        w52h, w52l = p.get('w52_high'), p.get('w52_low')
        
        # í˜„ì¬ê°€ê°€ ì—†ìœ¼ë©´ (ì˜µì…˜ í—ˆìš© ì‹œ) ì¤‘ì•™í™”ëœ í”„ë¡œë°”ì´ë” ì‚¬ìš©
        if current is None and self.include_realtime:
            try:
                # prefer centralized provider (uses TTL cache + retries)
                p2 = self.data_provider.get_price_data(stock_dict.get('symbol'))
                current = p2.get('current_price') or current
                w52h = w52h or p2.get('w52_high')
                w52l = w52l or p2.get('w52_low')
            except Exception:
                pass
        
        # 52ì£¼ ê³ ê°€/ì €ê°€ê°€ ì—†ìœ¼ë©´ (ì˜µì…˜ í—ˆìš© ì‹œ) ì‹¤ì‹œê°„ ì¡°íšŒ (KIS + ì¬ì‹œë„ + ë ˆì´íŠ¸ë¦¬ë¯¸í„°)
        if (w52h is None or w52l is None) and self.include_realtime:
            try:
                symbol = stock_dict.get('symbol')
                if symbol:
                    self.rate_limiter.acquire()
                    cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                    cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                    price_info = _with_retries(
                        lambda: self.provider.get_stock_price_info(symbol),
                        metrics_attempt=cb_attempt,
                        metrics_final=cb_final
                    )
                    if price_info:
                        w52h = price_info.get('w52_high') or w52h
                        w52l = price_info.get('w52_low') or w52l
            except Exception as e:
                # _with_retriesê°€ ìµœì¢… ì‹¤íŒ¨ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìŒ. ì—¬ê¸°ì„  ë¡œê·¸ë§Œ.
                logging.debug(f"52ì£¼ ê³ ê°€/ì €ê°€ ì¡°íšŒ ì‹¤íŒ¨ {stock_dict.get('symbol')}: {e}")
        
        # ì—¬ì „íˆ 52ì£¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ KOSPI íŒŒì¼ì—ì„œ ì‹œë„
        if (w52h is None or w52l is None) and self.kospi_data is not None and not self.kospi_data.empty:
            try:
                code = stock_dict.get('symbol')
                # ì¸ë±ìŠ¤ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ loc ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ì¡´ ë°©ì‹
                if _is_indexed_by_code(self.kospi_data):
                    try:
                        row = self.kospi_data.loc[[str(code)]]
                    except KeyError:
                        row = pd.DataFrame()
                else:
                    row = self.kospi_data[self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] == str(code)]
                if not row.empty:
                    # KOSPI íŒŒì¼ì—ì„œ 52ì£¼ ì •ë³´ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
                    if '52ì£¼ìµœê³ ê°€' in row.columns:
                        w52h = row.iloc[0].get('52ì£¼ìµœê³ ê°€') or w52h
                    if '52ì£¼ìµœì €ê°€' in row.columns:
                        w52l = row.iloc[0].get('52ì£¼ìµœì €ê°€') or w52l
            except Exception as e:
                logging.debug(f"KOSPI íŒŒì¼ 52ì£¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ {stock_dict.get('symbol')}: {e}")
        
        # ìœ„ì¹˜ ê³„ì‚°ì€ ë‹¨ì¼ ì§„ì…ì  í•¨ìˆ˜ë¡œ í†µì¼
        position = self._calculate_price_position({'current_price': current, 'w52_high': w52h, 'w52_low': w52l})
        return current, position
    
    def _position_label(self, pos: Optional[float], is_outside_band: bool = False) -> str:
        """52ì£¼ ìœ„ì¹˜ì— ë”°ë¥¸ ë¼ë²¨ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # âœ… ê°€ë“œ 3: NaN/ë¹„ì •ìƒ ê°’ ì•ˆì „ ì²˜ë¦¬
        try:
            if pos is None:
                return "N/A"
            v = float(pos)
            if not math.isfinite(v):
                return "N/A"
            pos = max(0.0, min(100.0, v))
        except Exception:
            return "N/A"
        base_text = fmt(pos, '%')
        warning = " âš ï¸ ë°´ë“œë°–" if is_outside_band else ""
        
        if pos >= 95:
            return f"{base_text} ğŸ”´ ê³¼ì—´/ì¶”ì„¸{warning}"
        if pos >= 85:
            return f"{base_text} ğŸŸ¡ ìƒë‹¨{warning}"
        if pos <= 30:
            return f"{base_text} ğŸŸ¢ ì €ê°€êµ¬ê°„(í• ì¸){warning}"
        return f"{base_text} ì¤‘ë¦½{warning}"
    
    def _classify_bucket(self, pos: Optional[float]) -> str:
        """52ì£¼ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°”ìŠ¤ì¼“ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
        if pos is None:
            return "ë°¸ë¥˜/ë¦¬ìŠ¤í¬ê´€ë¦¬"
        return "ëª¨ë©˜í…€/ë¸Œë ˆì´í¬ì•„ì›ƒ" if pos >= 85 else "ë°¸ë¥˜/ë¦¬ìŠ¤í¬ê´€ë¦¬"
    
    def _get_position_sizing(self, pos: Optional[float], bucket_type: str) -> float:
        """í¬ì§€ì…˜ ì‚¬ì´ì§•ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if pos is None:
            return 1.0
        
        if bucket_type == "ë°¸ë¥˜/ë¦¬ìŠ¤í¬ê´€ë¦¬":
            if pos <= 30:  # ë”¥ë°¸ë¥˜
                return 1.2
            elif pos <= 70:  # ì¤‘ë¦½
                return 1.0
            else:
                return 0.8
        else:  # ëª¨ë©˜í…€/ë¸Œë ˆì´í¬ì•„ì›ƒ
            if pos >= 95:
                return 0.5
            else:
                return 0.7
    
    def _get_risk_reward_ratio(self, pos: Optional[float], bucket_type: str) -> str:
        """ì†ìµë¹„ ê¸°ì¤€ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if bucket_type == "ëª¨ë©˜í…€/ë¸Œë ˆì´í¬ì•„ì›ƒ" and pos is not None:
            if pos >= 95:
                return "ì†ì ˆ7% ëª©í‘œ1.8R"
            elif pos >= 85:
                return "ì†ì ˆ8% ëª©í‘œ1.8R"
            else:
                return "ì†ì ˆ8% ëª©í‘œ1.8R"
        else:
            return "N/A"
    
    def _extract_sector_valuation_text(self, stock: dict) -> str:
        """dict â†’ AnalysisResult(enhanced_result) â†’ sector_analysisì—ì„œ ì„¹í„° ë°¸ë¥˜ ì ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            # dict â†’ AnalysisResult(enhanced_result) â†’ sector_analysis
            ar = stock.get("enhanced_result")
            raw = {}
            if isinstance(ar, AnalysisResult):
                raw = ar.sector_analysis or {}
            if not raw:
                raw = stock.get("sector_analysis", {})
            norm = self._normalize_sector_analysis(raw)
            if norm['grade'] == 'N/A' or norm['total_score'] is None:
                return "N/A"
            return f"{norm['grade']}({norm['total_score']:.1f})"
        except Exception:
            return "N/A"

    def _get_sector_valuation_score(self, stock: Dict[str, Any]) -> str:
        """ì„¹í„° ìƒëŒ€ ë°¸ë¥˜ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            norm = self._normalize_sector_analysis(stock.get('sector_analysis', {}))
            if norm['total_score'] is None:
                return "N/A"
            return f"{norm['grade']}({norm['total_score']:.1f})"
        except Exception as e:
            logging.debug(f"ì„¹í„° ë°¸ë¥˜ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨ {stock.get('symbol')}: {e}")
            return "N/A"
    
    def _get_basket_type(self, stock: Dict[str, Any]) -> str:
        """ì¢…ëª©ì˜ 52ì£¼ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°”ìŠ¤ì¼“ íƒ€ì…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            # ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš© (ì¶”ê°€ API í˜¸ì¶œ ê¸ˆì§€)
            price_position = stock.get("price_position")
            if price_position is None:
                current_price = stock.get("current_price")
                w52h = stock.get("w52_high")
                w52l = stock.get("w52_low")
                if current_price is not None and w52h is not None and w52l is not None:
                    price_position = self._calculate_price_position({
                        'current_price': current_price,
                        'w52_high': w52h,
                        'w52_low': w52l
                    })
            return self._classify_bucket(price_position)
        except Exception as e:
            logging.debug(f"ë°”ìŠ¤ì¼“ ë¶„ë¥˜ ì‹¤íŒ¨ {stock.get('symbol')}: {e}")
            return "ë¶„ë¥˜ë¶ˆê°€"
    
    # --- ì„¹í„° ë¶„ì„ ìŠ¤í‚¤ë§ˆ ì •ê·œí™” í—¬í¼ ---
    def _normalize_sector_analysis(self, node: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë‹¤ì–‘í•œ í˜•íƒœ(ì¤‘ì²©/í‰ë©´)ì˜ ì„¹í„° ë¶„ì„ ê²°ê³¼ë¥¼ í‰ë©´ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”.
        ë°˜í™˜ ìŠ¤í‚¤ë§ˆ: {'grade': str, 'total_score': float}
        """
        if not node:
            return {'grade': 'N/A', 'total_score': None}
        # ì¤‘ì²©ëœ {'sector_analysis': {...}} í˜•íƒœ ìˆ˜ìš©
        if 'sector_analysis' in node and isinstance(node['sector_analysis'], dict):
            node = node['sector_analysis']
        # í‚¤ ë³€í˜• ìˆ˜ìš©
        grade = node.get('grade') or node.get('sector_grade') or 'N/A'
        total = node.get('total_score')
        try:
            total = float(total) if total is not None else None
        except Exception:
            total = None
        return {'grade': grade, 'total_score': total}
    
    def _nan_if_nonpos(self, x, zero_is_nan: bool = True):
        """
        0 ì´ìƒì´ê³  ìœ í•œí•œ ê°’ë§Œ ë°˜í™˜, ê·¸ ì™¸ëŠ” NaN
        
        ì •ì±…:
        - PER/PBR: 0 ì´ìƒë§Œ í†µê³¼ (ìŒìˆ˜ëŠ” ì˜ì—…ì ìë¡œ ì œì™¸)
        - ROE: 0 ì´ìƒë§Œ í†µê³¼ (ìŒìˆ˜ëŠ” ì†ì‹¤ë¡œ ì œì™¸, 0ì€ í¬í•¨)
        - zero_is_nan=True: 0ë„ NaNìœ¼ë¡œ ì²˜ë¦¬ (ë” ì—„ê²©í•œ í•„í„°ë§)
        """
        v = DataValidator.safe_float(x, float('nan'))
        if not (isinstance(v, (int, float, np.floating)) and math.isfinite(float(v))):
            return float('nan')
        if v < 0: 
            return float('nan')
        if zero_is_nan and v == 0: 
            return float('nan')
        return float(v)
    
    def _nan_if_negative(self, x):
        """
        ìŒìˆ˜ë§Œ NaNìœ¼ë¡œ ì²˜ë¦¬, 0ê³¼ ì–‘ìˆ˜ëŠ” ìœ ì§€ (ROE=0 ì¼€ì´ìŠ¤ í¬í•¨)
        """
        x = DataValidator.safe_float(x, float('nan'))
        if isinstance(x, (int, float, np.floating)) and math.isfinite(float(x)) and float(x) >= 0:
            return float(x)
        return float('nan')

    def _get_sector_peers_snapshot(self, sector_name: str) -> List[PeerTriple]:
        """
        ì„¹í„° í”¼ì–´ì˜ (PER, PBR, ROE) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ TTL ìºì‹œì™€ í•¨ê»˜ ë°˜í™˜.
        - ìºì‹œ í‚¤: sector_name
        - ê°’: List[Tuple[per, pbr, roe]]
        """
        now = _monotonic()
        key = f"sector:{sector_name}"
        with self._sector_cache_lock:
            hit = self._sector_cache.get(key)
            if hit and now - hit[0] < self._sector_cache_ttl:
                return hit[1]

        # ìºì‹œ ë¯¸ìŠ¤ â†’ ìˆ˜ì§‘
        peers = self._collect_sector_peers(sector_name)
        with self._sector_cache_lock:
            self._sector_cache[key] = (now, peers)
            # LRU ì œí•œ (ë™ì  í¬ê¸° ì œí•œ)
            while len(self._sector_cache) > self._sector_cache_max_size:
                self._sector_cache.popitem(last=False)
        return peers

    def _collect_sector_peers(self, sector_name: str) -> List[PeerTriple]:
        """
        ì„¹í„° í”¼ì–´ ìƒ˜í”Œì„ ìˆ˜ì§‘í•˜ì—¬ (per, pbr, roe) ë°°ì—´ì„ ìƒì„±.
        - KOSPI íŒŒì¼ì—ì„œ ì„¹í„° í›„ë³´ ì»¬ëŸ¼ì„ íƒìƒ‰í•´ í•„í„°ë§, ì—†ìœ¼ë©´ ìƒìœ„ ì‹œì´ ìƒ˜í”Œ í´ë°±
        - í™˜ê²½ë³€ìˆ˜/ìºì‹œëœ í•œë„ ì‚¬ìš©: baseâ†’full ë‹¨ê³„ë¡œ í™•ëŒ€ ì‹œë„
        """
        max_base = self.env_cache.get('max_sector_peers_base', 40)
        max_full = self.env_cache.get('max_sector_peers_full', 200)
        target = self.env_cache.get('sector_target_good', 60)

        df = getattr(self, 'kospi_data', None)
        symbols: List[str] = []
        if df is not None and not df.empty:
            try:
                # ì„¹í„° ì»¬ëŸ¼ í›„ë³´
                cand_cols = ['ì—…ì¢…', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì—…ì¢…ëª…', 'ì„¹í„°']
                col = next((c for c in cand_cols if c in df.columns), None)
                if col:
                    m = df[df[col].astype(str).str.contains(str(sector_name), na=False)]
                else:
                    m = df
                # ì‹œì´ ì •ë ¬(ë‚´ë¦¼ì°¨ìˆœ) í›„ ì½”ë“œ ì¶”ì¶œ
                if 'ì‹œê°€ì´ì•¡' in m.columns:
                    m = m.sort_values('ì‹œê°€ì´ì•¡', ascending=False)
                idx_is_code = (m.index.name == 'ë‹¨ì¶•ì½”ë“œ')
                codes = (m.index.astype(str).tolist() if idx_is_code else m['ë‹¨ì¶•ì½”ë“œ'].astype(str).tolist())
                symbols = codes[:max_full]
            except Exception as e:
                logging.debug(f"[sector-peers] kospi filtering failed: {e}")

        peers: List[PeerTriple] = []
        if not symbols:
            return peers

        # 1ì°¨ ìˆ˜ì§‘(ë² ì´ìŠ¤ í•œë„)
        for sym in symbols[:max_base]:
            try:
                pd_ = self.data_provider.get_price_data(sym)
                fd_ = self.data_provider.get_financial_data(sym)
                per_ = DataValidator.safe_float_optional(pd_.get('per'))
                pbr_ = DataValidator.safe_float_optional(pd_.get('pbr'))
                roe_ = DataValidator.safe_float_optional(fd_.get('roe'))
                if per_ is None or pbr_ is None or roe_ is None:
                    continue
                if not (math.isfinite(per_) and math.isfinite(pbr_) and math.isfinite(roe_)):
                    continue
                peers.append((per_, pbr_, roe_))
                if len(peers) >= target:
                    break
            except Exception:
                continue

        # ë¶€ì¡±í•˜ë©´ 2ì°¨ í™•ëŒ€(í’€ í•œë„)
        if len(peers) < target:
            for sym in symbols[max_base:max_full]:
                try:
                    pd_ = self.data_provider.get_price_data(sym)
                    fd_ = self.data_provider.get_financial_data(sym)
                    per_ = DataValidator.safe_float_optional(pd_.get('per'))
                    pbr_ = DataValidator.safe_float_optional(pd_.get('pbr'))
                    roe_ = DataValidator.safe_float_optional(fd_.get('roe'))
                    if per_ is None or pbr_ is None or roe_ is None:
                        continue
                    if not (math.isfinite(per_) and math.isfinite(pbr_) and math.isfinite(roe_)):
                        continue
                    peers.append((per_, pbr_, roe_))
                    if len(peers) >= target:
                        break
                except Exception:
                    continue

        return peers
    
    def _analyze_stocks_parallel(self, stocks_data, max_workers: int = None) -> List[AnalysisResult]:
        """ì¢…ëª©ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ëŠ” ê³µí†µ ë©”ì„œë“œ (API TPS ìµœì í™”, ë™ì  ì›Œì»¤ ì¡°ì •)"""
        results = []
        if max_workers is None:
            # âœ… ì›Œì»¤ ìˆ˜ ìë™ ì¶”ì • ê°œì„ : TPS, ì½”ì–´ ìˆ˜, ì™¸ë¶€ ë¶„ì„ ì‚¬ìš© ì—¬ë¶€ ê³ ë ¤
            cpu_cores = os.cpu_count() or 1
            max_tps = safe_env_int("KIS_MAX_TPS", 8, 1)
            
            # âœ… MAX_WORKERS=0 ì˜ë¯¸ ë¶ˆì¼ì¹˜ ìˆ˜ì •: 0ì´ë©´ ìë™ ì¶”ì •
            env_mw_raw = os.getenv("MAX_WORKERS", "")
            env_mw = None
            try:
                env_mw = int(env_mw_raw)
            except Exception:
                env_mw = None

            # ë™ì  ì›Œì»¤ ìˆ˜ ê³„ì‚° (ë°°ì¹˜ í¬ê¸° ê³ ë ¤)
            batch_size = len(stocks_data)
            if batch_size <= 10:
                # ì†Œê·œëª¨ ë°°ì¹˜: ì›Œì»¤ ìˆ˜ ì œí•œ
                auto_guess = min(4, max_tps)
            elif batch_size <= 50:
                # ì¤‘ê·œëª¨ ë°°ì¹˜: TPS ê¸°ë°˜
                auto_guess = (int(1.5 * max_tps) if self.include_external else int(2.0 * max_tps))
            else:
                # ëŒ€ê·œëª¨ ë°°ì¹˜: ìµœëŒ€ í™œìš©
                auto_guess = (int(2.0 * max_tps) if self.include_external else int(2.5 * max_tps))
            
            # I/O ë°”ìš´ë“œ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ ì½”ì–´*4ê¹Œì§€ ì—¬ìœ ë¥¼ ë‘  (í™˜ê²½ì— ë”°ë¼ íŠœë‹ ê°€ëŠ¥)
            auto_cap   = (cpu_cores * 3 if self.include_external else cpu_cores * 4)
            auto_val   = min(auto_guess, auto_cap)

            if env_mw is None or env_mw == 0:
                max_workers = max(1, auto_val)
            else:
                # ì‚¬ìš©ìê°€ ê°•ì œ ì§€ì •í•œ ê²½ìš°, ê³¼ë„í•œ ê°’ì€ ìº¡
                max_workers = max(1, min(env_mw, auto_cap))
        
        # Guard against negative/zero workers
        max_workers = max(1, max_workers or 1)
        
        # ë°°ì¹˜ í¬ê¸° ìµœì í™”: í° ë°°ì¹˜ëŠ” ì²­í¬ë¡œ ë¶„í• 
        chunk_size = safe_env_int("ANALYSIS_CHUNK_SIZE", 20, 5)
        if len(stocks_data) > chunk_size:
            # í° ë°°ì¹˜ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
            chunks = [stocks_data[i:i + chunk_size] for i in range(0, len(stocks_data), chunk_size)]
            logging.info(f"Large batch ({len(stocks_data)} stocks) split into {len(chunks)} chunks of max {chunk_size}")
        else:
            chunks = [stocks_data]

        # ì²­í¬ë³„ë¡œ ë³‘ë ¬ ì²˜ë¦¬
        all_results = []
        for chunk_idx, chunk in enumerate(chunks):
            if len(chunks) > 1:
                logging.info(f"Processing chunk {chunk_idx + 1}/{len(chunks)} ({len(chunk)} stocks)")
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # ì‘ì—… ì œì¶œ
                futures = []
                for _, stock in chunk.iterrows():
                    # ì¸ë±ìŠ¤ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©, ì•„ë‹ˆë©´ ì»¬ëŸ¼ ì‚¬ìš©
                    if chunk.index.name == 'ë‹¨ì¶•ì½”ë“œ':
                        symbol = str(stock.name)  # ì¸ë±ìŠ¤ ê°’ ì‚¬ìš©
                        name = stock['í•œê¸€ëª…']
                    else:
                        symbol = str(stock['ë‹¨ì¶•ì½”ë“œ'])
                        name = stock['í•œê¸€ëª…']
                    future = executor.submit(self.analyze_single_stock, symbol, name)
                    futures.append((future, symbol, name))

                # ê²°ê³¼ ìˆ˜ì§‘ (as_completed ì‚¬ìš©ìœ¼ë¡œ ì™„ë£Œëœ ì‘ì—…ë¶€í„° ì²˜ë¦¬)
                future_map = {f: (symbol, name) for f, symbol, name in futures}
                chunk_results = []
                for f in as_completed(future_map):
                    symbol, name = future_map[f]
                    try:
                        result = f.result()
                        if result.status == AnalysisStatus.SUCCESS:
                            chunk_results.append(result)
                        elif result.status == AnalysisStatus.SKIPPED_PREF:
                            logging.debug(f"ìš°ì„ ì£¼ ì œì™¸: {name} ({symbol})")
                        else:
                            logging.debug(f"ë¶„ì„ ì‹¤íŒ¨: {name} ({symbol}) - {result.error}")
                    except Exception as e:
                        log_error("ì¢…ëª© ë¶„ì„", f"{name}({symbol})", e, LogLevel.ERROR)
                        continue

                all_results.extend(chunk_results)
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ (ëŒ€ê·œëª¨ ë°°ì¹˜ ì²˜ë¦¬ ì‹œ)
                if len(chunks) > 1:
                    del chunk_results
                    import gc
                    gc.collect()

        # ë¶„ì„ëœ ì¢…ëª© ìˆ˜ ê¸°ë¡
        if hasattr(self, "metrics") and self.metrics:
            self.metrics.record_stocks_analyzed(len(all_results))
        
        return all_results

    # -----------------------------
    # ì‹¤í–‰ ìœ í‹¸/ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ ë³´ê°•
    # -----------------------------
    def run_universe(self, limit: int = 100) -> List[AnalysisResult]:
        """
        KOSPI ë§ˆìŠ¤í„°ì—ì„œ ìš°ì„ ì£¼ ì œì™¸ í›„ ì‹œì´ ìƒìœ„ limitê°œë¥¼ ë³‘ë ¬ ë¶„ì„.
        """
        if self.kospi_data is None or self.kospi_data.empty:
            logging.error("KOSPI ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. kospi_code.csv/xlsxë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return []

        df = self.kospi_data.copy()

        # ìš°ì„ ì£¼ ì œì™¸
        if "í•œê¸€ëª…" in df.columns:
            df = df[~df["í•œê¸€ëª…"].astype(str).apply(DataValidator.is_preferred_stock)]

        # ì‹œì´ ì •ë ¬ í›„ ìƒìœ„ limit
        if "ì‹œê°€ì´ì•¡" in df.columns:
            df = df.sort_values("ì‹œê°€ì´ì•¡", ascending=False)
        if limit and limit > 0:
            df = df.head(limit)

        results = self._analyze_stocks_parallel(df)
        
        # íˆ¬ì ë§¤ë ¥ë„(ì¢…í•©ì ìˆ˜) ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x.enhanced_score, reverse=True)
        
        return results

    def export_json(self, results: List[AnalysisResult], path: str) -> None:
        """ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        payload = [r.to_dict() for r in results]
        with open(path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        logging.info(f"JSON ì €ì¥ ì™„ë£Œ: {path}")

    def export_csv(self, results: List[AnalysisResult], path: str) -> None:
        """ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (ì£¼ìš” í•„ë“œ ì¤‘ì‹¬)"""
        rows = []
        for r in results:
            d = r.to_dict()
            rows.append({
                "symbol": d.get("symbol"),
                "name": d.get("name"),
                "grade": d.get("enhanced_grade"),
                "score": d.get("enhanced_score"),
                "market_cap_ì–µ": d.get("market_cap"),
                "current_price": d.get("current_price"),
                "price_position": d.get("price_position"),
                "per": d.get("per"),
                "pbr": d.get("pbr"),
                "sector_valuation": d.get("sector_valuation"),
            })
        pd.DataFrame(rows).to_csv(path, index=False, encoding="utf-8-sig")
        logging.info(f"CSV ì €ì¥ ì™„ë£Œ: {path}")
    
    def analyze_full_market_enhanced(self, max_stocks: int = 100, min_score: float = 20.0, 
                                   include_realtime: bool = True, include_external: bool = True,
                                   max_workers: Optional[int] = None) -> Dict[str, Any]:
        """
        í–¥ìƒëœ ì „ì²´ ì‹œì¥ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª©ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ì—¬ ì €í‰ê°€ ì¢…ëª©ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Note: include_realtime, include_external íŒŒë¼ë¯¸í„°ëŠ” ë©”íƒ€ë°ì´í„° í‘œì‹œìš©ì…ë‹ˆë‹¤.
              ì‹¤ì œ ë¡œì§ì€ ì¸ìŠ¤í„´ìŠ¤ í”Œë˜ê·¸(self.include_realtime, self.include_external)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            max_stocks (int): ìµœëŒ€ ë¶„ì„ ì¢…ëª© ìˆ˜ (ê¸°ë³¸ê°’: 100)
            min_score (float): ìµœì†Œ ì ìˆ˜ í•„í„° (ê¸°ë³¸ê°’: 20.0)
            include_realtime (bool): ì‹¤ì‹œê°„ ë°ì´í„° í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            include_external (bool): ì™¸ë¶€ ë°ì´í„° í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            Dict[str, Any]: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
                - metadata: ë¶„ì„ ë©”íƒ€ë°ì´í„°
                - top_recommendations: ìƒìœ„ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
                - sector_analysis: ì—…ì¢…ë³„ ë¶„ì„ ê²°ê³¼
                - market_statistics: ì‹œì¥ í†µê³„
                
        Note:
            ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
            CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì›Œì»¤ ìˆ˜ë¥¼ ìë™ ì¡°ì •í•©ë‹ˆë‹¤.
        """
        try:
            # âœ… ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œ ë¡œê·¸ ì´ˆê¸°í™”
            _setup_logging_if_needed()
            
            start_time = _monotonic()
            
            # KOSPI ë°ì´í„° í™•ì¸
            if self.kospi_data is None or self.kospi_data.empty:
                raise ValueError("KOSPI ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì„ ë³„
            top_stocks = self.kospi_data.nlargest(max_stocks, 'ì‹œê°€ì´ì•¡')
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
            results = self._analyze_stocks_parallel(top_stocks, max_workers=max_workers)
            
            # ê²°ê³¼ ì •ë ¬ ë° í•„í„°ë§
            filtered_results = [
                r for r in results 
                if r.enhanced_score >= min_score
            ]
            filtered_results.sort(key=lambda x: x.enhanced_score, reverse=True)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            analysis_time = _monotonic() - start_time
            from datetime import datetime as dt
            metadata = {
                'analysis_version': '2.0_enhanced',
                'analysis_date': dt.now().isoformat(),
                'analysis_time_seconds': analysis_time,
                'total_analyzed': len(results),
                'total_stocks_analyzed': len(results),
                'undervalued_count': len(filtered_results),
                'features_enabled': {
                    'realtime_data': self.include_realtime,
                    'external_data': self.include_external,
                    'enhanced_scoring': True
                }
            }
            
            return {
                'metadata': metadata,
                'top_recommendations': [r.to_dict() for r in filtered_results[:20]],
                'sector_analysis': self._analyze_sector_distribution_enhanced(results),
                'market_statistics': self._calculate_enhanced_market_statistics(results)
            }
            
        except Exception as e:
            log_error("ì „ì²´ ì‹œì¥ ë¶„ì„", error=e, level="error")
            return {
                'metadata': {'error': str(e)},
                'top_recommendations': [],
                'sector_analysis': {},
                'market_statistics': {}
            }
        finally:
            try:
                summ = self.metrics.get_summary() if hasattr(self, "metrics") and self.metrics else {}
                # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ ê²¹ì¹¨ ë°©ì§€
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                metrics_filename = f"metrics_summary_{timestamp}.json"
                with open(metrics_filename, "w", encoding="utf-8") as f:
                    json.dump(serialize_for_json(summ), f, ensure_ascii=False, indent=2)
                logging.info(f"ë©”íŠ¸ë¦­ ìš”ì•½ ì €ì¥: {metrics_filename}")
            except Exception as _e:
                logging.warning(f"ë©”íŠ¸ë¦­ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {_e}")
    
    def analyze_top_market_cap_stocks_enhanced(self, count: int = 50, min_score: float = 20.0, 
                                             max_workers: Optional[int] = None) -> Dict[str, Any]:
        """
        ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© í–¥ìƒëœ ë¶„ì„
        
        Note: ì‹¤ì œ ë¡œì§ì€ ì¸ìŠ¤í„´ìŠ¤ í”Œë˜ê·¸(self.include_realtime, self.include_external)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        try:
            start_time = _monotonic()
            
            if self.kospi_data is None or self.kospi_data.empty:
                raise ValueError("KOSPI ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì„ ë³„
            top_stocks = self.kospi_data.nlargest(count, 'ì‹œê°€ì´ì•¡')
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
            results = self._analyze_stocks_parallel(top_stocks, max_workers=max_workers)
            
            # ê²°ê³¼ í•„í„°ë§ ë° ì •ë ¬
            filtered_results = [
                r for r in results 
                if r.enhanced_score >= min_score
            ]
            filtered_results.sort(key=lambda x: x.enhanced_score, reverse=True)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            analysis_time = _monotonic() - start_time
            from datetime import datetime as dt
            metadata = {
                'analysis_version': '2.0_enhanced',
                'analysis_date': dt.now().isoformat(),
                'analysis_time_seconds': analysis_time,
                'total_analyzed': len(results),
                'total_stocks_analyzed': len(results),
                'undervalued_count': len(filtered_results),
                'features_enabled': {
                    'realtime_data': self.include_realtime,
                    'external_data': self.include_external,
                    'enhanced_scoring': True
                }
            }
            
            return {
                'metadata': metadata,
                'top_recommendations': [r.to_dict() for r in filtered_results[:15]],
                'sector_analysis': self._analyze_sector_distribution_enhanced(results),
                'market_statistics': self._calculate_enhanced_market_statistics(results)
            }
            
        except Exception as e:
            log_error("ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ë¶„ì„", error=e, level="error")
            return {
                'metadata': {'error': str(e)},
                'top_recommendations': [],
                'sector_analysis': {},
                'market_statistics': {}
            }
    
    def _analyze_sector_distribution_enhanced(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """í–¥ìƒëœ ì—…ì¢…ë³„ ë¶„í¬ ë¶„ì„ (ì¤‘ë³µ ì„¹í„°ì¡°íšŒ ì œê±°)"""
        try:
            sector_distribution = {}
            
            # ì‹¬ë³¼â†’ì„¹í„° ë§¤í•‘ì„ í•œ ë²ˆë§Œ êµ¬í•˜ì—¬ ì¤‘ë³µ ì¡°íšŒ ì œê±°
            sector_map = {}
            for result in results:
                sym = result.symbol
                if sym not in sector_map:
                    sector_map[sym] = self._get_sector_characteristics(sym).get('name', 'ê¸°íƒ€')
                sector = sector_map[sym]
                
                if sector not in sector_distribution:
                    sector_distribution[sector] = {
                        'count': 0,
                        'total_score': 0,
                        'avg_score': 0,
                        'recommendations': {'BUY': 0, 'HOLD': 0, 'SELL': 0}
                    }
                
                sector_distribution[sector]['count'] += 1
                sector_distribution[sector]['total_score'] += result.enhanced_score
                
                # íˆ¬ì ì¶”ì²œ ë¶„í¬ (ì•ˆì „ ì ‘ê·¼)
                recommendation = DataValidator._getattr_or_get(result, 'investment_recommendation', 'HOLD')
                if recommendation in sector_distribution[sector]['recommendations']:
                    sector_distribution[sector]['recommendations'][recommendation] += 1
            
            # í‰ê·  ì ìˆ˜ ê³„ì‚°
            for sector in sector_distribution:
                if sector_distribution[sector]['count'] > 0:
                    sector_distribution[sector]['avg_score'] = (
                        sector_distribution[sector]['total_score'] / sector_distribution[sector]['count']
                    )
            
            return sector_distribution
            
        except Exception as e:
            log_error("ì—…ì¢…ë³„ ë¶„í¬ ë¶„ì„", error=e, level="error")
            return {}
    
    def _calculate_enhanced_market_statistics(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """í–¥ìƒëœ ì‹œì¥ í†µê³„ ê³„ì‚°"""
        try:
            if not results:
                return {}
            
            scores = [r.enhanced_score for r in results if r.enhanced_score > 0]
            market_caps = [r.market_cap for r in results if r.market_cap > 0]
            
            if not scores:
                return {}
            
            return {
                'total_analyzed': len(results),
                'avg_score': sum(scores) / len(scores),
                'max_score': max(scores),
                'min_score': min(scores),
                'score_distribution': {
                    'A+': len([s for s in scores if s >= 80]),
                    'A': len([s for s in scores if 70 <= s < 80]),
                    'B+': len([s for s in scores if 60 <= s < 70]),
                    'B': len([s for s in scores if 50 <= s < 60]),
                    'C': len([s for s in scores if 40 <= s < 50]),
                    'D': len([s for s in scores if 20 <= s < 40]),
                    'F': len([s for s in scores if s < 20])
                },
                'market_cap_stats': {
                    'total_market_cap': sum(market_caps),
                    'avg_market_cap': sum(market_caps) / len(market_caps) if market_caps else 0,
                    'max_market_cap': max(market_caps) if market_caps else 0,
                    'min_market_cap': min(market_caps) if market_caps else 0
                }
            }
            
        except Exception as e:
            log_error("ì‹œì¥ í†µê³„ ê³„ì‚°", error=e, level="error")
            return {}
    
    def _display_enhanced_results_table(self, results: Dict[str, Any]):
        """í–¥ìƒëœ ë¶„ì„ ê²°ê³¼ë¥¼ í‘œ í˜•íƒœë¡œ ì¶œë ¥"""
        try:
            metadata = results.get('metadata', {})
            print(f"\nğŸš€ í–¥ìƒëœ í†µí•© ë¶„ì„ ê²°ê³¼ v{metadata.get('analysis_version', '2.0_enhanced')}")
            print(f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {metadata.get('analysis_date', 'Unknown')}")
            print(f"â±ï¸ ë¶„ì„ ì‹œê°„: {metadata.get('analysis_time_seconds', 0):.1f}ì´ˆ")
            total = metadata.get('total_analyzed', metadata.get('total_stocks_analyzed', 0))
            print(f"ğŸ“Š ì´ ë¶„ì„ ì¢…ëª©: {total}ê°œ")
            print(f"ğŸ¯ ì¶”ì²œ ì¢…ëª©: {metadata.get('undervalued_count', 0)}ê°œ")
            
            # ìƒìœ„ ì¶”ì²œ ì¢…ëª© í‘œ
            top_recommendations = results.get('top_recommendations', [])
            if top_recommendations:
                print("\nğŸ† í–¥ìƒëœ ì¢…ëª© ì¶”ì²œ ê²°ê³¼ (í˜„ì¬ê°€ ë° 52ì£¼ ìœ„ì¹˜ ìƒì„¸)")
                print("=" * 130)
                print(f"{'ìˆœìœ„':<4} {'ì¢…ëª©ì½”ë“œ':<8} {'ì¢…ëª©ëª…':<15} {'í˜„ì¬ê°€':<12} {'52ì£¼ê³ ê°€':<12} {'52ì£¼ì €ê°€':<12} {'52ì£¼ìœ„ì¹˜':<10} {'ì¢…í•©ì ìˆ˜':<8} {'ë“±ê¸‰':<6} {'ì‹œê°€ì´ì•¡':<12}")
                print("-" * 130)
                
                for i, stock in enumerate(top_recommendations[:10], 1):
                    # stockì´ ë”•ì…”ë„ˆë¦¬ì¸ì§€ ê°ì²´ì¸ì§€ í™•ì¸
                    if isinstance(stock, dict):
                        symbol = stock.get('symbol', 'N/A')
                        name = stock.get('name', 'N/A')
                        enhanced_score = stock.get('enhanced_score', 0)
                        market_cap = stock.get('market_cap', 0)
                        current_price = stock.get('current_price', 0)
                        grade = stock.get('enhanced_grade', 'F')
                        w52_high = stock.get('w52_high', 0)
                        w52_low = stock.get('w52_low', 0)
                    else:
                        symbol = getattr(stock, 'symbol', 'N/A')
                        name = getattr(stock, 'name', 'N/A')
                        enhanced_score = getattr(stock, 'enhanced_score', 0)
                        market_cap = getattr(stock, 'market_cap', 0)
                        current_price = getattr(stock, 'current_price', 0)
                        grade = getattr(stock, 'enhanced_grade', 'F')
                        w52_high = getattr(stock, 'w52_high', 0)
                        w52_low = getattr(stock, 'w52_low', 0)
                    
                    # í˜„ì¬ê°€ í‘œì‹œ (ì²œì› ë‹¨ìœ„ë¡œ í‘œì‹œ)
                    if current_price is not None and current_price > 0:
                        if current_price >= 10000:
                            current_price_display = f"{current_price/1000:,.0f}ì²œì›"
                        else:
                            current_price_display = f"{current_price:,.0f}ì›"
                    else:
                        current_price_display = "N/A"
                    
                    # 52ì£¼ ê³ ê°€ í‘œì‹œ
                    if w52_high is not None and w52_high > 0:
                        if w52_high >= 10000:
                            w52_high_display = f"{w52_high/1000:,.0f}ì²œì›"
                        else:
                            w52_high_display = f"{w52_high:,.0f}ì›"
                    else:
                        w52_high_display = "N/A"
                    
                    # 52ì£¼ ì €ê°€ í‘œì‹œ
                    if w52_low is not None and w52_low > 0:
                        if w52_low >= 10000:
                            w52_low_display = f"{w52_low/1000:,.0f}ì²œì›"
                        else:
                            w52_low_display = f"{w52_low:,.0f}ì›"
                    else:
                        w52_low_display = "N/A"
                    
                    # 52ì£¼ ìœ„ì¹˜ ê³„ì‚° ë° í‘œì‹œ (ìƒ‰ìƒ ì½”ë“œ í¬í•¨)
                    if current_price and w52_high and w52_low and w52_high > w52_low:
                        position = ((current_price - w52_low) / (w52_high - w52_low)) * 100
                        if position >= 80:
                            position_display = f"{position:.0f}% ğŸ”´"  # ê³ ìœ„ì¹˜
                        elif position >= 60:
                            position_display = f"{position:.0f}% ğŸŸ¡"  # ì¤‘ìœ„ì¹˜
                        elif position >= 40:
                            position_display = f"{position:.0f}% ğŸŸ¢"  # ì¤‘í•˜ìœ„ì¹˜
                        else:
                            position_display = f"{position:.0f}% ğŸ”µ"  # ì €ìœ„ì¹˜
                    else:
                        position_display = "N/A"
                    
                    # ì‹œê°€ì´ì•¡ í‘œì‹œ
                    if market_cap and market_cap > 0:
                        if market_cap >= 10000:  # 1ì¡°ì› ì´ìƒ
                            market_cap_display = f"{market_cap/10000:,.1f}ì¡°ì›"
                        else:
                            market_cap_display = f"{market_cap:,.0f}ì–µì›"
                    else:
                        market_cap_display = "N/A"
                    
                    # ì¢…ëª©ëª… ê¸¸ì´ ì œí•œ
                    name_display = name[:12] + ('...' if len(name) > 12 else '')
                    
                    print(f"{i:<4} {symbol:<8} {name_display:<15} {current_price_display:<12} {w52_high_display:<12} {w52_low_display:<12} {position_display:<10} {enhanced_score:<8.1f} {grade:<6} {market_cap_display:<12}")
                
                print("=" * 130)
                print("ğŸ“Š 52ì£¼ ìœ„ì¹˜ ì„¤ëª…:")
                print("  ğŸ”´ 80% ì´ìƒ: 52ì£¼ ê³ ê°€ ê·¼ì²˜ (ê³ ìœ„ì¹˜)")
                print("  ğŸŸ¡ 60-79%: 52ì£¼ ì¤‘ìƒìœ„ (ì¤‘ìœ„ì¹˜)")
                print("  ğŸŸ¢ 40-59%: 52ì£¼ ì¤‘í•˜ìœ„ (ì¤‘í•˜ìœ„ì¹˜)")
                print("  ğŸ”µ 40% ë¯¸ë§Œ: 52ì£¼ ì €ê°€ ê·¼ì²˜ (ì €ìœ„ì¹˜)")
                print("=" * 130)
            
            # ì—…ì¢…ë³„ ë¶„ì„ ê²°ê³¼
            sector_analysis = results.get('sector_analysis', {})
            if sector_analysis:
                print(f"\nğŸ“Š ì—…ì¢…ë³„ ë¶„ì„ ê²°ê³¼")
                for sector, data in sector_analysis.items():
                    print(f"  {sector}: {data['count']}ê°œ ì¢…ëª©, í‰ê· ì ìˆ˜ {data['avg_score']:.1f}")
            
            # ì‹œì¥ í†µê³„
            market_stats = results.get('market_statistics', {})
            if market_stats:
                print(f"\nğŸ“ˆ ì‹œì¥ í†µê³„")
                print(f"  í‰ê·  ì ìˆ˜: {market_stats.get('avg_score', 0):.1f}")
                print(f"  ìµœê³  ì ìˆ˜: {market_stats.get('max_score', 0):.1f}")
                print(f"  ìµœì € ì ìˆ˜: {market_stats.get('min_score', 0):.1f}")
                
                score_dist = market_stats.get('score_distribution', {})
                if score_dist:
                    print(f"  ì ìˆ˜ ë¶„í¬: A+({score_dist.get('A+', 0)}) A({score_dist.get('A', 0)}) B+({score_dist.get('B+', 0)}) B({score_dist.get('B', 0)})")
            
        except Exception as e:
            log_error("ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥", error=e, level="error")
            pass

# =============================================================================
# 6. CLI ì¸í„°í˜ì´ìŠ¤ (ì„ íƒì  - typerê°€ ì„¤ì¹˜ëœ ê²½ìš°ì—ë§Œ ì‚¬ìš© ê°€ëŠ¥)
# =============================================================================

# Typer CLI ì•± ìƒì„± (ì„ íƒì  import)
try:
    import typer
    app = typer.Typer(help="Enhanced Integrated Analyzer")
    TYPER_AVAILABLE = True
    
    @app.command()
    def analyze(
        symbol: str = typer.Argument(..., help="ë¶„ì„í•  ì¢…ëª© ì½”ë“œ (ì˜ˆ: 005930)"),
        name: str = typer.Option("", help="ì¢…ëª©ëª… (ì„ íƒì‚¬í•­)"),
        realtime: bool = typer.Option(True, help="ì‹¤ì‹œê°„ ë°ì´í„° í¬í•¨"),
        external: bool = typer.Option(True, help="ì™¸ë¶€ ë¶„ì„ í¬í•¨(ì˜ê²¬/ì¶”ì •)"),
    ):
        """ë‹¨ì¼ ì¢…ëª© ë¶„ì„"""
        _setup_logging_if_needed()
        analyzer = EnhancedIntegratedAnalyzer(include_realtime=realtime, include_external=external)
        try:
            result = analyzer.analyze_single_stock(symbol, name)
            print(f"ë¶„ì„ ê²°ê³¼: {result.status}")
            print(f"ì¢…ëª©: {result.name} ({result.symbol})")
            print(f"ì ìˆ˜: {result.enhanced_score:.1f} ({result.enhanced_grade})")
            
            # ìƒì„¸í•œ ê°€ê²© ì •ë³´ í‘œì‹œ
            if IMPROVED_MODULES_AVAILABLE:
                try:
                    price_data = {
                        'symbol': result.symbol,
                        'name': result.name,
                        'current_price': result.current_price,
                        'w52_high': result.price_data.get('w52_high') if result.price_data else None,
                        'w52_low': result.price_data.get('w52_low') if result.price_data else None,
                        'market_cap': result.market_cap
                    }
                    print(display_detailed_price_info(price_data))
                except Exception as e:
                    # í´ë°±: ê¸°ë³¸ ê°€ê²© ì •ë³´ í‘œì‹œ
                    print(f"í˜„ì¬ê°€: {result.current_price:,.0f}ì›" if result.current_price else "í˜„ì¬ê°€: N/A")
                    print(f"52ì£¼ìœ„ì¹˜: {result.price_position:.1f}%" if result.price_position else "52ì£¼ìœ„ì¹˜: N/A")
            else:
                # ê¸°ë³¸ ê°€ê²© ì •ë³´ í‘œì‹œ
                print(f"í˜„ì¬ê°€: {result.current_price:,.0f}ì›" if result.current_price else "í˜„ì¬ê°€: N/A")
                print(f"52ì£¼ìœ„ì¹˜: {result.price_position:.1f}%" if result.price_position else "52ì£¼ìœ„ì¹˜: N/A")
            
            print(f"ì„¹í„°: {result.sector_analysis.get('grade', 'N/A')} ({result.sector_analysis.get('total_score', 0):.1f})")
        except Exception as e:
            typer.echo(f"ë¶„ì„ ì‹¤íŒ¨: {e}", err=True)
        finally:
            analyzer.close()
    
    @app.command()
    def scan(
        max_stocks: int = typer.Option(50, help="ë¶„ì„í•  ì‹œì´ ìƒìœ„ ì¢…ëª© ìˆ˜"),
        min_score: float = typer.Option(20.0, help="ìµœì†Œ ì ìˆ˜"),
        max_workers: int = typer.Option(0, help="ì›Œì»¤ ìˆ˜(0=ìë™)"),
        realtime: bool = typer.Option(True, help="ì‹¤ì‹œê°„ ë°ì´í„° í¬í•¨"),
        external: bool = typer.Option(True, help="ì™¸ë¶€ ë¶„ì„ í¬í•¨(ì˜ê²¬/ì¶”ì •)"),
    ):
        """ì‹œì´ ìƒìœ„ ì¢…ëª© ìŠ¤ìº”"""
        _setup_logging_if_needed()
        analyzer = EnhancedIntegratedAnalyzer(include_realtime=realtime, include_external=external)
        try:
            results = analyzer.analyze_top_market_cap_stocks_enhanced(
                count=max_stocks,
                min_score=min_score,
                max_workers=(None if max_workers == 0 else max_workers),
            )
            print(f"ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì¢…ëª©")
            for i, result in enumerate(results[:10], 1):
                print(f"{i:2d}. {result.name} ({result.symbol}) - {result.enhanced_score:.1f}ì  ({result.enhanced_grade})")
        except Exception as e:
            typer.echo(f"ìŠ¤ìº” ì‹¤íŒ¨: {e}", err=True)
        finally:
            analyzer.close()
    
    @app.command()
    def full_market(
        max_stocks: int = typer.Option(100, help="ì‹œì´ ìƒìœ„ Nê°œ ë¶„ì„"),
        min_score: float = typer.Option(20.0, help="ìµœì†Œ ì ìˆ˜"),
        max_workers: int = typer.Option(0, help="ì›Œì»¤ ìˆ˜(0=ìë™)"),
        realtime: bool = typer.Option(True, help="ì‹¤ì‹œê°„ ë°ì´í„° í¬í•¨"),
        external: bool = typer.Option(True, help="ì™¸ë¶€ ë¶„ì„ í¬í•¨(ì˜ê²¬/ì¶”ì •)"),
    ):
        """ì „ì²´ ì‹œì¥ ë¶„ì„"""
        _setup_logging_if_needed()
        analyzer = EnhancedIntegratedAnalyzer(include_realtime=realtime, include_external=external)
        try:
            result_dict = analyzer.analyze_full_market_enhanced(
                max_stocks=max_stocks,
                min_score=min_score,
                include_realtime=realtime,
                include_external=external,
                max_workers=(None if max_workers == 0 else max_workers),
            )
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì¶”ì²œ ì¢…ëª© ì¶”ì¶œ
            recommendations = result_dict.get('top_recommendations', [])
            metadata = result_dict.get('metadata', {})
            
            print(f"ì „ì²´ ì‹œì¥ ë¶„ì„ ì™„ë£Œ: {metadata.get('total_analyzed', 0)}ê°œ ì¢…ëª© ë¶„ì„")
            print(f"ì €í‰ê°€ ì¢…ëª©: {metadata.get('undervalued_count', 0)}ê°œ ë°œê²¬")
            print(f"ë¶„ì„ ì‹œê°„: {metadata.get('analysis_time_seconds', 0):.1f}ì´ˆ")
            print()
            
            if recommendations:
                print("\nìƒìœ„ ì¶”ì²œ ì¢…ëª© (ê°€ì¹˜íˆ¬ì ìƒì„¸ ë¶„ì„)")
                print("=" * 170)
                print(f"{'ìˆœìœ„':<4} {'ì¢…ëª©ëª…':<20} {'ì¢…ëª©ì½”ë“œ':<8} {'ì ìˆ˜':<8} {'ë“±ê¸‰':<6} {'ë‚´ì¬ê°€ì¹˜':<12} {'ì•ˆì „ë§ˆì§„':<10} {'ì‹œê·¸ë„':<8} {'ëª©í‘œë§¤ìˆ˜ê°€':<12} {'ì‹œê°€ì´ì•¡':<12} {'í˜„ì¬ê°€':<10}")
                print("-" * 170)
                
                for i, result in enumerate(recommendations[:20], 1):
                    name = result.get('name', 'N/A')
                    symbol = result.get('symbol', 'N/A')
                    score = result.get('enhanced_score', 0)
                    grade = result.get('enhanced_grade', 'N/A')
                    
                    # ê°€ì¹˜íˆ¬ì ì •ë³´ ì¶”ì¶œ
                    intrinsic_value = result.get('intrinsic_value')
                    margin_of_safety = result.get('margin_of_safety')
                    watchlist_signal = result.get('watchlist_signal', 'N/A')
                    target_buy = result.get('target_buy')
                    market_cap = result.get('market_cap')
                    current_price = result.get('current_price', 0)
                    
                    # ë‚´ì¬ê°€ì¹˜ í¬ë§·íŒ…
                    iv_str = f"{intrinsic_value:,.0f}ì›" if intrinsic_value else "N/A"
                    
                    # ì•ˆì „ë§ˆì§„ í¬ë§·íŒ…
                    mos_str = f"{margin_of_safety*100:.1f}%" if margin_of_safety else "N/A"
                    
                    # ì‹œê°€ì´ì•¡ í¬ë§·íŒ…
                    mc_str = f"{market_cap:,.0f}ì–µ" if market_cap else "N/A"
                    
                    # í˜„ì¬ê°€ í¬ë§·íŒ…
                    cp_str = f"{current_price:,.0f}ì›" if current_price else "N/A"
                    
                    # ì‹œê·¸ë„ í‘œì‹œ
                    signal_str = watchlist_signal if watchlist_signal != 'N/A' else "N/A"
                    
                    # ëª©í‘œë§¤ìˆ˜ê°€ í¬ë§·íŒ…
                    target_str = f"{target_buy:,.0f}ì›" if target_buy else "N/A"
                    
                    print(f"{i:2d}. {name:<20} {symbol:<8} {score:>6.1f}ì  {grade:<6} {iv_str:<12} {mos_str:<10} {signal_str:<8} {target_str:<12} {mc_str:<12} {cp_str:<10}")
                
                print("\nê°€ì¹˜íˆ¬ì í•µì‹¬ ì§€í‘œ ì„¤ëª…:")
                print("- ë‚´ì¬ê°€ì¹˜: ë³´ìˆ˜ì  2ì›í™” ëª¨ë¸ (FCF/EPS ë©€í‹°í”Œ ì¤‘ ë‚®ì€ ê°’)")
                print("- ì•ˆì „ë§ˆì§„: ë‚´ì¬ê°€ì¹˜ ëŒ€ë¹„ í˜„ì¬ê°€ í• ì¸ìœ¨ (ë†’ì„ìˆ˜ë¡ ë§¤ë ¥ì )")
                print("- ì‹œê·¸ë„: BUY(30%â†‘+í•´ì+ì €êµ¬ê°„), WATCH(10-30%), PASS(ë¯¸ë§Œ)")
                print("- ëª©í‘œë§¤ìˆ˜ê°€: ë‚´ì¬ê°€ì¹˜ Ã— (1 - ìµœì†Œì•ˆì „ë§ˆì§„) = ë°©ì–´ì  ë§¤ìˆ˜ê°€")
                print("- ì ìˆ˜: ê°€ì¹˜íˆ¬ì ì² í•™ ë°˜ì˜ (ì‚¬ì—…ì˜ ì§ˆ + ì•ˆì „ë§ˆì§„)")
                
                # ìƒìœ„ 5ê°œ ì¢…ëª©ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ì¶”ê°€
                print("\nìƒìœ„ 5ê°œ ì¢…ëª© ìƒì„¸ ë¶„ì„:")
                print("=" * 120)
                
                for i, result in enumerate(recommendations[:5], 1):
                    name = result.get('name', 'N/A')
                    symbol = result.get('symbol', 'N/A')
                    score = result.get('enhanced_score', 0)
                    grade = result.get('enhanced_grade', 'N/A')
                    
                    # ê°€ì¹˜íˆ¬ì ì •ë³´
                    intrinsic_value = result.get('intrinsic_value')
                    margin_of_safety = result.get('margin_of_safety')
                    watchlist_signal = result.get('watchlist_signal', 'N/A')
                    moat_grade = result.get('moat_grade', 'N/A')
                    target_buy = result.get('target_buy')
                    playbook = result.get('playbook', [])
                    
                    # ì¬ë¬´ ì •ë³´
                    financial_data = result.get('financial_data', {})
                    roe = financial_data.get('roe')
                    roa = financial_data.get('roa')
                    debt_ratio = financial_data.get('debt_ratio')
                    net_profit_margin = financial_data.get('net_profit_margin')
                    
                    # ê°€ê²© ì •ë³´ (ìƒë‹¨ í…Œì´ë¸”ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°)
                    current_price = result.get('current_price', 0)
                    price_data = result.get('price_data', {})
                    # AnalysisResultì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                    price_52w_high = result.get('w52_high') or price_data.get('w52_high')
                    price_52w_low = result.get('w52_low') or price_data.get('w52_low')
                    price_position = result.get('price_position')
                    
                    # ì ìˆ˜ ë¶„ì„
                    score_breakdown = result.get('score_breakdown', {})
                    raw_breakdown = result.get('raw_breakdown', {})
                    value_score = raw_breakdown.get('value_raw', 0)  # ì›ì ìˆ˜ ì‚¬ìš©
                    financial_score = score_breakdown.get('ì¬ë¬´ë¹„ìœ¨', 0)
                    growth_score = score_breakdown.get('ì„±ì¥ì„±', 0)
                    
                    print(f"\n{i}. {name} ({symbol}) - {score:.1f}ì  ({grade})")
                    print("-" * 80)
                    
                    # ê°€ì¹˜íˆ¬ì ì •ë³´
                    print(f"ê°€ì¹˜íˆ¬ì ë¶„ì„:")
                    print(f"   - ë‚´ì¬ê°€ì¹˜: {intrinsic_value:,.0f}ì›" if intrinsic_value else "   - ë‚´ì¬ê°€ì¹˜: N/A")
                    print(f"   - ì•ˆì „ë§ˆì§„: {margin_of_safety*100:.1f}%" if margin_of_safety else "   - ì•ˆì „ë§ˆì§„: N/A")
                    print(f"   - íˆ¬ìì‹œê·¸ë„: {watchlist_signal}")
                    print(f"   - í•´ìë“±ê¸‰: {moat_grade}")
                    print(f"   - ëª©í‘œë§¤ìˆ˜ê°€: {target_buy:,.0f}ì›" if target_buy else "   - ëª©í‘œë§¤ìˆ˜ê°€: N/A")
                    print(f"   - ê°€ì¹˜íˆ¬ìì ìˆ˜: {value_score:.1f}ì ")
                    
                    # ê°€ì¹˜íˆ¬ì í”Œë ˆì´ë¶
                    if playbook:
                        print(f"ê°€ì¹˜íˆ¬ì í”Œë ˆì´ë¶:")
                        for tip in playbook:
                            print(f"   - {tip}")
                    
                    # ì¬ë¬´ ì •ë³´
                    print(f"ì¬ë¬´ ê±´ì „ì„±:")
                    print(f"   - ROE: {roe:.1f}%" if roe else "   - ROE: N/A")
                    print(f"   - ROA: {roa:.1f}%" if roa else "   - ROA: N/A")
                    print(f"   - ë¶€ì±„ë¹„ìœ¨: {debt_ratio:.1f}%" if debt_ratio else "   - ë¶€ì±„ë¹„ìœ¨: N/A")
                    print(f"   - ìˆœì´ìµë§ˆì§„: {net_profit_margin:.1f}%" if net_profit_margin else "   - ìˆœì´ìµë§ˆì§„: N/A")
                    print(f"   - ì¬ë¬´ì ìˆ˜: {financial_score:.1f}ì ")
                    
                    # ê°€ê²© ì •ë³´
                    print(f"ê°€ê²© ë¶„ì„:")
                    print(f"   - í˜„ì¬ê°€: {current_price:,.0f}ì›" if current_price else "   - í˜„ì¬ê°€: N/A")
                    print(f"   - 52ì£¼ê³ ê°€: {price_52w_high:,.0f}ì›" if price_52w_high else "   - 52ì£¼ê³ ê°€: N/A")
                    print(f"   - 52ì£¼ì €ê°€: {price_52w_low:,.0f}ì›" if price_52w_low else "   - 52ì£¼ì €ê°€: N/A")
                    print(f"   - 52ì£¼ìœ„ì¹˜: {price_position:.1f}%" if price_position else "   - 52ì£¼ìœ„ì¹˜: N/A")
                    
                    # íˆ¬ì í¬ì¸íŠ¸
                    print(f"íˆ¬ì í¬ì¸íŠ¸:")
                    if watchlist_signal == "BUY" and margin_of_safety and margin_of_safety > 0.3:
                        print(f"   - ë†’ì€ ì•ˆì „ë§ˆì§„ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ë§¤ìˆ˜ ê¸°íšŒ")
                    if roe and roe > 15:
                        print(f"   - ìš°ìˆ˜í•œ ìë³¸ íš¨ìœ¨ì„± (ROE {roe:.1f}%)")
                    if debt_ratio and debt_ratio < 30:
                        print(f"   - ì•ˆì •ì ì¸ ì¬ë¬´ êµ¬ì¡° (ë¶€ì±„ë¹„ìœ¨ {debt_ratio:.1f}%)")
                    if price_position and price_position < 30:
                        print(f"   - 52ì£¼ ì €ì  ê·¼ì²˜ì—ì„œ ë§¤ìˆ˜ ê¸°íšŒ")
                    
                    print()
            else:
                print("ì¡°ê±´ì— ë§ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            typer.echo(f"ì „ì²´ ì‹œì¥ ë¶„ì„ ì‹¤íŒ¨: {e}", err=True)
        finally:
            analyzer.close()

except ImportError:
    app = None
    TYPER_AVAILABLE = False

def main():
    """Main entry point for the analyzer"""
    _setup_logging_if_needed()
    install_sighup_handler()
    _validate_startup_configuration()  # êµ¬ì„± ê²€ì¦
    
    if TYPER_AVAILABLE and app:
        try:
            app()
        except KeyboardInterrupt:
            logging.warning("ì‚¬ìš©ì ì¤‘ë‹¨(CTRL+C)")
    else:
        print("Enhanced Integrated Analyzer")
        print("Typerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ CLIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”:")
        print("  from enhanced_integrated_analyzer_refactored import EnhancedIntegratedAnalyzer")
        print("  analyzer = EnhancedIntegratedAnalyzer()")
        print("  result = analyzer.analyze_single_stock('005930', 'ì‚¼ì„±ì „ì')")

if __name__ == "__main__":
    main()

# CLI í•¨ìˆ˜ë“¤ (typerê°€ ì„¤ì¹˜ëœ ê²½ìš°ì—ë§Œ ì‚¬ìš© ê°€ëŠ¥) - ì£¼ì„ ì²˜ë¦¬
# í•„ìš”ì‹œ ë³„ë„ CLI ëª¨ë“ˆë¡œ ë¶„ë¦¬í•˜ì—¬ êµ¬í˜„ ê°€ëŠ¥

# =============================================================================
# Graceful Shutdown & Metrics Dump
# =============================================================================

_global_analyzer_instance = None

def _dump_metrics_on_exit():
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ë©”íŠ¸ë¦­ ë¤í”„ (ê°„ì†Œí™”)"""
    try:
        if _global_analyzer_instance and getattr(_global_analyzer_instance, "metrics", None):
            m = _global_analyzer_instance.metrics.get_summary()
            logging.info(
                "[METRICS] api_succ_rate=%.1f%% price_hit=%.1f%% fin_hit=%.1f%% sector_hit=%.1f%% "
                "avg_analysis=%.2fs avg_sector=%.2fs errors=%s",
                m.get('api_success_rate', 0.0),
                m['cache_hit_rates'].get('price', 0.0),
                m['cache_hit_rates'].get('financial', 0.0),
                m['cache_hit_rates'].get('sector', 0.0),
                m.get('avg_analysis_duration', 0.0),
                m.get('avg_sector_evaluation', 0.0),
                m.get('errors_by_type', {})
            )
    except Exception:
        pass

# ì „ì—­ ë©”íŠ¸ë¦­ ë¤í”„ í›… ë“±ë¡
atexit.register(_dump_metrics_on_exit)

def _install_signals():
    """ê¹”ë”í•œ ì¢…ë£Œ(ë©”íŠ¸ë¦­ ì§‘ê³„ í›„)ë¥¼ ìœ„í•œ ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ì„¤ì¹˜"""
    def _graceful_exit(signum, frame):
        logging.info("ì‹ í˜¸ ìˆ˜ì‹ : ì¢…ë£Œí•©ë‹ˆë‹¤.")
        raise SystemExit(0)
    try:
        signal.signal(signal.SIGINT, _graceful_exit)
        signal.signal(signal.SIGTERM, _graceful_exit)
    except Exception:
        pass

def show_help():
    """ë„ì›€ë§ í‘œì‹œ"""
    print("""
ğŸš€ í–¥ìƒëœ í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ v2.0

ì‚¬ìš©ë²•:
  python enhanced_integrated_analyzer_refactored.py [ì˜µì…˜]

ì˜µì…˜:
  --help, -h           ì´ ë„ì›€ë§ í‘œì‹œ
  --count N            ë¶„ì„í•  ì¢…ëª© ìˆ˜ (ê¸°ë³¸ê°’: 10)
  --min-score N        ìµœì†Œ ì ìˆ˜ í•„í„° (ê¸°ë³¸ê°’: 15.0)
  --max-workers N      ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 0=ìë™)
  --no-external        ì™¸ë¶€ ë°ì´í„°(íˆ¬ìì˜ê²¬/ì¶”ì •ì‹¤ì ) ë¹„í™œì„±í™”
  --no-realtime        ì‹¤ì‹œê°„ ë°ì´í„°(ê°€ê²©/52ì£¼) ë¹„í™œì„±í™”
  --dump PATH          ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
  --smoke SYMBOL       ë‹¨ì¼ ì¢…ëª© ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ (JSON ì¶œë ¥)

ì˜ˆì‹œ:
  python enhanced_integrated_analyzer_refactored.py --count 20 --min-score 25
  python enhanced_integrated_analyzer_refactored.py --no-external --dump results.json
  python enhanced_integrated_analyzer_refactored.py --count 5 --min-score 30 --max-workers 4
  python enhanced_integrated_analyzer_refactored.py --smoke 005930
    """)

def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    import sys
    
    # ê¸°ë³¸ê°’
    count = 10
    min_score = 15.0
    max_workers = 0
    include_external = True
    include_realtime = True
    dump_path = None
    
    i = 1
    while i < len(sys.argv):
        arg = sys.argv[i]
        
        if arg in ['--help', '-h', 'help']:
            show_help()
            sys.exit(0)
        elif arg == '--count' and i + 1 < len(sys.argv):
            count = int(sys.argv[i + 1])
            i += 2
        elif arg == '--min-score' and i + 1 < len(sys.argv):
            min_score = float(sys.argv[i + 1])
            i += 2
        elif arg == '--max-workers' and i + 1 < len(sys.argv):
            max_workers = int(sys.argv[i + 1])
            i += 2
        elif arg == '--no-external':
            include_external = False
            i += 1
        elif arg == '--no-realtime':
            include_realtime = False
            i += 1
        elif arg == '--dump' and i + 1 < len(sys.argv):
            dump_path = sys.argv[i + 1]
            i += 2
        else:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: {arg}")
            print("ğŸ’¡ --helpë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ì„¸ìš”.")
            sys.exit(1)
    
    return {
        'count': count,
        'min_score': min_score,
        'max_workers': max_workers if max_workers > 0 else None,
        'include_external': include_external,
        'include_realtime': include_realtime,
        'dump_path': dump_path
    }

    def main():
        """Main entry point for the analyzer"""
        _setup_logging_if_needed()
        install_sighup_handler()
        try:
            app()
        except KeyboardInterrupt:
            logging.warning("ì‚¬ìš©ì ì¤‘ë‹¨(CTRL+C)")

if __name__ == "__main__":
    # ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ì‚¬í•­ ê²€ì¦)
    if len(sys.argv) == 1:
        print("ğŸ§ª Running smoke test...")
        _setup_logging_if_needed()
        install_sighup_handler()
        
        analyzer = EnhancedIntegratedAnalyzer(include_realtime=False, include_external=False)
        try:
            r = analyzer.analyze_single_stock("005930", "ì‚¼ì„±ì „ì")
            print("âœ… Smoke test passed!")
            print(f"Status: {r.status}, Grade: {r.enhanced_grade}, Score: {r.enhanced_score:.1f}")
            print(f"Dict keys: {list(r.to_dict().keys())[:8]}")
        except Exception as e:
            print(f"âŒ Smoke test failed: {e}")
            sys.exit(1)
        finally:
            analyzer.close()
    else:
        main()

# =============================================================================
# í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹° ë° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
# =============================================================================

class EnvContextManager:
    """í™˜ê²½ë³€ìˆ˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € - í…ŒìŠ¤íŠ¸ ê²©ë¦¬ìš©"""
    
    def __init__(self, **env_vars):
        self.env_vars = env_vars
        self.original_values = {}
    
    def __enter__(self):
        for key, value in self.env_vars.items():
            self.original_values[key] = os.environ.get(key)
            if value is None:
                os.environ.pop(key, None)
            else:
                os.environ[key] = str(value)
        # í™˜ê²½ë³€ìˆ˜ ìºì‹œ ê°±ì‹ 
        _refresh_env_cache()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        for key, original_value in self.original_values.items():
            if original_value is None:
                os.environ.pop(key, None)
            else:
                os.environ[key] = original_value
        # í™˜ê²½ë³€ìˆ˜ ìºì‹œ ê°±ì‹ 
        _refresh_env_cache()

def with_env(**env_vars):
    """í™˜ê²½ë³€ìˆ˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            with EnvContextManager(**env_vars):
                return func(*args, **kwargs)
        return wrapper
    return decorator

def test_normalize_market_cap_ekwon_strict():
    """Test market cap normalization in strict mode"""
    import os
    os.environ["MARKET_CAP_STRICT_MODE"] = "true"
    
    # Reload environment cache
    _refresh_env_cache()
    
    # Test value that satisfies: min_threshold â‰¤ v â‰¤ max_threshold and v â‰¥ 1e7
    # But 1e7 = 10M, max_threshold = 2M, so no value can satisfy both conditions
    # Test large value conversion instead
    assert normalize_market_cap_ekwon(500_000_000_000) == 5000  # ì› â†’ ì–µì› (â‰¥1e11)
    assert normalize_market_cap_ekwon(50_000_000) is None       # ambiguous dropped

def test_financial_units_canonical():
    """Test financial units canonicalization"""
    d = {"roe": 0.12, "current_ratio": 1.8, "debt_ratio": 0.45}
    out = DataConverter.standardize_financial_units(d)
    assert out["roe"] == 12.0
    assert out["current_ratio"] == 180.0
    assert out["debt_ratio"] == 45.0
    assert out["_percent_canonicalized"] is True

def test_price_position():
    """Test price position calculation"""
    p = {"current_price": 60, "w52_low": 40, "w52_high": 100}
    a = EnhancedIntegratedAnalyzer(include_external=False)
    expected = (60-40)/(100-40)*100  # 33.333...
    result = a._calculate_price_position(p)
    assert abs(result - expected) < 0.01

def test_rate_limiter_applied_to_price_provider():
    """Test that rate limiter is applied to price provider calls"""
    calls = {"n": 0}
    
    class Dummy:
        def get_comprehensive_price_data(self, s): 
            calls["n"] += 1
            return {"current_price": 10.0, "eps": 2.0, "bps": 5.0}
    
    prov = FinancialDataProvider(KISDataProvider(), TPSRateLimiter(max_tps=1), metrics=MetricsCollector())
    prov.price_provider = Dummy()
    _ = prov.get_price_data("000001")
    assert calls["n"] == 1

def test_kospi_index_detection():
    """Test KOSPI index detection robustness"""
    import pandas as pd
    
    # Test with named index
    df1 = pd.DataFrame({'data': [1, 2, 3]}, index=['A', 'B', 'C'])
    df1.index.name = 'ë‹¨ì¶•ì½”ë“œ'
    assert _is_indexed_by_code(df1) is True
    
    # Test with unnamed index
    df2 = pd.DataFrame({'data': [1, 2, 3]}, index=['A', 'B', 'C'])
    assert _is_indexed_by_code(df2) is False
    
    # Test with None index name
    df3 = pd.DataFrame({'data': [1, 2, 3]}, index=['A', 'B', 'C'])
    df3.index.name = None
    assert _is_indexed_by_code(df3) is False

def test_percent_canonicalization_safety():
    """Test percent canonicalization safety (no double scaling)"""
    # Test cases: roe=[0.03, 3, 300] â†’ [3, 300, 300] (enforce_canonical_percent logic)
    test_cases = [
        (0.03, 3.0),    # 3% as decimal â†’ 3%
        (3.0, 300.0),   # 3% as decimal (â‰¤5) â†’ 300%
        (300.0, 300.0), # 300% already â†’ 300%
    ]
    
    for input_val, expected in test_cases:
        d = {"roe": input_val}
        out = DataConverter.standardize_financial_units(d)
        assert out["roe"] == expected, f"ROE {input_val} should become {expected}, got {out['roe']}"

def test_current_ratio_ambiguous_policy():
    """Test current_ratio ambiguous range policy"""
    # Test cases: [1.5, 120, 35] â†’ [150, 120, 35] (ambiguous 35 stays in [10,300] range)
    test_cases = [
        (1.5, 150.0),   # Multiple â†’ Percent
        (120.0, 120.0), # Already percent
        (35.0, 35.0),   # Ambiguous but in safe range
    ]
    
    for input_val, expected in test_cases:
        d = {"current_ratio": input_val}
        out = DataConverter.standardize_financial_units(d)
        assert out["current_ratio"] == expected, f"Current ratio {input_val} should become {expected}, got {out['current_ratio']}"

def test_52w_band_degeneration():
    """Test 52-week band degeneration cases"""
    a = EnhancedIntegratedAnalyzer(include_external=False)
    
    # Test cases: (hi, lo, cp) â†’ expected_position
    test_cases = [
        (100, 100, 100, None),  # Same values â†’ degeneration
        (100, 100, 100, None),  # Same values â†’ degeneration  
        (100, 99.9, 100, None), # Tiny band â†’ degeneration
        (100, 1, 50, 49.49),    # Normal case (band=99, positionâ‰ˆ49.49%)
        (100, 50, 75, 50.0),    # Normal case (band=50, position=50%)
    ]
    
    for hi, lo, cp, expected in test_cases:
        position = a._calculate_price_position({
            'current_price': cp,
            'w52_high': hi,
            'w52_low': lo
        })
        if expected is None:
            assert position is None, f"Position should be None for hi={hi}, lo={lo}, cp={cp}"
        else:
            assert abs(position - expected) < 0.1, f"Position mismatch for hi={hi}, lo={lo}, cp={cp}: expected {expected}, got {position}"

def test_per_pbr_guards():
    """Test PER/PBR guards with extreme values"""
    # Test EPS=0.01 (very small) should skip PER calculation
    # Test BPS=0.01 (very small) should skip PBR calculation
    # Test clamp upper bounds apply
    
    # This would require mocking the price provider, so we'll test the logic conceptually
    # EPS_MIN = 0.1, BPS_MIN = 100.0 (from environment)
    assert True  # Placeholder - actual implementation would test the guards

def test_kospi_market_cap_strict_mode():
    """Test KOSPI market cap strict mode handling"""
    # Test cases: mc=200_000_000_000_000(ì›) â†’ 2_000_000(ì–µì›) (always converts, â‰¥1e11)
    # Test ambiguous range: mc=50_000_000_000(ì›) strict=true â†’ None, strict=false â†’ 500(ì–µì›)
    
    # Test large value (â‰¥1e11) - always converts regardless of strict mode
    result_large = normalize_market_cap_ekwon(200_000_000_000_000)
    assert result_large == 2_000_000, f"Large value should convert to 2_000_000, got {result_large}"
    
    # Test ambiguous range (1e10-1e11) - depends on strict mode
    with EnvContextManager(MARKET_CAP_STRICT_MODE="true"):
        result_strict = normalize_market_cap_ekwon(50_000_000_000)  # 500ì–µì›
        assert result_strict is None, f"Strict mode should return None for ambiguous value, got {result_strict}"
    
    # Test non-strict mode  
    with EnvContextManager(MARKET_CAP_STRICT_MODE="false"):
        result_nonstrict = normalize_market_cap_ekwon(50_000_000_000)  # 500ì–µì›
        assert result_nonstrict == 500, f"Non-strict mode should convert to 500, got {result_nonstrict}"

def test_market_cap_boundary_values():
    """Test market cap normalization across all regimes"""
    test_cases = [
        # (input, strict_mode, expected_result, description)
        (1e6, True, None, "Too small (<1e7)"),
        (5e9, True, None, "Small cap in won (5e9)"),
        (2e10, True, None, "Ambiguous range (2e10)"),
        (5e10, True, None, "Ambiguous range (5e10)"),
        (1e11, True, 1000, "Large value (â‰¥1e11)"),
        (5e11, True, 5000, "Very large value (5e11)"),
        
        # Non-strict mode
        (5e9, False, 50, "Small cap in won (non-strict)"),
        (2e10, False, 200, "Ambiguous range (non-strict)"),
        (5e10, False, 500, "Ambiguous range (non-strict)"),
    ]
    
    for input_val, strict_mode, expected, description in test_cases:
        with EnvContextManager(MARKET_CAP_STRICT_MODE=str(strict_mode).lower()):
            result = normalize_market_cap_ekwon(input_val)
            assert result == expected, f"{description}: {input_val} -> expected {expected}, got {result}"

def test_current_ratio_ambiguous_policy_matrix():
    """Test current_ratio ambiguous range policy matrix"""
    test_cases = [
        # (input, force_percent, ambiguous_strategy, expected_result, description)
        (1.5, False, "as_is", 150.0, "Multiple â†’ Percent (force_percent=false)"),
        (1.5, True, "as_is", 150.0, "Multiple â†’ Percent (force_percent=true)"),
        (120.0, False, "as_is", 120.0, "Already percent"),
        (35.0, False, "as_is", 35.0, "Ambiguous but in safe range"),
        (35.0, False, "clamp", 35.0, "Ambiguous with clamp strategy (no change needed)"),
        (8.0, False, "as_is", 800.0, "Multiple â†’ Percent"),
        (8.0, True, "as_is", 8.0, "Multiple â†’ Percent (force_percent=true, but 8.0 > 5.0 so no change)"),
    ]
    
    for input_val, force_percent, ambiguous_strategy, expected, description in test_cases:
        with EnvContextManager(
            CURRENT_RATIO_FORCE_PERCENT=str(force_percent).lower(),
            CURRENT_RATIO_AMBIGUOUS_STRATEGY=ambiguous_strategy
        ):
            d = {"current_ratio": input_val}
            out = DataConverter.standardize_financial_units(d)
            assert out["current_ratio"] == expected, f"{description}: {input_val} -> expected {expected}, got {out['current_ratio']}"

def test_percent_canonicalization_regression():
    """Test percent canonicalization regression prevention"""
    test_cases = [
        # (input_data, expected_output, description)
        ({"roe": 0.12, "debt_ratio": 0.45}, {"roe": 12.0, "debt_ratio": 45.0}, "Decimal to percent"),
        ({"roe": 12.0, "debt_ratio": 45.0}, {"roe": 12.0, "debt_ratio": 45.0}, "Already percent"),
        ({"roe": 0.03, "debt_ratio": 0.03}, {"roe": 300.0, "debt_ratio": 300.0}, "Small decimals (enforce_canonical_percent)"),
    ]
    
    for input_data, expected_output, description in test_cases:
        # First pass
        out1 = DataConverter.standardize_financial_units(input_data.copy())
        assert out1["_percent_canonicalized"] is True, f"{description}: First pass should set flag"
        
        # Second pass (regression test)
        out2 = DataConverter.standardize_financial_units(out1.copy())
        assert out2["_percent_canonicalized"] is True, f"{description}: Second pass should maintain flag"
        
        # Values should not change
        for key in expected_output:
            assert out2[key] == expected_output[key], f"{description}: {key} should be {expected_output[key]}, got {out2[key]}"

def test_valuation_penalty_double_prevention():
    """Test valuation penalty double application prevention"""
    # Test case: Both VAL_PENALTY_IN_PRICE and VAL_PENALTY_IN_FIN are True
    # Should warn and disable VAL_PENALTY_IN_FIN
    
    # Capture log output to verify warning
    
    log_capture = io.StringIO()
    handler = logging.StreamHandler(log_capture)
    handler.setLevel(logging.WARNING)
    
    # Add handler temporarily
    logger = logging.getLogger()
    original_handlers = logger.handlers[:]
    logger.addHandler(handler)
    
    try:
        with EnvContextManager(
            VAL_PENALTY_IN_PRICE="true",
            VAL_PENALTY_IN_FIN="true"
        ):
            # Create analyzer and test scoring
            analyzer = EnhancedIntegratedAnalyzer(include_realtime=False, include_external=False)
            
            # Mock data with high PER/PBR to trigger penalties
            test_data = {
                'price_data': {
                    'per': 50.0,  # High PER
                    'pbr': 5.0,   # High PBR
                    'current_price': 100.0
                },
                'financial_data': {
                    'per': 50.0,
                    'pbr': 5.0,
                    'roe': 10.0
                }
            }
            
            # Test scoring
            scorer = EnhancedScoreCalculator(ConfigManager())
            score, breakdown = scorer.calculate_score(test_data)
            
            # Verify warning was logged
            log_output = log_capture.getvalue()
            assert "PRICEì™€ FIN ë™ì‹œ ì ìš© ê°ì§€" in log_output, "Warning about double penalty should be logged"
            
            # Verify that FIN penalty was disabled (score should not be extremely low)
            assert score > 0, "Score should be positive even with high PER/PBR"
            
            analyzer.close()
            
    finally:
        # Restore original handlers
        logger.handlers = original_handlers
        handler.close()

def test_valuation_penalty_single_application():
    """Test that only one penalty is applied when configured correctly"""
    test_cases = [
        # (price_penalty, fin_penalty, expected_behavior)
        (True, False, "Only price penalty applied"),
        (False, True, "Only financial penalty applied"),
        (False, False, "No penalties applied"),
    ]
    
    for price_penalty, fin_penalty, description in test_cases:
        with EnvContextManager(
            VAL_PENALTY_IN_PRICE=str(price_penalty).lower(),
            VAL_PENALTY_IN_FIN=str(fin_penalty).lower()
        ):
            analyzer = EnhancedIntegratedAnalyzer(include_realtime=False, include_external=False)
            
            # Test data with high PER/PBR
            test_data = {
                'price_data': {
                    'per': 50.0,
                    'pbr': 5.0,
                    'current_price': 100.0
                },
                'financial_data': {
                    'per': 50.0,
                    'pbr': 5.0,
                    'roe': 10.0
                }
            }
            
            scorer = EnhancedScoreCalculator(ConfigManager())
            score, breakdown = scorer.calculate_score(test_data)
            
            # Score should be reasonable (not extremely low from double penalty)
            assert score > 0, f"{description}: Score should be positive"
            
            analyzer.close()

def test_52w_band_boundary_cases():
    """Test 52-week band boundary cases and price position edge cases"""
    analyzer = EnhancedIntegratedAnalyzer(include_realtime=False, include_external=False)
    
    test_cases = [
        # (w52_high, w52_low, current_price, expected_position, description)
        (100.0, 100.0, 100.0, None, "Identical high/low (degenerate band)"),
        (100.0, 99.95, 100.0, None, "Tiny band (0.05% difference)"),
        (100.0, 99.0, 100.0, 100.0, "At high boundary"),
        (100.0, 99.0, 99.0, 0.0, "At low boundary"),
        (100.0, 99.0, 99.5, 50.0, "Middle position"),
        (100.0, 99.0, 101.0, 100.0, "Above band (clamped to 100)"),
        (100.0, 99.0, 98.0, 0.0, "Below band (clamped to 0)"),
    ]
    
    for w52_high, w52_low, current_price, expected, description in test_cases:
        price_data = {
            'w52_high': w52_high,
            'w52_low': w52_low,
            'current_price': current_price
        }
        
        result = analyzer._calculate_price_position(price_data)
        
        if expected is None:
            assert result is None, f"{description}: Should return None, got {result}"
        else:
            assert result is not None, f"{description}: Should return {expected}, got None"
            assert abs(result - expected) < 0.1, f"{description}: Expected ~{expected}, got {result}"
    
    analyzer.close()

def test_52w_band_tiny_threshold():
    """Test POS_TINY_BAND_THRESHOLD configuration"""
    test_cases = [
        # (threshold, band_ratio, expected_result, description)
        (0.001, 0.0005, None, "Band below threshold (0.05% < 0.1%)"),
        (0.001, 0.0015, 50.0, "Band above threshold (0.15% > 0.1%)"),
        (0.01, 0.005, None, "Band below higher threshold (0.5% < 1%)"),
        (0.01, 0.015, 50.0, "Band above higher threshold (1.5% > 1%)"),
    ]
    
    for threshold, band_ratio, expected, description in test_cases:
        with EnvContextManager(POS_TINY_BAND_THRESHOLD=str(threshold)):
            analyzer = EnhancedIntegratedAnalyzer(include_realtime=False, include_external=False)
            
            # Create band with specified ratio
            w52_high = 100.0
            w52_low = w52_high * (1 - band_ratio)
            current_price = (w52_high + w52_low) / 2  # Middle
            
            price_data = {
                'w52_high': w52_high,
                'w52_low': w52_low,
                'current_price': current_price
            }
            
            result = analyzer._calculate_price_position(price_data)
            
            if expected is None:
                assert result is None, f"{description}: Should return None, got {result}"
            else:
                assert result is not None, f"{description}: Should return ~{expected}, got {result}"
            
            analyzer.close()

def test_price_position_score_mapping():
    """Test price position to score mapping edge cases"""
    scorer = EnhancedScoreCalculator(ConfigManager())
    
    test_cases = [
        # (price_position, expected_score_range, description)
        (0.0, (95, 100), "At 52w low (should be high score)"),
        (50.0, (25, 35), "Middle position (neutral score)"),
        (100.0, (0, 5), "At 52w high (should be low score)"),
        (None, (45, 55), "Invalid position (should default to neutral)"),
    ]
    
    for price_position, expected_range, description in test_cases:
        result = scorer._calculate_price_position_score(price_position)
        
        assert expected_range[0] <= result <= expected_range[1], \
            f"{description}: Expected {expected_range}, got {result}"

def test_startup_configuration_validation():
    """Test startup configuration validation"""
    # Test 1: Valid configuration should pass
    with EnvContextManager(
        VAL_PENALTY_IN_PRICE="true",
        VAL_PENALTY_IN_FIN="false",
        MARKET_CAP_STRICT_MODE="true"
    ):
        try:
            _validate_startup_configuration()
            # Should not raise exception
        except ValueError as e:
            assert False, f"Valid configuration should not raise ValueError: {e}"
    
    # Test 2: Double penalty configuration should fail
    with EnvContextManager(
        VAL_PENALTY_IN_PRICE="true",
        VAL_PENALTY_IN_FIN="true"
    ):
        try:
            _validate_startup_configuration()
            assert False, "Double penalty configuration should raise ValueError"
        except ValueError as e:
            assert "VAL_PENALTY_IN_PRICE and VAL_PENALTY_IN_FIN cannot both be True" in str(e)
    
    # Test 3: High TPS should warn
    with EnvContextManager(KIS_MAX_TPS="25"):
        # Capture log output
        
        log_capture = io.StringIO()
        handler = logging.StreamHandler(log_capture)
        handler.setLevel(logging.WARNING)
        
        logger = logging.getLogger()
        original_handlers = logger.handlers[:]
        logger.addHandler(handler)
        
        try:
            _validate_startup_configuration()
            log_output = log_capture.getvalue()
            assert "KIS_MAX_TPS is very high" in log_output
        finally:
            logger.handlers = original_handlers
            handler.close()

def test_sighup_handler_installation():
    """Test SIGHUP handler installation tracking"""
    # Reset the flag
    if hasattr(_validate_startup_configuration, '_sighup_installed'):
        delattr(_validate_startup_configuration, '_sighup_installed')
    
    # Test without SIGHUP installation
    
    log_capture = io.StringIO()
    handler = logging.StreamHandler(log_capture)
    handler.setLevel(logging.WARNING)
    
    logger = logging.getLogger()
    original_handlers = logger.handlers[:]
    logger.addHandler(handler)
    
    try:
        _validate_startup_configuration()
        log_output = log_capture.getvalue()
        assert "SIGHUP handler not installed" in log_output
    finally:
        logger.handlers = original_handlers
        handler.close()
    
    # Test with SIGHUP installation
    _mark_sighup_installed()
    
    log_capture2 = io.StringIO()
    handler2 = logging.StreamHandler(log_capture2)
    handler2.setLevel(logging.WARNING)
    
    logger.addHandler(handler2)
    
    try:
        _validate_startup_configuration()
        log_output2 = log_capture2.getvalue()
        assert "SIGHUP handler not installed" not in log_output2
    finally:
        logger.handlers = original_handlers
        handler2.close()

def run_quick_tests():
    """Run all quick smoke tests"""
    print("Running quick smoke tests...")
    
    try:
        test_normalize_market_cap_ekwon_strict()
        print("Market cap normalization test passed")
        
        test_financial_units_canonical()
        print("Financial units canonicalization test passed")
        
        test_price_position()
        print("Price position calculation test passed")
        
        test_rate_limiter_applied_to_price_provider()
        print("Rate limiter test passed")
        
        test_kospi_index_detection()
        print("KOSPI index detection test passed")
        
        # New safety/accuracy tests
        test_percent_canonicalization_safety()
        print("Percent canonicalization safety test passed")
        
        test_current_ratio_ambiguous_policy()
        print("Current ratio ambiguous policy test passed")
        
        test_52w_band_degeneration()
        print("52-week band degeneration test passed")
        
        test_per_pbr_guards()
        print("PER/PBR guards test passed")
        
        test_kospi_market_cap_strict_mode()
        print("KOSPI market cap strict mode test passed")
        
        # New comprehensive boundary tests
        test_market_cap_boundary_values()
        print("Market cap boundary values test passed")
        
        test_current_ratio_ambiguous_policy_matrix()
        print("Current ratio policy matrix test passed")
        
        test_percent_canonicalization_regression()
        print("Percent canonicalization regression test passed")
        
        # Valuation penalty tests
        test_valuation_penalty_double_prevention()
        print("Valuation penalty double prevention test passed")
        
        test_valuation_penalty_single_application()
        print("Valuation penalty single application test passed")
        
        # 52-week band boundary tests
        test_52w_band_boundary_cases()
        print("52-week band boundary cases test passed")
        
        test_52w_band_tiny_threshold()
        print("52-week band tiny threshold test passed")
        
        test_price_position_score_mapping()
        print("Price position score mapping test passed")
        
        # Startup validation tests
        test_startup_configuration_validation()
        print("Startup configuration validation test passed")
        
        test_sighup_handler_installation()
        print("SIGHUP handler installation test passed")
        
        print("All quick tests passed!")
        return True
        
    except Exception as e:
        import traceback
        print(f"Test failed: {e}")
        print("Traceback:")
        traceback.print_exc()
        return False

if __name__ == "__main__" and len(sys.argv) == 1:
    # Run quick tests if no arguments provided
    if run_quick_tests():
        print("All fixes verified!")
    else:
        print("Some tests failed!")
        sys.exit(1)
