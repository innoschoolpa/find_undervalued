# enhanced_integrated_analyzer_refactored.py
# mypy: ignore-errors  # TODO: í•µì‹¬ ê³µìš© í•¨ìˆ˜ë“¤ë¶€í„° íƒ€ì…ì„ ì—„ê²©íˆ í•˜ì—¬ ë“œë¦¬í”„íŠ¸ ë°©ì§€
"""
ë¦¬íŒ©í† ë§ëœ í–¥ìƒëœ í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ
- ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì ìš©
- í´ë˜ìŠ¤ ë¶„ë¦¬ ë° ëª¨ë“ˆí™”
- ì„±ëŠ¥ ìµœì í™”
- ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
"""

# Public API surface
__all__ = [
    # Main classes
    'EnhancedIntegratedAnalyzer',
    'AnalysisResult',
    'AnalysisStatus',
    'AnalysisConfig',
    
    # Data classes
    'PriceData',
    'FinancialData',
    'ErrorType',
    
    # Utilities
    'normalize_market_cap_ekwon',
    'serialize_for_json',
    'fmt',
    'fmt_pct',
    
    # Configuration
    'ConfigManager',
    'MetricsCollector',
]

"""
ìŠ¤ë ˆë“œ ì•ˆì „ì„± (Thread Safety):
- ë‚´ë¶€ ìºì‹œ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì€ RLockìœ¼ë¡œ ë³´í˜¸ë¨
- ì™¸ë¶€ ë°ì´í„° í”„ë¡œë°”ì´ë”(KISDataProvider, EnhancedPriceProvider)ëŠ” 
  ìŠ¤ë ˆë“œ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ. ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ì£¼ì˜ í•„ìš”.
- ë ˆì´íŠ¸ë¦¬ë¯¸í„°ëŠ” ìŠ¤ë ˆë“œ ì•ˆì „í•˜ê²Œ êµ¬í˜„ë¨
- ê¶Œì¥ì‚¬í•­: í”„ë¡œë°”ì´ë” ë‚´ë¶€ì—ì„œ ìš”ì²­ ë‹¨ìœ„ ì„¸ì…˜ ìƒì„± ë˜ëŠ” ë½/í ë„ì…

í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Environment Variables):
- KIS_MAX_TPS: API TPS ì œí•œ (ê¸°ë³¸ê°’: 8, ë‹¨ìœ„: ìš”ì²­/ì´ˆ)
- MAX_WORKERS: ì›Œì»¤ ìˆ˜ ê°•ì œ ì„¤ì • (ê¸°ë³¸ê°’: 0=ìë™, ë‹¨ìœ„: ê°œ)
- EPS_MIN: EPS ìµœì†Œì¹˜ (ê¸°ë³¸ê°’: 0.1, ë‹¨ìœ„: ì›)
- BPS_MIN: BPS ìµœì†Œì¹˜ (ê¸°ë³¸ê°’: 100.0, ë‹¨ìœ„: ì›)
- POS_TINY_BAND_THRESHOLD: 52ì£¼ ë°´ë“œ ì„ê³„ì¹˜ (ê¸°ë³¸ê°’: 0.001, ë‹¨ìœ„: 0.1%)
- KIS_CACHE_TTL_PRICE: ê°€ê²© ìºì‹œ TTL (ê¸°ë³¸ê°’: 5.0, ë‹¨ìœ„: ì´ˆ)
- KIS_CACHE_TTL_FINANCIAL: ì¬ë¬´ ìºì‹œ TTL (ê¸°ë³¸ê°’: 900.0, ë‹¨ìœ„: ì´ˆ)
- KIS_CACHE_MAX_KEYS: ìºì‹œ ìµœëŒ€ ì—”íŠ¸ë¦¬ ìˆ˜ (ê¸°ë³¸ê°’: 2000, ë‹¨ìœ„: ê°œ)
- PREFERRED_STOCK_INCLUDE_WOORI: "ìš°ë¦¬" ì‹œì‘ ì¢…ëª© ìš°ì„ ì£¼ ê°„ì£¼ (ê¸°ë³¸ê°’: false)
- PER_MAX_DEFAULT: PER ìƒí•œ í´ë¨í”„ (ê¸°ë³¸ê°’: 500.0, ë‹¨ìœ„: ë°°)
- PBR_MAX_DEFAULT: PBR ìƒí•œ í´ë¨í”„ (ê¸°ë³¸ê°’: 100.0, ë‹¨ìœ„: ë°°)
- SECTOR_TARGET_GOOD: ì„¹í„° í”¼ì–´ ëª©í‘œ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ê°’: 60, ë‹¨ìœ„: ê°œ)
- RATE_LIMITER_DEFAULT_TIMEOUT: ë ˆì´íŠ¸ë¦¬ë¯¸í„° íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ê°’: 2.0, ë‹¨ìœ„: ì´ˆ)
- RATE_LIMITER_NOTIFY_ALL: ë ˆì´íŠ¸ë¦¬ë¯¸í„° ê³µì •í•œ ì›¨ì´í¬ì—… (ê¸°ë³¸ê°’: false)
- MARKET_CAP_STRICT_MODE: ì‹œì´ ë‹¨ìœ„ ì¶”ì • ì—„ê²© ëª¨ë“œ (ê¸°ë³¸ê°’: true; true=ì• ë§¤ ê°’ ë¬´ì‹œ, false=ì™„í™” ë³€í™˜ í—ˆìš©)
- ENABLE_FAKE_PROVIDERS: ì™¸ë¶€ ëª¨ë“ˆ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ êµ¬í˜„ ì‚¬ìš© (ê¸°ë³¸ê°’: false; true=ìš´ì˜ ì¤‘ ì¼ì‹œ ì¥ì•  ì‹œ ì§„ë‹¨ ê³„ì†)
"""

import typer
import pandas as pd
import numpy as np
import logging
import json
import time
import os
import yaml
import math
import random
import signal
import atexit
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple, Union, TypedDict, Set
from decimal import Decimal
from threading import Lock, RLock, Condition
from collections import deque, OrderedDict
from rich.console import Console
from rich.table import Table
from rich.box import ROUNDED

# monotonic time ë³„ì¹­ (ì‹œìŠ¤í…œ ì‹œê°„ ë³€ê²½ì— ì•ˆì „)
_monotonic = time.monotonic

# âœ… ëª¨ë“ˆ ë ˆë²¨ í™˜ê²½ë³€ìˆ˜ ìºì‹œ (í•«íŒ¨ìŠ¤ ìµœì í™”)
_ENV_CACHE = {
    'current_ratio_ambiguous_strategy': os.getenv("CURRENT_RATIO_AMBIGUOUS_STRATEGY", "as_is"),
    'current_ratio_force_percent': os.getenv("CURRENT_RATIO_FORCE_PERCENT", "false"),
    'market_cap_strict_mode': os.getenv("MARKET_CAP_STRICT_MODE", "true"),
}

def _refresh_env_cache():
    """í™˜ê²½ë³€ìˆ˜ ìºì‹œ hot-reload (ëŸ°íƒ€ì„ ì„¤ì • ë³€ê²½ ì§€ì›)"""
    _ENV_CACHE['current_ratio_ambiguous_strategy'] = os.getenv("CURRENT_RATIO_AMBIGUOUS_STRATEGY", "as_is")
    _ENV_CACHE['current_ratio_force_percent'] = os.getenv("CURRENT_RATIO_FORCE_PERCENT", "false")
    _ENV_CACHE['market_cap_strict_mode'] = os.getenv("MARKET_CAP_STRICT_MODE", "true")

# --- í™˜ê²½ë³€ìˆ˜ ìºì‹œ í•«ë¦¬ë¡œë“œ: SIGHUP ì§€ì› ------------------------------------
def _handle_sighup(signum, frame):
    try:
        _refresh_env_cache()
        logging.info("[env] SIGHUP received â†’ environment cache reloaded")
    except Exception as e:
        logging.debug(f"[env] SIGHUP handler error: {e}")

try:
    signal.signal(signal.SIGHUP, _handle_sighup)
except Exception:
    # ì¼ë¶€ í”Œë«í¼(Windows ë“±)ì—ì„œëŠ” SIGHUP ë¯¸ì§€ì›
    pass

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================

def normalize_market_cap_ekwon(x: Optional[float]) -> Optional[float]:
    """
    Normalize market cap to ì–µì› (eokwon).
    Heuristics:
      - If value looks like ì–µì› (<= 20,000,000 = 2,000ì¡°), keep as-is.
      - If value looks like ì› (>= 1e11 = 1,000ì–µ), convert to ì–µì› by /1e8.
      - Otherwise treat as ambiguous â†’ optional non-strict conversion via env.
    """
    v = DataValidator.safe_float_optional(x)
    if v is None or not math.isfinite(v) or v <= 0:
        return None

    # If already reasonable in ì–µì› (up to 2,000ì¡°), assume eokwon
    if v <= 20_000_000:  # 20,000,000 ì–µ = 2,000ì¡°
        logging.debug(f"[unit] market_cap assumed eokwon: {x} -> {v}")
        return v

    # If looks like KRW (ì›): anything â‰¥ 1e11 (1,000ì–µ ì›) convert to ì–µì›
    if v >= 1e11:
        converted = v / 1e8
        logging.debug(f"[unit] market_cap converted from wonâ†’eokwon: {x} -> {converted}")
        return converted

    # Ambiguous band (1e7 ~ 1e11): gate via env for safety (ìºì‹œëœ ê°’ ì‚¬ìš©)
    non_strict = _ENV_CACHE['market_cap_strict_mode'].lower() != "true"
    if non_strict and v >= 1e7:
        converted = v / 1e8
        logging.debug(f"[unit] market_cap non-strict (ambiguous) wonâ†’eokwon: {x} -> {converted} (ì²œë‹¨ìœ„ êµ¬ë¶„ í•´ì„ ê²°ê³¼)")
        return converted

    # Confidence logging when discarding ambiguous values
    if v >= 1e7:  # Only warn for values in ambiguous range
        logging.warning(f"[unit] market_cap ambiguous range dropped in strict mode: {x} -> None (1e7 â‰¤ v < 1e11)")
    else:
        logging.debug(f"[unit] market_cap too small (dropped): {x} -> None (ì²œë‹¨ìœ„ êµ¬ë¶„ í•´ì„ ê²°ê³¼)")
    return None

# íƒ€ì… ì •ì˜
JSONValue = Union[None, bool, int, float, str, List["JSONValue"], Dict[str, "JSONValue"]]
PeerTriple = Tuple[float, float, float]

# âœ… TypedDict ì •ì˜: ë°ì´í„° êµ¬ì¡° ë“œë¦¬í”„íŠ¸ ë°©ì§€ ë° ì—ë””í„° íŒíŠ¸ ê°œì„ 
class PriceData(TypedDict, total=False):
    """ê°€ê²© ë°ì´í„° êµ¬ì¡°"""
    current_price: Optional[float]
    w52_high: Optional[float]
    w52_low: Optional[float]
    per: Optional[float]
    pbr: Optional[float]
    eps: Optional[float]
    bps: Optional[float]
    volume: Optional[int]
    market_cap: Optional[float]
    price_change: Optional[float]
    price_change_rate: Optional[float]

class FinancialData(TypedDict, total=False):
    """ì¬ë¬´ ë°ì´í„° êµ¬ì¡°"""
    roe: Optional[float]
    roa: Optional[float]
    debt_ratio: Optional[float]
    equity_ratio: Optional[float]
    revenue_growth_rate: Optional[float]
    operating_income_growth_rate: Optional[float]
    net_income_growth_rate: Optional[float]
    net_profit_margin: Optional[float]
    gross_profit_margin: Optional[float]
    current_ratio: Optional[float]
    profitability_grade: Optional[str]

class SectorAnalysis(TypedDict, total=False):
    """ì„¹í„° ë¶„ì„ ê²°ê³¼ êµ¬ì¡°"""
    grade: str
    total_score: Optional[float]
    breakdown: Dict[str, float]
    is_leader: bool
    base_score: Optional[float]
    leader_bonus: float
    notes: List[str]

# =============================================================================
# ë¡œê¹… ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹°
# =============================================================================

# ---- ëŸ°íƒ€ì„ ë¡œê¹… ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´) ------------------------------------
_LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
_LOG_FMT = os.getenv(
    "LOG_FORMAT",
    "[%(asctime)s] %(levelname)s %(message)s"
)
# âœ… ë¡œê·¸ ì´ˆê¸°í™” íŒ¨í„´ ê°œì„ : ëª¨ë“ˆ import ì‹œì ì—ëŠ” ì„¤ì •í•˜ì§€ ì•Šê³ , ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œë§Œ ê¸°ë³¸ ë¡œê¹… ì„¤ì •
def _setup_logging_if_needed():
    """ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œë§Œ í˜¸ì¶œí•˜ì—¬ ê¸°ë³¸ ë¡œê¹… ì„¤ì •"""
    root = logging.getLogger()
    if not root.handlers:
        try:
            logging.basicConfig(
                level=getattr(logging, _LOG_LEVEL, logging.INFO),
                format=_LOG_FMT,
                datefmt="%H:%M:%S",
            )
        except Exception:
            # ì´ë¯¸ ë‹¤ë¥¸ í™˜ê²½ì—ì„œ í•¸ë“¤ëŸ¬ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìƒˆ í•¸ë“¤ëŸ¬ ì¶”ê°€ëŠ” ê±´ë„ˆëœ€
            if not root.handlers:
                logging.basicConfig(level=logging.INFO, format="%(levelname)s %(message)s")
            logging.warning("ë¡œê·¸ ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ì¡´ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
# ---------------------------------------------------------------------------

class LogLevel:
    """ë¡œê¹… ë ˆë²¨ ìƒìˆ˜"""
    ERROR = "error"
    WARNING = "warning"
    INFO = "info"
    DEBUG = "debug"

class ErrorType:
    """ì—ëŸ¬ íƒ€ì… ë¶„ë¥˜ ìƒìˆ˜ (ë©”íŠ¸ë¦­ìŠ¤ ì§‘ê³„ìš©)"""
    API_TIMEOUT = "api_timeout"
    API_CONNECTION = "api_connection"
    API_RATE_LIMIT = "api_rate_limit"
    DATA_PARSE = "data_parse"
    SECTOR_PEER_DATA = "sector_peer_data_error"
    FINANCIAL_DATA = "financial_data_error"
    PRICE_DATA = "price_data_error"
    STABILITY_RATIO = "stability_ratio_error"
    # âœ… ì¶”ê°€ëœ ì—ëŸ¬íƒ€ì… ìƒìˆ˜ë“¤
    OPINION = "opinion_analysis_error"
    ESTIMATE = "estimate_analysis_error"
    EMPTY_PRICE_PAYLOAD = "empty_price_payload"
    INVALID_52W_BAND = "invalid_52w_band"  # 52ì£¼ ë°´ë“œ ë¹ˆì•½/í‡´í™”
    HTTP_4XX = "http_4xx"
    HTTP_5XX = "http_5xx"
    UNKNOWN = "unknown_error"
    
    # ìƒìœ„ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (SRE ëŒ€ì‹œë³´ë“œìš©)
    CATEGORY_MAP = {
        API_TIMEOUT: "ë„¤íŠ¸ì›Œí¬",
        API_CONNECTION: "ë„¤íŠ¸ì›Œí¬", 
        API_RATE_LIMIT: "HTTP",
        HTTP_4XX: "HTTP",
        HTTP_5XX: "HTTP",
        DATA_PARSE: "ë°ì´í„°",
        FINANCIAL_DATA: "ë°ì´í„°",
        PRICE_DATA: "ë°ì´í„°",
        EMPTY_PRICE_PAYLOAD: "ë°ì´í„°",
        INVALID_52W_BAND: "ë°ì´í„°",
        SECTOR_PEER_DATA: "ë¶„ì„",
        STABILITY_RATIO: "ë¶„ì„",
        OPINION: "ë¶„ì„",
        ESTIMATE: "ë¶„ì„",
        UNKNOWN: "ê¸°íƒ€"
    }
    
    @classmethod
    def get_category(cls, error_type: str) -> str:
        """ì—ëŸ¬ íƒ€ì…ì„ ìƒìœ„ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘"""
        return cls.CATEGORY_MAP.get(error_type, "ê¸°íƒ€")

def log_error(operation: str, symbol: str = None, error: Exception = None, level: str = LogLevel.WARNING):
    """ì¼ê´€ëœ ì—ëŸ¬ ë¡œê¹… í¬ë§· (ìš´ì˜ ë¡œê·¸ grep ì¹œí™”ì )"""
    if symbol:
        message = f"{operation} ì‹¤íŒ¨ | symbol={symbol} | err={error}"
    else:
        message = f"{operation} ì‹¤íŒ¨ | err={error}"
    
    # âœ… LogLevel ê°’ ì¼ê´€ì„± ê°œì„ : ë ˆë²¨ ë§¤í•‘ ì‚¬ìš©
    LEVEL_MAP = {
        LogLevel.ERROR: logging.error,
        LogLevel.WARNING: logging.warning,
        LogLevel.INFO: logging.info,
        LogLevel.DEBUG: logging.debug
    }
    LEVEL_MAP.get(level, logging.warning)(message)

def log_success(operation: str, symbol: str = None, details: str = None):
    """ì¼ê´€ëœ ì„±ê³µ ë¡œê¹… í¬ë§·"""
    if symbol and details:
        message = f"âœ… {operation} ì„±ê³µ {symbol}: {details}"
    elif symbol:
        message = f"âœ… {operation} ì„±ê³µ {symbol}"
    else:
        message = f"âœ… {operation} ì„±ê³µ"
    
    logging.info(message)

def safe_env_int(key: str, default: int, min_val: Optional[int] = None) -> int:
    """ì•ˆì „í•œ í™˜ê²½ë³€ìˆ˜ ì •ìˆ˜ íŒŒì‹± (0=auto ì„¤ì • í—ˆìš©)"""
    try:
        value = int(os.getenv(key, str(default)))
    except (ValueError, TypeError):
        value = default
    if min_val is None:
        return value
    return max(min_val, value)

def safe_env_float(key: str, default: float, min_val: float = 0.0) -> float:
    """ì•ˆì „í•œ í™˜ê²½ë³€ìˆ˜ ì‹¤ìˆ˜ íŒŒì‹± (ìŒìˆ˜ ë°©ì–´)"""
    try:
        value = float(os.getenv(key, str(default)))
        return max(min_val, value)  # ìµœì†Œê°’ ë³´ì¥
    except (ValueError, TypeError):
        return max(min_val, default)

def safe_env_bool(key: str, default: bool = False) -> bool:
    """ì•ˆì „í•œ í™˜ê²½ë³€ìˆ˜ ë¶ˆë¦° íŒŒì‹± (robust parser)"""
    v = os.getenv(key)
    if v is None:
        return default
    return str(v).strip().lower() in {"1", "true", "t", "yes", "y", "on"}

def safe_env_ms_to_seconds(key: str, default_ms: float, min_ms: float = 0.0) -> float:
    """
    ë°€ë¦¬ì´ˆ(ms) í™˜ê²½ë³€ìˆ˜ë¥¼ ì´ˆ(second)ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜.
    RATE_LIMITER_MIN_SLEEP_MS ê°™ì€ í‚¤ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ì˜ëª» ì‚¬ìš©í•˜ëŠ” ë²„ê·¸ ë°©ì§€.
    """
    try:
        ms = float(os.getenv(key, str(default_ms)))
        ms = max(min_ms, ms)
    except (ValueError, TypeError):
        ms = max(min_ms, default_ms)
    return ms / 1000.0

# =============================================================================
# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í´ë˜ìŠ¤
# =============================================================================

class MetricsCollector:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ê´€ë¦¬"""
    
    def __init__(self):
        self.metrics = {
            'api_calls': {'total': 0, 'success': 0, 'error': 0},
            'cache_hits': {'price': 0, 'financial': 0, 'sector': 0},
            'cache_misses': {'price': 0, 'financial': 0, 'sector': 0},
            'analysis_duration': {'total': 0, 'count': 0, 'avg': 0},
            'sector_evaluation': {'total': 0, 'count': 0, 'avg': 0},
            'stocks_analyzed': 0,
            'errors_by_type': {},
            # âœ… ì„¹í„° í”¼ì–´ ìƒ˜í”Œ í¬ê¸° ë©”íŠ¸ë¦­ ì¶”ê°€
            'sector_sample_insufficient': 0,
            # âœ… ë©”íŠ¸ë¦­ ê°œì„ : missing í•„ë“œ ì¹´ìš´í„° ì¶”ê°€
            'missing_financial_fields': 0,
            # âœ… API ì¬ì‹œë„ ì¤‘ê°„ ì‹¤íŒ¨ ì¹´ìš´í„° ì¶”ê°€ (ì´ì¤‘ ì§‘ê³„ ë°©ì§€)
            'api_retry_attempt_errors': 0,
            # âœ… PER/PBR ìŠ¤í‚µ ë©”íŠ¸ë¦­ ì¶”ê°€
            'valuation_skips': {'per_epsmin': 0, 'pbr_bpsmin': 0},
            'start_time': _monotonic()
        }
        # Histogram buckets for duration analysis (seconds)
        # âœ… ë©”íŠ¸ë¦­ ê°œì„ : p95 ë°±ë¶„ìœ„ ì¶”ê°€ (SREê°€ ì£¼ë¡œ ì‚¬ìš©)
        # ìš´ì˜ ê¸°ì¤€: p90ì´ 5ì´ˆ, p95ê°€ 10ì´ˆ ë„˜ìœ¼ë©´ ê²½ê³  (SLO)
        self.duration_buckets = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
        self.analysis_histogram = [0] * (len(self.duration_buckets) + 1)  # +1 for overflow
        self.sector_histogram = [0] * (len(self.duration_buckets) + 1)
        self.lock = RLock()
    
    def record_api_call(self, success: bool, error_type: str = None):
        """API í˜¸ì¶œ ê¸°ë¡ (ìµœì¢… ê²°ê³¼ë§Œ)"""
        with self.lock:
            self.metrics['api_calls']['total'] += 1
            if success:
                self.metrics['api_calls']['success'] += 1
            else:
                self.metrics['api_calls']['error'] += 1
                if error_type:
                    self.metrics['errors_by_type'][error_type] = self.metrics['errors_by_type'].get(error_type, 0) + 1

    def record_api_attempt_error(self, error_type: str = None):
        """API ì¬ì‹œë„ ì¤‘ê°„ ì‹¤íŒ¨ ê¸°ë¡ (ì´ì¤‘ ì§‘ê³„ ë°©ì§€)"""
        with self.lock:
            self.metrics['api_retry_attempt_errors'] += 1
            if error_type:
                self.metrics['errors_by_type'][error_type] = self.metrics['errors_by_type'].get(error_type, 0) + 1
    
    def record_cache_hit(self, cache_type: str):
        """ìºì‹œ íˆíŠ¸ ê¸°ë¡"""
        with self.lock:
            self.metrics['cache_hits'].setdefault(cache_type, 0)
            self.metrics['cache_hits'][cache_type] += 1
    
    def record_cache_miss(self, cache_type: str):
        """ìºì‹œ ë¯¸ìŠ¤ ê¸°ë¡"""
        with self.lock:
            self.metrics['cache_misses'].setdefault(cache_type, 0)
            self.metrics['cache_misses'][cache_type] += 1
    
    def record_analysis_duration(self, duration: float):
        """ë¶„ì„ ì†Œìš” ì‹œê°„ ê¸°ë¡"""
        with self.lock:
            self.metrics['analysis_duration']['total'] += duration
            self.metrics['analysis_duration']['count'] += 1
            self.metrics['analysis_duration']['avg'] = (
                self.metrics['analysis_duration']['total'] / self.metrics['analysis_duration']['count']
            )
            # Record in histogram
            bucket_idx = self._find_bucket(duration, self.duration_buckets)
            self.analysis_histogram[bucket_idx] += 1
    
    def record_sector_evaluation(self, duration: float):
        """ì„¹í„° í‰ê°€ ì†Œìš” ì‹œê°„ ê¸°ë¡"""
        with self.lock:
            self.metrics['sector_evaluation']['total'] += duration
            self.metrics['sector_evaluation']['count'] += 1
            self.metrics['sector_evaluation']['avg'] = (
                self.metrics['sector_evaluation']['total'] / self.metrics['sector_evaluation']['count']
            )
            # Record in histogram
            bucket_idx = self._find_bucket(duration, self.duration_buckets)
            self.sector_histogram[bucket_idx] += 1
    
    def record_sector_sample_insufficient(self, sector_name: str = None):
        """ì„¹í„° í”¼ì–´ í‘œë³¸ ë¶€ì¡± ê¸°ë¡"""
        with self.lock:
            self.metrics['sector_sample_insufficient'] += 1
            if sector_name:
                if 'sector_sample_insufficient_by_sector' not in self.metrics:
                    self.metrics['sector_sample_insufficient_by_sector'] = {}
                self.metrics['sector_sample_insufficient_by_sector'][sector_name] = \
                    self.metrics['sector_sample_insufficient_by_sector'].get(sector_name, 0) + 1
    
    def record_missing_financial_fields(self, count: int = 1):
        """âœ… missing ì¬ë¬´ í•„ë“œ ì¹´ìš´í„°: ë°ì´í„° í’ˆì§ˆ ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§"""
        with self.lock:
            self.metrics['missing_financial_fields'] += count
    
    def record_stocks_analyzed(self, count: int):
        """ë¶„ì„ëœ ì¢…ëª© ìˆ˜ ê¸°ë¡"""
        with self.lock:
            self.metrics['stocks_analyzed'] += count
    
    def get_cache_hit_rate(self, cache_type: str) -> float:
        """ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°"""
        with self.lock:
            hits = self.metrics['cache_hits'].get(cache_type, 0)
            misses = self.metrics['cache_misses'].get(cache_type, 0)
            total = hits + misses
            return (hits / total * 100.0) if total > 0 else 0.0
    
    def get_api_success_rate(self) -> float:
        """API ì„±ê³µë¥  ê³„ì‚°"""
        with self.lock:
            total = self.metrics['api_calls']['total']
            success = self.metrics['api_calls']['success']
            return (success / total * 100) if total > 0 else 0.0
    
    def _find_bucket(self, value: float, buckets: List[float]) -> int:
        """Find histogram bucket index for a value"""
        for i, bucket in enumerate(buckets):
            if value <= bucket:
                return i
        return len(buckets)  # Overflow bucket
    
    def get_percentiles(self, histogram: List[int], buckets: List[float], percentile: float) -> float:
        """Calculate percentile from histogram"""
        total = sum(histogram)
        if total == 0:
            return 0.0
        
        target = total * (percentile / 100.0)
        cumulative = 0
        
        for i, count in enumerate(histogram):
            cumulative += count
            if cumulative >= target:
                if i < len(buckets):
                    return buckets[i]
                else:
                    return buckets[-1] * 2  # Estimate for overflow
        return buckets[-1] * 2
    
    def get_summary(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìš”ì•½ ë°˜í™˜"""
        with self.lock:
            # SLO ê²½ê³  ì²´í¬
            p90 = self.get_percentiles(self.analysis_histogram, self.duration_buckets, 90)
            p95 = self.get_percentiles(self.analysis_histogram, self.duration_buckets, 95)
            if p90 > 5.0:
                logging.warning(f"[SLO] ë¶„ì„ p90 {p90:.1f}s > 5s")
            if p95 > 10.0:
                logging.warning(f"[SLO] ë¶„ì„ p95 {p95:.1f}s > 10s")
            
            # ìƒìœ„ ì¹´í…Œê³ ë¦¬ë³„ ì—ëŸ¬ ì§‘ê³„ (SRE ëŒ€ì‹œë³´ë“œìš©)
            errors_by_category = {}
            for error_type, count in self.metrics['errors_by_type'].items():
                category = ErrorType.get_category(error_type)
                errors_by_category[category] = errors_by_category.get(category, 0) + count
            
            return {
                'runtime_seconds': _monotonic() - self.metrics['start_time'],
                'stocks_analyzed': self.metrics['stocks_analyzed'],
                'api_calls': self.metrics['api_calls'].copy(),
                'api_success_rate': self.get_api_success_rate(),
                'cache_hit_rates': {
                    'price': self.get_cache_hit_rate('price'),
                    'financial': self.get_cache_hit_rate('financial'),
                    'sector': self.get_cache_hit_rate('sector')
                },
                'avg_analysis_duration': self.metrics['analysis_duration']['avg'],
                'avg_sector_evaluation': self.metrics['sector_evaluation']['avg'],
                'errors_by_type': self.metrics['errors_by_type'].copy(),
                'errors_by_category': errors_by_category,  # SRE ëŒ€ì‹œë³´ë“œìš© ìƒìœ„ ì¹´í…Œê³ ë¦¬
                'sector_sample_insufficient': self.metrics['sector_sample_insufficient'],
                'sector_sample_insufficient_by_sector': self.metrics.get('sector_sample_insufficient_by_sector', {}),
                'analysis_p50': self.get_percentiles(self.analysis_histogram, self.duration_buckets, 50),
                'analysis_p90': p90,
                'analysis_p95': p95,
                'sector_p50': self.get_percentiles(self.sector_histogram, self.duration_buckets, 50),
                'sector_p90': self.get_percentiles(self.sector_histogram, self.duration_buckets, 90),
                'sector_p95': self.get_percentiles(self.sector_histogram, self.duration_buckets, 95)
            }

# Safer price/52w checks
def _none_if_missing_strict(x):
    """Return None if value is truly missing, keep 0.0 if provider returns it"""
    v = DataValidator.safe_float_optional(x)
    return v  # keep 0.0 if provider truly returns it

# Safe formatter for consistent number display
def fmt(x, suffix='', nd=1):
    """Centralized number formatter that handles None/NaN consistently"""
    try:
        if x is None or not math.isfinite(float(x)):
            return "N/A"
        return f"{float(x):.{nd}f}{suffix}"
    except Exception:
        return "N/A"

def fmt_pct(x, nd=1):
    """Percentage formatter that avoids N/A%"""
    v = DataValidator.safe_float_optional(x)
    return f"{v:.{nd}f}%" if v is not None else "N/A"


# API ì¬ì‹œë„ ìœ í‹¸ (ë°±ì˜¤í”„+ì§€í„°) - expanded transient error handling
try:
    from requests.exceptions import Timeout as ReqTimeout, ReadTimeout, ConnectTimeout, ConnectionError as ReqConnErr, HTTPError
except ImportError:
    class ReqTimeout(Exception): ...
    class ReadTimeout(Exception): ...
    class ConnectTimeout(Exception): ...
    class ReqConnErr(Exception): ...
    class HTTPError(Exception): ...

import socket

def _classify_http_error(e: Exception) -> Tuple[bool, str, Optional[int]]:
    """HTTPErrorë¥¼ ì¬ì‹œë„ ì—¬ë¶€/ì—ëŸ¬íƒ€ì…/ìƒíƒœì½”ë“œë¡œ ë¶„ë¥˜"""
    status = None
    if isinstance(e, HTTPError) and getattr(e, "response", None) is not None:
        try:
            status = e.response.status_code
        except Exception:
            status = None
    # 429: ë ˆì´íŠ¸ë¦¬ë°‹ â†’ ì¬ì‹œë„
    if status == 429:
        return True, ErrorType.API_RATE_LIMIT, status
    # ê²Œì´íŠ¸ì›¨ì´/ì„œë²„ ê³„ì—´ â†’ ì¬ì‹œë„
    if status in (500, 502, 503, 504):
        return True, ErrorType.HTTP_5XX, status
    # ë‚˜ë¨¸ì§€ 4xxëŠ” í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ â†’ ì¬ì‹œë„ ê¸ˆì§€
    if status is not None and 400 <= status < 500:
        return False, ErrorType.HTTP_4XX, status
    # ìƒíƒœì½”ë“œ ë¶ˆëª…: ì¬ì‹œë„ ë¹„ê²°ì • â†’ ì¼ë°˜ ë„¤íŠ¸ì›Œí¬ ë¶„ë¥˜ì— ìœ„ì„
    # ë¡œê¹…ì— ìƒíƒœì½”ë“œê°€ ì—†ë‹¤ëŠ” ì ì„ ëª…í™•íˆ ë‚¨ê¸°ë©´ ìš´ì˜ ë¶„ì„ì´ í¸í•¨
    if status is None:
        logging.debug(f"[retry] HTTPError with status=None, treating as UNKNOWN for retry decision")
    return True, ErrorType.UNKNOWN, status

TRANSIENT_ERRORS = (TimeoutError, ReqTimeout, ReadTimeout, ConnectTimeout, ReqConnErr, socket.timeout, HTTPError)
def _with_retries(call, tries=5, base=0.5, jitter=0.3, retry_on=TRANSIENT_ERRORS, max_total_sleep=15.0, metrics_attempt=None, metrics_final=None):
    """API í˜¸ì¶œ ì¬ì‹œë„ ë˜í¼ (ì„ ë³„ì  ì¬ì‹œë„ + ì´ ì†Œìš” ìƒí•œ)"""
    slept = 0.0
    for i in range(tries):
        try:
            result = call()
            # ì„±ê³µ ì‹œì—ëŠ” ìµœì¢… ê²°ê³¼ë§Œ ê¸°ë¡ (ì´ì¤‘ ì§‘ê³„ ë°©ì§€)
            if metrics_final:
                try:
                    metrics_final(success=True, error_type=None)
                except Exception:
                    pass
            return result
        except Exception as e:
            # HTTP ì˜¤ë¥˜ ì •êµ ë¶„ë¥˜
            et = ErrorType.UNKNOWN
            if isinstance(e, (ReqTimeout, ReadTimeout, ConnectTimeout, TimeoutError, socket.timeout)):
                et = ErrorType.API_TIMEOUT
            elif isinstance(e, ReqConnErr):
                et = ErrorType.API_CONNECTION
            elif isinstance(e, HTTPError):
                should_retry, et_http, status = _classify_http_error(e)
                et = et_http
                if not should_retry:
                    # HTTP 4xx ë“± ì¬ì‹œë„ ê¸ˆì§€ ì˜¤ë¥˜ëŠ” ì¦‰ì‹œ final ê¸°ë¡ í›„ ì¢…ë£Œ
                    if metrics_final:
                        try: metrics_final(success=False, error_type=et)
                        except Exception: pass
                    raise  # â† ì—¬ê¸°ì„œ ë°”ë¡œ íƒˆì¶œí•˜ë¯€ë¡œ retry_on ê²½ë¡œì™€ ê²©ë¦¬ë¨
                # HTTP 5xx/429 ë“± ì¬ì‹œë„ ê°€ëŠ¥í•œ ì˜¤ë¥˜ëŠ” ì•„ë˜ retry_on ê²½ë¡œë¡œ ê³„ì†
            
            # ì‹¤íŒ¨í–ˆìœ¼ë‚˜ ì¬ì‹œë„í•  ê²½ìš°ì—ë§Œ attempt ê¸°ë¡ (HTTP 4xxëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)
            if i < tries - 1 and isinstance(e, retry_on):
                if metrics_attempt:
                    try:
                        metrics_attempt(error_type=et)  # â† record_api_attempt_errorë§Œ í˜¸ì¶œ
                    except Exception:
                        pass
            else:
                # ìµœì¢… ì‹¤íŒ¨ëŠ” finalë§Œ ê¸°ë¡ (attempt ë¯¸ê¸°ë¡ ë³´ì¥)
                if metrics_final:
                    try:
                        metrics_final(success=False, error_type=et)
                    except Exception:
                        pass
                raise

            backoff = base * (2 ** i) + random.uniform(0, jitter)
            if slept + backoff > max_total_sleep:
                backoff = max(0.0, max_total_sleep - slept)
            if backoff > 0:
                time.sleep(backoff)
                slept += backoff
from concurrent.futures import ThreadPoolExecutor, as_completed

# ë¡œê¹… ì„¤ì •ì€ ë©”ì¸ ì‹¤í–‰ë¶€ì—ì„œ ì´ˆê¸°í™”
# rich import ì œê±° (ë¯¸ì‚¬ìš©)
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum

# ê¸°ì¡´ importë“¤ (ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨)
try:
    from kis_data_provider import KISDataProvider
    from enhanced_price_provider import EnhancedPriceProvider
    from investment_opinion_analyzer import InvestmentOpinionAnalyzer
    from estimate_performance_analyzer import EstimatePerformanceAnalyzer
    from financial_ratio_analyzer import FinancialRatioAnalyzer
    from profit_ratio_analyzer import ProfitRatioAnalyzer
    from stability_ratio_analyzer import StabilityRatioAnalyzer
    from test_integrated_analysis import create_integrated_analysis
except ImportError as e:
    logging.error(f"âŒ í•„ìˆ˜ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    if safe_env_bool("ENABLE_FAKE_PROVIDERS", False):
        logging.warning("ENABLE_FAKE_PROVIDERS=true â†’ ë”ë¯¸ êµ¬í˜„ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
        class KISDataProvider:
            def __init__(self): pass
            def get_stock_price_info(self, symbol): 
                return {'per': 15.0, 'pbr': 1.2, 'eps': 1000.0, 'bps': 8000.0}
            def get_financial_ratios(self, symbol): 
                return [{'roe': 12.5, 'roa': 8.0, 'debt_ratio': 30.0}]
            def get_profit_ratios(self, symbol): 
                return [{'gross_margin': 25.0, 'operating_margin': 15.0, 'net_margin': 10.0}]
            def get_stability_ratios(self, symbol): 
                return [{'current_ratio': 1.5, 'quick_ratio': 1.2, 'debt_to_equity': 0.4}]
        
        class EnhancedPriceProvider:
            def get_comprehensive_price_data(self, symbol): 
                return {'per': 15.0, 'pbr': 1.2, 'eps': 1000.0, 'bps': 8000.0, 'market_cap': 500000000000}
        
        class InvestmentOpinionAnalyzer:
            def analyze_single_stock(self, symbol, days_back=30): 
                return {'buy': 5, 'hold': 3, 'sell': 1, 'target_price': 50000}
        
        class EstimatePerformanceAnalyzer:
            def analyze_single_stock(self, symbol): 
                return {'accuracy': 0.75, 'bias': 0.05, 'revision_trend': 'up'}
        
        class FinancialRatioAnalyzer:
            def get_financial_ratios(self, symbol): 
                return [{'roe': 12.5, 'roa': 8.0, 'debt_ratio': 30.0}]
        
        class ProfitRatioAnalyzer:
            def get_profit_ratios(self, symbol): 
                return [{'gross_margin': 25.0, 'operating_margin': 15.0, 'net_margin': 10.0}]
        
        class StabilityRatioAnalyzer:
            def get_stability_ratios(self, symbol): 
                return [{'current_ratio': 1.5, 'quick_ratio': 1.2, 'debt_to_equity': 0.4}]
        
        def create_integrated_analysis(opinion, estimate): 
            return {'score': 75.0, 'recommendation': 'BUY', 'confidence': 0.8}
    else:
        logging.error("ğŸ’¡ í•´ê²°: ëª¨ë“ˆ ê²½ë¡œ/ì„¤ì¹˜ í™•ì¸ ë˜ëŠ” ENABLE_FAKE_PROVIDERS=true")
        raise

# =============================================================================
# 1. ë°ì´í„° í´ë˜ìŠ¤ ë° ì—´ê±°í˜•
# =============================================================================

class AnalysisStatus(Enum):
    """ë¶„ì„ ìƒíƒœ ì—´ê±°í˜•"""
    SUCCESS = "success"
    ERROR = "error"
    SKIPPED_PREF = "skipped_pref"
    NO_DATA = "no_data"


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    symbol: str
    name: str
    status: AnalysisStatus
    enhanced_score: float = 0.0
    enhanced_grade: str = 'F'
    market_cap: float = 0.0
    current_price: float = 0.0
    price_position: Optional[float] = None
    price_band_outside: bool = False  # 52ì£¼ ë°´ë“œ ë°– ì—¬ë¶€ í”Œë˜ê·¸
    risk_score: Optional[float] = None
    financial_data: FinancialData = field(default_factory=dict)
    opinion_analysis: Dict[str, Any] = field(default_factory=dict)
    estimate_analysis: Dict[str, Any] = field(default_factory=dict)
    integrated_analysis: Dict[str, Any] = field(default_factory=dict)
    risk_analysis: Dict[str, Any] = field(default_factory=dict)
    score_breakdown: Dict[str, float] = field(default_factory=dict)
    error: Optional[str] = None
    price_data: PriceData = field(default_factory=dict)  # ê°€ê²© ë°ì´í„° ìºì‹±ìš©
    sector_analysis: Dict[str, Any] = field(default_factory=dict)  # ì„¹í„° ë¶„ì„ ê²°ê³¼
    

@dataclass(frozen=True)
class AnalysisConfig:
    """ë¶„ì„ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤ (ë¶ˆë³€)"""
    weights: Dict[str, float]
    financial_ratio_weights: Dict[str, float]
    estimate_analysis_weights: Dict[str, float]
    grade_thresholds: Dict[str, float]
    growth_score_thresholds: Dict[str, float]
    scale_score_thresholds: Dict[str, float]

# =============================================================================
# 2. ì¶”ìƒ í´ë˜ìŠ¤ ë° ì¸í„°í˜ì´ìŠ¤
# =============================================================================

class DataProvider(ABC):
    """ë°ì´í„° ì œê³µì ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def get_financial_data(self, symbol: str) -> Dict[str, Any]:
        """ì¬ë¬´ ë°ì´í„° ì¡°íšŒ"""
        pass
    
    @abstractmethod
    def get_price_data(self, symbol: str) -> Dict[str, Any]:
        """ê°€ê²© ë°ì´í„° ì¡°íšŒ"""
        pass

class ScoreCalculator(ABC):
    """ì ìˆ˜ ê³„ì‚°ê¸° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def calculate_score(self, data: Dict[str, Any], **kwargs) -> Tuple[float, Dict[str, float]]:
        """ì ìˆ˜ ê³„ì‚°"""
        pass

# =============================================================================
# 3. ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ë“¤
# =============================================================================

class TPSRateLimiter:
    """KIS OpenAPI TPS ì œí•œì„ ê³ ë ¤í•œ ë ˆì´íŠ¸ë¦¬ë¯¸í„° (Condition ê¸°ë°˜ ê°œì„ )"""
    
    def __init__(self, max_tps: int = None):
        self.max_tps = max_tps or safe_env_int("KIS_MAX_TPS", 8, 1)
        self.ts = deque()
        self.cv = Condition()
        # ì§€í„° ìƒí•œì„ í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì • ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
        self.jitter_max = safe_env_float("RATE_LIMITER_JITTER_MAX", 0.004, 0.0)
        # âœ… notify_all í† ê¸€ ì˜µì…˜ (ê³ TPS í™˜ê²½ì—ì„œ ê³µí‰í•œ ì›¨ì´í¬ì—…)
        self.notify_all = safe_env_bool("RATE_LIMITER_NOTIFY_ALL", False)
        # âœ… ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ ì˜µì…˜ (ê½‰ ë§‰í˜ ë°©ì§€)
        self.default_timeout = safe_env_float("RATE_LIMITER_DEFAULT_TIMEOUT", 2.0, 0.1)
        # âœ… ë°€ë¦¬ì´ˆ â†’ ì´ˆ ë³€í™˜ (ê¸°ì¡´ ë²„ê·¸: msë¥¼ ì´ˆë¡œ ì˜¤í•´)
        # RATE_LIMITER_MIN_SLEEP_MS: ë°€ë¦¬ì´ˆ ë‹¨ìœ„ (ê¸°ë³¸ê°’: 2.0ms, ìµœì†Œê°’: 1.0ms)
        self.min_sleep_seconds = safe_env_ms_to_seconds("RATE_LIMITER_MIN_SLEEP_MS", 2.0, 1.0)
    
    def acquire(self, timeout: float = None):
        """ìš”ì²­ í—ˆê°€ë¥¼ ë°›ìŠµë‹ˆë‹¤ (íƒ€ì„ì•„ì›ƒ ì§€ì›)."""
        timeout = self.default_timeout if timeout is None else timeout
        start = _monotonic()
        with self.cv:
            while True:
                now = _monotonic()
                # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì •ë¦¬(í•­ìƒ ìˆ˜í–‰)
                one_sec_ago = now - 1.0
                old_count = len(self.ts)
                while self.ts and self.ts[0] < one_sec_ago:
                    self.ts.popleft()
                # ì˜¤ë˜ëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° í›„ ëŒ€ê¸°ìë“¤ì—ê²Œ ì•Œë¦¼
                if len(self.ts) < old_count:
                    if self.notify_all:
                        self.cv.notify_all()
                    else:
                        self.cv.notify()

                if len(self.ts) < self.max_tps:
                    self.ts.append(now)
                    # í† í° íšë“ í›„ ëŒ€ê¸°ìë“¤ì—ê²Œ ì•Œë¦¼
                    if self.notify_all:
                        self.cv.notify_all()
                    else:
                        self.cv.notify()
                    break

                waited = now - start
                if timeout is not None and waited >= timeout:
                    logging.warning(f"[ratelimiter] acquire timeout (max_tps={self.max_tps})")
                    raise TimeoutError(f"Rate limiter acquire() timed out after {timeout:.1f}s (max_tps={self.max_tps}, in_window={len(self.ts)})")

                # ë‹¤ìŒ í•´ì œ ì‹œì ê¹Œì§€ ê¸°ë‹¤ë¦¼ (ì •í™•í•œ ëŒ€ê¸° + ìŠ¤í•€ ë°©ì§€)
                earliest = self.ts[0]
                wait_for = max(0.0, (earliest + 1.0) - now)
                # ê³ TPS í™˜ê²½ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­/ìŠ¤í•€ ê°ì†Œ: ms ì„¤ì •ì„ ì´ˆë¡œ ë³€í™˜í•´ ì‚¬ìš©
                min_sleep = self.min_sleep_seconds  # e.g., 2ms â†’ 0.002s
                sleep_for = max(wait_for + random.uniform(0.0, self.jitter_max), min_sleep)
                if waited > 1.0:
                    logging.debug(f"[ratelimiter] waited={waited:.3f}s, in_window={len(self.ts)}, next={sleep_for:.3f}s")
                self.cv.wait(sleep_for)
    

class ConfigManager:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_file: str = "config.yaml"):
        self.config_file = config_file
        self._config_cache = None
        self._last_modified = 0
    
    def load_config(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
            current_modified = os.path.getmtime(self.config_file)
            if self._config_cache and current_modified <= self._last_modified:
                return self._config_cache
            
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            self._config_cache = config
            self._last_modified = current_modified
            return config
            
        except Exception as e:
            logging.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            'enhanced_integrated_analysis': {
                'weights': {
                    'opinion_analysis': 25,
                    'estimate_analysis': 30,
                    'financial_ratios': 30,
                    'growth_analysis': 10,
                    'scale_analysis': 5,
                    'price_position': 5
                },
                'financial_ratio_weights': {
                    'roe_score': 8,
                    'roa_score': 5,
                    'debt_ratio_score': 7,
                    'net_profit_margin_score': 5,
                    'current_ratio_score': 3,
                    'growth_score': 2
                },
                'estimate_analysis_weights': {
                    'financial_health': 15,
                    'valuation': 15
                },
                'grade_thresholds': {
                    'A_plus': 80,
                    'A': 70,
                    'B_plus': 60,
                    'B': 50,
                    'C_plus': 40,
                    'C': 30,
                    'D_plus': 20,
                    'D': 10,
                    'F': 0
                },
                'growth_score_thresholds': {
                    'excellent': 20,
                    'good': 10,
                    'average': 0,
                    'poor': -10
                },
                'scale_score_thresholds': {
                    'mega_cap': 100000,
                    'large_cap': 50000,
                    'mid_large_cap': 10000,
                    'mid_cap': 5000,
                    'small_cap': 1000
                }
            }
        }

class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""
    
    @staticmethod
    def _finite(val: Any, default: float = 0.0) -> float:
        """NaN/Inf í´ë¦°ì—… ìœ í‹¸"""
        try:
            x = float(val)
            if math.isfinite(x):
                return x
        except Exception:
            pass
        return default
    
    @staticmethod
    def safe_divide(numerator: Any, denominator: Any, default: float = None, allow_negative_den: bool = False) -> Optional[float]:
        """ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ - NaN/Inf ë°©ì§€.
        Note: ë¶„ëª¨<=0 ì¸ ê²½ìš° default ë°˜í™˜ (PER/PBRì²˜ëŸ¼ ìŒìˆ˜/0ê°’ì´ ë¬´ì˜ë¯¸í•œ ì§€í‘œì— ë§ì¶¤)."""
        try:
            num = DataValidator._finite(numerator)
            den = DataValidator._finite(denominator)
            
            # ë¶„ëª¨ê°€ 0ì´ê±°ë‚˜ (ìŒìˆ˜ í—ˆìš©í•˜ì§€ ì•Šìœ¼ë©´) ìŒìˆ˜ë©´ default ë°˜í™˜
            if den == 0 or (den < 0 and not allow_negative_den):
                return default
            
            result = num / den
            if math.isfinite(result):
                return result
            else:
                return default
        except Exception:
            return default
    
    @staticmethod
    def safe_float(value: Any, default: float = 0.0) -> float:
        """ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜ (ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ì§€ì›)"""
        try:
            if value is None or pd.isna(value):
                return default
            if isinstance(value, str):
                v = value.strip().replace(',', '')
                if v == '':
                    return default
                return float(v)
            return float(value)
        except (ValueError, TypeError):
            return default
    
    @staticmethod
    def safe_float_optional(value: Any) -> Optional[float]:
        """ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜í•˜ë˜ ê²°ì¸¡ì¹˜ëŠ” Noneìœ¼ë¡œ ë³´ì¡´ (ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ì§€ì›)"""
        try:
            if value is None or pd.isna(value):
                return None
            if isinstance(value, float):
                return value if math.isfinite(value) else None
            if isinstance(value, str):
                v = value.strip().replace(',', '')
                if v == '':
                    return None
                x = float(v)
                return x if math.isfinite(x) else None
            x = float(value)
            return x if math.isfinite(x) else None
        except (ValueError, TypeError):
            return None
    
    @staticmethod
    def is_valid_symbol(symbol: str) -> bool:
        """ì¢…ëª© ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬"""
        if not symbol or not isinstance(symbol, str):
            return False
        import re
        return bool(re.match(r'^\d{6}$', symbol.strip()))
    
    @staticmethod
    def is_preferred_stock(name: str) -> bool:
        """ìš°ì„ ì£¼ ì—¬ë¶€ í™•ì¸ (ê°•í™”ëœ ì •ê·œì‹)"""
        if not name or not isinstance(name, str):
            return False
        s = name.strip()
        
        # âœ… í™˜ê²½ë³€ìˆ˜ë¡œ "ìš°ë¦¬" ì‹œì‘ ì¢…ëª©ì„ ìš°ì„ ì£¼ë¡œ ê°„ì£¼í• ì§€ ì œì–´ (ê¸°ë³¸ê°’: False = ê°„ì£¼ ì•ˆí•¨)
        if safe_env_bool("PREFERRED_STOCK_INCLUDE_WOORI", False) and s.startswith("ìš°ë¦¬"):
            return True
            
        import re
        # KRX ìŠ¤íƒ€ì¼ ì ‘ë¯¸ì‚¬ì™€ ëª…ì‹œì  í‚¤ì›Œë“œ (ë„ì–´ì“°ê¸°/íŠ¹ìˆ˜ë¬¸ì ë³€í˜• í—ˆìš©)
        # ë” ì—„ê²©í•œ íŒ¨í„´: ê´„í˜¸ í‘œê¸°, ëª…ì‹œì  í‚¤ì›Œë“œ, ìš°ì„ ì£¼ ì ‘ë¯¸ì‚¬ë§Œ í—ˆìš©
        pat = re.compile(r"(?:\((?:ìš°|ìš°B|ìš°C)\)|\bìš°ì„ ì£¼\b|(?:\s|^)ìš°(?:B|C)?$)")
        return bool(pat.search(s))
    
    @staticmethod
    def _getattr_or_get(d, key, default=None):
        """ê°ì²´/ë”•ì…”ë„ˆë¦¬ ì•ˆì „ ì ‘ê·¼ ìœ í‹¸"""
        try:
            return getattr(d, key)
        except Exception:
            try:
                return d.get(key, default)
            except Exception:
                return default

# =============================================================================
# JSON ì§ë ¬í™” ìœ í‹¸ (NumPy/Datetime/Decimal ì•ˆì „)
# =============================================================================
def serialize_for_json(obj: Any) -> JSONValue:
    """
    Convert various Python/NumPy/Decimal/Datetime containers to JSON-serializable.
    - Handles: dict/list/tuple/set, numpy scalars/arrays, Decimal, datetime/date, objects with __dict__
    """
    import numpy as np
    from datetime import date, datetime

    if obj is None or isinstance(obj, (str, int, float, bool)):
        return obj
    if isinstance(obj, Decimal):
        return float(obj)
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    if hasattr(obj, "tolist"):  # numpy arrays
        try:
            return obj.tolist()
        except Exception:
            pass
    # numpy scalar heuristic
    if obj.__class__.__module__ == "numpy":
        try:
            return obj.item()
        except Exception:
            pass
    if isinstance(obj, dict):
        return {serialize_for_json(k): serialize_for_json(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple, set)):
        return [serialize_for_json(x) for x in obj]
    if hasattr(obj, "__dict__"):
        return {k: serialize_for_json(v) for k, v in obj.__dict__.items()}
    return str(obj)


class DataConverter:
    """ë°ì´í„° ë³€í™˜ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    # í¼ì„¼íŠ¸ì„± ì§€í‘œ í•„ë“œ ì •ì˜ (ì´ì¤‘ ìŠ¤ì¼€ì¼ë§ ë°©ì§€)
    PERCENT_FIELDS = {
        "roe", "roa", "revenue_growth_rate", "operating_income_growth_rate",
        "net_income_growth_rate", "net_profit_margin", "gross_profit_margin",
        "debt_ratio", "equity_ratio", "current_ratio"
    }
    
    
    @staticmethod
    def to_percent(x: Any) -> float:
        """í¼ì„¼íŠ¸ ë‹¨ìœ„ë¡œ ê°•ì œ ë³€í™˜ (ì´ì¤‘ ìŠ¤ì¼€ì¼ë§ ë°©ì§€, ë¶€í˜¸ ë³´ì¡´)"""
        v = DataValidator.safe_float(x, 0.0)
        # |v|<=5ë©´ ë¹„ìœ¨ë¡œ ë³´ê³  Ã—100, ë¶€í˜¸ ìœ ì§€
        return v * 100.0 if abs(v) <= 5.0 else v
    
    @staticmethod
    def normalize_percentage(value: Any, assume_ratio_if_abs_lt_1: bool = True) -> Optional[float]:
        """í¼ì„¼íŠ¸ ê°’ì„ ì •ê·œí™” (0.12 â†’ 12.0)"""
        try:
            v = float(value)
            if pd.isna(v):
                return None
            return v * 100.0 if assume_ratio_if_abs_lt_1 and -1.0 <= v <= 1.0 else v
        except Exception:
            return None
    
    @staticmethod
    def format_percentage(value: Any, decimal_places: int = 1) -> str:
        """í¼ì„¼íŠ¸ ê°’ í¬ë§·íŒ…"""
        try:
            if value is None or pd.isna(value):
                return "N/A"
            v = float(value)
            return f"{v:.{decimal_places}f}%"
        except Exception:
            return "N/A"
    
    @staticmethod
    def standardize_financial_units(data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì¬ë¬´ ë°ì´í„° ë‹¨ìœ„ í‘œì¤€í™” (í¼ì„¼íŠ¸ì„± ì§€í‘œ % ë‹¨ìœ„ í†µì¼)
        - ê²°ì¸¡ì¹˜ëŠ” Noneìœ¼ë¡œ ë³´ì¡´í•˜ì—¬ ì´í›„ ìŠ¤ì½”ì–´ëŸ¬ì—ì„œ 'ë¶€ë¶„ ê²°ì¸¡ ê°€ì¤‘ì¹˜ ì¬ì •ê·œí™”'ê°€ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        
        âš ï¸ ì¤‘ìš”: % ë‹¨ìœ„ëŠ” ì´ í•¨ìˆ˜ì—ì„œë§Œ ë³€í™˜ë©ë‹ˆë‹¤. ì´í›„ íŒŒì´í”„ë¼ì¸ì—ì„œ ê°™ì€ í•„ë“œì— ì¶”ê°€ ë³€í™˜ ê¸ˆì§€.
        
        # DO NOT convert % units again after this point.
        # Any additional scaling will create double-scaling bugs (e.g., 0.03 -> 3 -> 300).
        """
        # í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì •ì±…ì´ ë°”ë€Œì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì§„ì… ì‹œì ì— ìºì‹œë¥¼ ê°±ì‹ 
        try:
            _refresh_env_cache()
        except Exception:
            pass
        out = data.copy()

        # 1) í¼ì„¼íŠ¸ í•„ë“œëŠ” ë¹„ìœ¨í˜•(<=5) â†’ %ë¡œ ë³€í™˜, ê²°ì¸¡ì€ None ìœ ì§€
        for k in DataConverter.PERCENT_FIELDS:
            if k in out:
                v = out[k]
                if v is None or (isinstance(v, float) and (not math.isfinite(v))):
                    out[k] = None
                else:
                    # âœ… current_ratio í¼ì„¼íŠ¸ í•´ì„ ê³ ì •: ê³µê¸‰ì›ì´ í¼ì„¼íŠ¸/ë°°ìˆ˜ í˜¼ì¬ ê°€ëŠ¥ â†’ ë³´ìˆ˜ì  ê°€ë“œ
                    if k == "current_ratio":
                        vv = DataValidator.safe_float_optional(v)
                        if vv is None:
                            out[k] = None
                        else:
                            # í™˜ê²½ë³€ìˆ˜ ê°€ë“œ: ê°•ì œ % í•´ì„ ëª¨ë“œ (ìºì‹œëœ ê°’ ì‚¬ìš©)
                            force_percent = _ENV_CACHE['current_ratio_force_percent'].lower() == "true"
                            
                            if force_percent:
                                # ê°•ì œ % ëª¨ë“œ: 0~5ëŠ” ë°°ìˆ˜ë¡œ ë³´ê³  %ë¡œ ë³€í™˜, ë‚˜ë¨¸ì§€ëŠ” %ë¡œ ê°„ì£¼
                                out[k] = vv * 100.0 if 0.0 <= vv <= 5.0 else vv
                                logging.debug(f"[unit] current_ratio force percent mode: {v} -> {out[k]} (0-5 range check applied)")
                            elif 0.0 <= vv <= 10.0:
                                out[k] = vv * 100.0
                                logging.debug(f"[unit] current_ratio treated as multiple: {v} -> {vv*100}")
                            elif vv >= 50.0:
                                out[k] = vv
                                logging.debug(f"[unit] current_ratio assumed as percent: {v} -> {vv}")
                            else:
                                # 10~50 ì‚¬ì´ ì• ë§¤ êµ¬ê°„ ì²˜ë¦¬ ì „ëµ (ìºì‹œëœ ê°’ ì‚¬ìš©)
                                ambiguous_strategy = _ENV_CACHE['current_ratio_ambiguous_strategy'].lower()
                                if ambiguous_strategy == "clamp":
                                    # í´ë¨í”„ ëª¨ë“œ: í•©ë¦¬ì  ë²”ìœ„ë¡œ ì œí•œ [10, 300]
                                    clamped = max(10.0, min(300.0, vv))
                                    out[k] = clamped
                                    logging.debug(f"[unit] current_ratio ambiguous range (clamped): {v} -> {clamped} (treated as %)")
                                else:  # as_is
                                    # as_is ëª¨ë“œ: ì›ë³¸ ê°’ ìœ ì§€ (outlier ê°€ë“œë§Œ)
                                    out[k] = vv
                                    if not (0.0 <= vv <= 10000.0):
                                        logging.debug(f"[unit] current_ratio outlier left as-is: {vv}")
                    else:
                        out[k] = DataConverter.enforce_canonical_percent(v, field_name=k)
                    # í•„ë“œë³„ í´ë¨í”„ ìƒí•œ ë¶„ë¦¬ (ê·¹ë‹¨ê°’ ë°©ì§€)
                    if out[k] is not None:
                        if k in ["roe", "roa"]:
                            # ìˆ˜ìµì„± ì§€í‘œ: 5,000% ìƒí•œ
                            if abs(out[k]) > 5000.0:
                                out[k] = math.copysign(5000.0, out[k])
                        elif k in ["revenue_growth_rate", "operating_income_growth_rate", "net_income_growth_rate"]:
                            # ì„±ì¥ë¥ : 1,000% ìƒí•œ
                            if abs(out[k]) > 1000.0:
                                out[k] = math.copysign(1000.0, out[k])
                        else:
                            # ê¸°íƒ€: 10,000% ìƒí•œ
                            if abs(out[k]) > 10000.0:
                                out[k] = math.copysign(10000.0, out[k])

        # 2) ë‚˜ë¨¸ì§€ ìŠ¤ì¹¼ë¼ë„ ê²°ì¸¡ì€ Noneìœ¼ë¡œ, ìˆ˜ì¹˜/ë¬¸ì ìˆ˜ì¹˜ë§Œ ì•ˆì „ ë³€í™˜
        for k, v in list(out.items()):
            if k in DataConverter.PERCENT_FIELDS:
                continue
            if isinstance(v, (int, float)):
                out[k] = v if math.isfinite(float(v)) else None
            elif isinstance(v, str):
                out[k] = DataValidator.safe_float_optional(v)  # ìˆ˜ì¹˜í˜• ë¬¸ìì—´ë§Œ float, ì•„ë‹ˆë©´ None
            elif v is None:
                out[k] = None
            # dict/list ë“± ë³µí•©í˜•ì€ ê·¸ëŒ€ë¡œ ë‘ (í•„ìš” ì‹œ ìƒìœ„ ë¡œì§ì—ì„œ ì²˜ë¦¬)

        return out
    
    @staticmethod
    def as_percent_maybe_ratio(x: Any) -> float:
        """%/ë°°ìˆ˜ í˜¼ì¬ ì •ê·œí™” (0<ê°’â‰¤5 â†’ Ã—100 ê·œì¹™)
        
        NOTE: í˜„ ì‹œì ì—” ingestì—ì„œ ëª¨ë‘ %ë¡œ í‘œì¤€í™”ë˜ë‹ˆ ì¶”ê°€ ìŠ¤ì¼€ì¼ ê¸ˆì§€.
        standardize_financial_units()ì—ì„œ ëª¨ë“  í¼ì„¼íŠ¸ì„± ì§€í‘œë¥¼ %ë¡œ í†µì¼í•˜ë¯€ë¡œ
        ì´ í•¨ìˆ˜ëŠ” ë ˆê±°ì‹œ í˜¸í™˜ìš©ì´ë©°, ì¤‘ë³µ ìŠ¤ì¼€ì¼ ë°©ì§€ê°€ ì£¼ëª©ì ì…ë‹ˆë‹¤.
        """
        v = DataValidator.safe_float(x, 0.0)
        if v <= 0:
            return 0.0
        return v * 100.0 if v <= 5.0 else v
    
    @staticmethod
    def enforce_canonical_percent(x: Any, field_name: str = "unknown") -> Optional[float]:
        """Enforce canonical percentage units for consistent scoring
        
        Args:
            x: Input value (could be ratio or percentage)
            field_name: Field name for logging/debugging
            
        Returns:
            Value normalized to percentage (preserves sign), None if missing
        """
        # â† ì¶”ê°€: ê²°ì¸¡ ë³´ì¡´
        x_opt = DataValidator.safe_float_optional(x)
        if x_opt is None:
            return None
        v = float(x_opt)
        if not math.isfinite(v):
            return None
        # convert likely ratios to %
        if -5.0 <= v <= 5.0:
            v = v * 100.0
        # clamp extreme outliers but DO NOT kill sign
        if abs(v) > 10000.0:
            logging.debug(f"[percent-clamp] {field_name}={v} -> {math.copysign(10000.0, v)}")
            v = math.copysign(10000.0, v)
        return v

# =============================================================================
# 4. í•µì‹¬ ë¶„ì„ í´ë˜ìŠ¤ë“¤
# =============================================================================

class FinancialDataProvider(DataProvider):
    """ì¬ë¬´ ë°ì´í„° ì œê³µì"""
    
    def __init__(self, provider: KISDataProvider, rate_limiter: TPSRateLimiter, ttl: float = None, metrics: MetricsCollector = None):
        self.provider = provider
        self.price_provider = EnhancedPriceProvider()
        self.rate_limiter = rate_limiter
        self.financial_ratio_analyzer = FinancialRatioAnalyzer(provider)
        self.profit_ratio_analyzer = ProfitRatioAnalyzer(provider)
        self.stability_ratio_analyzer = StabilityRatioAnalyzer(provider)
        self._cache_price: "OrderedDict[str, Tuple[float, Dict[str, Any]]]" = OrderedDict()
        self._cache_fin: "OrderedDict[str, Tuple[float, Dict[str, Any]]]" = OrderedDict()
        self._cache_lock = RLock()
        # TTL ë¶„ë¦¬: ê°€ê²© ë°ì´í„°ëŠ” ì§§ê²Œ, ì¬ë¬´ ë°ì´í„°ëŠ” ê¸¸ê²Œ
        self._ttl = {
            'price': safe_env_float("KIS_CACHE_TTL_PRICE", 5.0, 0.1),
            'financial': safe_env_float("KIS_CACHE_TTL_FINANCIAL", 900.0, 1.0),
        }
        self._max_keys = safe_env_int("KIS_CACHE_MAX_KEYS", 2000, 100)
        self.metrics = metrics
    
    
    def _get_cached(self, cache, key):
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (ë™ì‹œì„± ì•ˆì „, TTL ë¶„ë¦¬)"""
        now = _monotonic()
        with self._cache_lock:
            hit = cache.get(key)
            cache_type = 'price' if cache is self._cache_price else 'financial'
            if hit:
                # TTL override ì§€ì› (ë¹ˆ ë°ì´í„°ìš©)
                ttl = hit[2] if len(hit) > 2 and hit[2] is not None else self._ttl[cache_type]
                if now - hit[0] < ttl:
                    if self.metrics:
                        self.metrics.record_cache_hit(cache_type)
                    return hit[1]
        
        if self.metrics:
            self.metrics.record_cache_miss(cache_type)
        return None

    def _set_cached(self, cache, key, value, ttl_override=None):
        """ìºì‹œì— ë°ì´í„° ì €ì¥ (ë™ì‹œì„± ì•ˆì „, LRU í•œë„ ì ìš©)"""
        with self._cache_lock:
            # ë¹ˆ ë°ì´í„°ëŠ” ì§§ì€ TTL ì ìš©
            if ttl_override is None and isinstance(value, dict) and not value:
                ttl_override = min(1.0, self._ttl['price'] * 0.2)  # 20% of normal TTL
            cache[key] = (_monotonic(), value, ttl_override)
            cache.move_to_end(key)
            while len(cache) > self._max_keys:
                cache.popitem(last=False)  # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
    
    def get_financial_data(self, symbol: str) -> Dict[str, Any]:
        """ì¬ë¬´ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (TTL ìºì‹œ ì ìš©)."""
        # ìºì‹œ í™•ì¸
        hit = self._get_cached(self._cache_fin, symbol)
        if hit is not None:
            return hit
        
        financial_data = {}
        
        # ì¬ë¬´ë¹„ìœ¨ ë¶„ì„ (ì¬ì‹œë„ ì ìš©)
        try:
            cb = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            # rate_limiter ì˜ˆì™¸ë§Œ ë°”ê¹¥ì—ì„œ ì§‘ê³„
            try:
                self.rate_limiter.acquire()
            except TimeoutError as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.API_TIMEOUT)
                raise
            
            # ì‹¤ì œ APIëŠ” _with_retriesê°€ ì§‘ê³„
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            financial_ratios = _with_retries(
                lambda: self.financial_ratio_analyzer.get_financial_ratios(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final
            )
            if financial_ratios and len(financial_ratios) > 0:
                latest_ratios = financial_ratios[0]
                financial_data.update({
                    'roe': DataValidator.safe_float_optional(latest_ratios.get('roe')),
                    'roa': DataValidator.safe_float_optional(latest_ratios.get('roa')),
                    'debt_ratio': DataValidator.safe_float_optional(latest_ratios.get('debt_ratio')),
                    'equity_ratio': DataValidator.safe_float_optional(latest_ratios.get('equity_ratio')),
                    'revenue_growth_rate': DataValidator.safe_float_optional(latest_ratios.get('revenue_growth_rate')),
                    'operating_income_growth_rate': DataValidator.safe_float_optional(latest_ratios.get('operating_income_growth_rate')),
                    'net_income_growth_rate': DataValidator.safe_float_optional(latest_ratios.get('net_income_growth_rate'))
                })
        except Exception as e:
            if self.metrics:
                self.metrics.record_api_call(False, ErrorType.FINANCIAL_DATA)
            log_error("ì¬ë¬´ë¹„ìœ¨ ë¶„ì„", symbol, e)
        
        # ìˆ˜ìµì„±ë¹„ìœ¨ ë¶„ì„ (ì¬ì‹œë„ ì ìš©)
        try:
            cb = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            # rate_limiter ì˜ˆì™¸ë§Œ ë°”ê¹¥ì—ì„œ ì§‘ê³„
            try:
                self.rate_limiter.acquire()
            except TimeoutError as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.API_TIMEOUT)
                raise
            
            # ì‹¤ì œ APIëŠ” _with_retriesê°€ ì§‘ê³„
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            profit_ratios = _with_retries(
                lambda: self.profit_ratio_analyzer.get_profit_ratios(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final
            )
            if profit_ratios and len(profit_ratios) > 0:
                latest_profit = profit_ratios[0]
                financial_data.update({
                    'net_profit_margin': DataValidator.safe_float_optional(latest_profit.get('net_profit_margin')),
                    'gross_profit_margin': DataValidator.safe_float_optional(latest_profit.get('gross_profit_margin')),
                    'profitability_grade': latest_profit.get('profitability_grade', 'í‰ê°€ë¶ˆê°€')
                })
        except Exception as e:
            if self.metrics:
                self.metrics.record_api_call(False, ErrorType.FINANCIAL_DATA)
            log_error("ìˆ˜ìµì„±ë¹„ìœ¨ ë¶„ì„", symbol, e)
        
        # ì•ˆì •ì„±ë¹„ìœ¨ ë¶„ì„ (current_ratio í¬í•¨)
        try:
            cb = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            # rate_limiter ì˜ˆì™¸ë§Œ ë°”ê¹¥ì—ì„œ ì§‘ê³„
            try:
                self.rate_limiter.acquire()
            except TimeoutError as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.API_TIMEOUT)
                raise
            
            # ì‹¤ì œ APIëŠ” _with_retriesê°€ ì§‘ê³„
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            stability = _with_retries(
                lambda: self.stability_ratio_analyzer.get_stability_ratios(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final
            )
            if stability and len(stability) > 0:
                latest_stab = stability[0]
                financial_data.update({
                    'current_ratio': DataValidator.safe_float_optional(latest_stab.get('current_ratio'))  # ì›ì‹œê°’ë§Œ ì €ì¥, ë‹¨ìœ„ í‘œì¤€í™”ëŠ” standardize_financial_unitsì—ì„œë§Œ
                })
        except Exception as e:
            if self.metrics:
                self.metrics.record_api_call(False, ErrorType.STABILITY_RATIO)
            log_error("ì•ˆì •ì„±ë¹„ìœ¨ ë¶„ì„", symbol, e)
        
        # ë‹¨ìœ„ í‘œì¤€í™” ì¼ê´„ ì ìš© (ìƒˆë¡œìš´ í‘œì¤€í™” í•¨ìˆ˜ ì‚¬ìš©)
        financial_data = DataConverter.standardize_financial_units(financial_data)
        # âœ… Percent canonicalization ë³´í˜¸ í”Œë˜ê·¸ ì„¤ì •
        financial_data["_percent_canonicalized"] = True
        
        # ê¸°ì¡´ í˜¼ì¬ ë‹¨ìœ„ ì •ê·œí™”ë„ ìœ ì§€ (í˜¸í™˜ì„±) - standardize_financial_units()ì—ì„œ í†µì¼ ì²˜ë¦¬
        # debt_ratio, equity_ratioëŠ” PERCENT_FIELDSì— í¬í•¨ë˜ì–´ ìë™ ì²˜ë¦¬ë¨

        # âš ï¸ FIX: ROE/ROAëŠ” ì´ë¯¸ standardize_financial_unitsì—ì„œ ìŠ¤ì¼€ì¼ í†µì¼ë¨.
        #       ì—¬ê¸°ì„œ ì¬ì°¨ 0<x<=5 ë°°ìœ¨ ë³´ì •ì„ í•˜ë©´ 0.03â†’3.0â†’300.0ì²˜ëŸ¼ ì´ì¤‘ ê³±ì…ˆ ë²„ê·¸ê°€ ë°œìƒ.
        #       ë”°ë¼ì„œ ì¶”ê°€ ë³´ì • ë£¨í”„ë¥¼ ì œê±°í•˜ì—¬ ì´ì¤‘ ìŠ¤ì¼€ì¼ë§ì„ ê·¼ë³¸ ì°¨ë‹¨.
        
        # PER/PBRëŠ” get_price_data()ì—ì„œ ë‹¨ì¼ ì†ŒìŠ¤ë¡œ ê³„ì‚°ë¨ (ì¤‘ë³µ ì œê±°)
        
        # ìºì‹œì— ì €ì¥
        self._set_cached(self._cache_fin, symbol, financial_data)
        return financial_data
    
    def get_price_data(self, symbol: str) -> Dict[str, Any]:
        """ê°€ê²© ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (TTL ìºì‹œ ì ìš©)."""
        # ìºì‹œ í™•ì¸
        hit = self._get_cached(self._cache_price, symbol)
        if hit is not None:
            return hit
            
        try:
            # í–¥ìƒëœ ê°€ê²© í”„ë¡œë°”ì´ë” ì‚¬ìš© (ë¦¬íŠ¸ë¼ì´ + ë©”íŠ¸ë¦­ ì½œë°±ìœ¼ë¡œ ì¼ì›í™”)
            cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
            cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
            price_data = _with_retries(
                lambda: self.price_provider.get_comprehensive_price_data(symbol),
                metrics_attempt=cb_attempt,
                metrics_final=cb_final
            )
            # ë¹ˆ í˜ì´ë¡œë“œ ì¶”ê°€ ì§‘ê³„
            
            if price_data:
                # ê²°ì¸¡ì¹˜ í‘œí˜„ ì¼ê´€ì„±: "ì—†ìœ¼ë©´ None"ë¡œ í†µì¼ (legitimate zero í—ˆìš©)
                def _local_none_if_missing(x):
                    """None for None/NaN; allow legitimate zero"""
                    return DataValidator.safe_float_optional(x)
                
                data = {
                    'current_price': _local_none_if_missing(price_data.get('current_price')),
                    'price_change': _local_none_if_missing(price_data.get('price_change')),
                    'price_change_rate': _local_none_if_missing(price_data.get('price_change_rate')),
                    'volume': int(v) if (v := _local_none_if_missing(price_data.get('volume'))) is not None else None,
                    'eps': _local_none_if_missing(price_data.get('eps')),
                    'bps': _local_none_if_missing(price_data.get('bps')),
                    'market_cap': normalize_market_cap_ekwon(_local_none_if_missing(price_data.get('market_cap')))
                }
                
                # PER/PBR ê³„ì‚° (EPS/BPSê°€ ì–‘ìˆ˜ì¼ ë•Œë§Œ, 0ì› ì£¼ê°€ ë°©ì–´)
                cp = DataValidator.safe_float_optional(price_data.get('current_price'))
                eps = DataValidator.safe_float_optional(price_data.get('eps'))
                bps = DataValidator.safe_float_optional(price_data.get('bps'))
                
                # PER/PBR ê³„ì‚° ê°€ë“œ: í˜„ì‹¤ì  ë””í´íŠ¸(í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì ˆ ê°€ëŠ¥): ê·¹ì†Œ EPS/BPSì—ì„œ PER/PBR í­ì£¼ ë°©ì§€
                EPS_MIN = safe_env_float("EPS_MIN", 0.1, 0.0)  # 0.1ì› ì´ìƒë§Œ PER ê³„ì‚° (ì™„í™”)
                BPS_MIN = safe_env_float("BPS_MIN", 100.0, 0.0)  # 100ì› ì´ìƒë§Œ PBR ê³„ì‚° (ì™„í™”)
                
                # ë‹¨ìœ„ ê²€ì¦ ë¡œê¹… (1íšŒë§Œ, ë””ë²„ê¹…ìš©)
                if eps is not None and eps > 0:
                    logging.debug(f"[unit-check] EPS={eps:.2f} for {symbol} (ë‹¨ìœ„: ì›)")
                if bps is not None and bps > 0:
                    logging.debug(f"[unit-check] BPS={bps:.2f} for {symbol} (ë‹¨ìœ„: ì›)")
                # âœ… PER ê³„ì‚° ê°€ë“œ ëª…í™•í™”: current_priceê°€ Noneì´ê±°ë‚˜ 0ì´ë©´ ìŠ¤í‚µ (ì •ì§€/ë‹¨ì£¼ ë“±)
                if eps is not None and eps > EPS_MIN and cp is not None:
                    data['per'] = DataValidator.safe_divide(cp, eps)
                else:
                    data['per'] = None  # ì›ì¸: eps_min ë¯¸ë‹¬/ê²°ì¸¡/ì •ì§€
                    if self.metrics:
                        self.metrics.metrics['valuation_skips']['per_epsmin'] += 1
                # âœ… PBR ê³„ì‚° ê°€ë“œ ëª…í™•í™”: current_priceê°€ Noneì´ê±°ë‚˜ 0ì´ë©´ ìŠ¤í‚µ (ì •ì§€/ë‹¨ì£¼ ë“±)
                if bps is not None and bps > BPS_MIN and cp is not None:
                    data['pbr'] = DataValidator.safe_divide(cp, bps)
                else:
                    data['pbr'] = None  # ì›ì¸: bps_min ë¯¸ë‹¬/ê²°ì¸¡/ì •ì§€
                    if self.metrics:
                        self.metrics.metrics['valuation_skips']['pbr_bpsmin'] += 1
                
                # âœ… PER/PBR ìƒí•œ í´ë¨í”„ í™˜ê²½ë³€ìˆ˜í™”: ìš´ì˜ ì¤‘ íŠœë‹ ê°€ëŠ¥
                PER_MAX = safe_env_float("PER_MAX_DEFAULT", 500.0, 100.0)
                PBR_MAX = safe_env_float("PBR_MAX_DEFAULT", 100.0, 10.0)
                if data['per'] is not None:
                    data['per'] = min(data['per'], PER_MAX)  # ìƒí•œ í´ë¨í”„
                if data['pbr'] is not None:
                    data['pbr'] = min(data['pbr'], PBR_MAX)  # ìƒí•œ í´ë¨í”„
                
                # 52ì£¼ ê³ ì € ì •ë³´ ì¡°íšŒ (ì‹¤ì‹œê°„ í”Œë˜ê·¸ì— ë”°ë¼)
                w52h = _none_if_missing_strict(price_data.get('w52_high'))
                w52l = _none_if_missing_strict(price_data.get('w52_low'))
                
                if getattr(self, 'include_realtime', True) and (w52h is None or w52l is None):
                    # KIS APIì—ì„œ ì¶”ê°€ ì¡°íšŒ
                    try:
                        self.rate_limiter.acquire()
                        cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                        cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                        price_info = _with_retries(
                            lambda: self.provider.get_stock_price_info(symbol),
                            metrics_attempt=cb_attempt,
                            metrics_final=cb_final
                        )
                        if price_info:
                            w52h = _none_if_missing_strict(price_info.get('w52_high')) if w52h is None else w52h
                            w52l = _none_if_missing_strict(price_info.get('w52_low')) if w52l is None else w52l
                    except Exception as e:
                        if self.metrics:
                            self.metrics.record_api_call(False, ErrorType.PRICE_DATA)
                        logging.debug(f"KIS API 52ì£¼ ê³ ì € ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ {symbol}: {e}")
                
                # 52ì£¼ ê³ ì € ë°ì´í„° ì €ì¥ (ìœ íš¨í•œ ê°’ë§Œ)
                if w52h is not None: data['w52_high'] = w52h
                if w52l is not None: data['w52_low'] = w52l
                
                # ìºì‹œì— ì €ì¥
                self._set_cached(self._cache_price, symbol, data)
                return data
        except Exception as e:
            # _with_retriesê°€ ì´ë¯¸ ì‹¤íŒ¨ë¥¼ ê¸°ë¡í•˜ë¯€ë¡œ ì¤‘ë³µ ê¸°ë¡ ë°©ì§€
            log_error("ê°€ê²© ë°ì´í„° ì¡°íšŒ", symbol, e)
        
        if self.metrics:
            self.metrics.record_api_call(False, ErrorType.EMPTY_PRICE_PAYLOAD)
        data = {}
        self._set_cached(self._cache_price, symbol, data)
        return data

class EnhancedScoreCalculator(ScoreCalculator):
    """í–¥ìƒëœ ì ìˆ˜ ê³„ì‚°ê¸°"""
    
    def __init__(self, config: AnalysisConfig):
        self.config = config
    
    def calculate_score(self, data: Dict[str, Any], *, sector_info: Optional[Dict[str, Any]] = None, price_data: Optional[Dict[str, Any]] = None) -> Tuple[float, Dict[str, float]]:
        """í†µí•© ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (ìˆœìˆ˜ í•¨ìˆ˜).
        
        ê°€ì¤‘ì¹˜ ì²˜ë¦¬ ì •ì±…:
        - ê²°ì¸¡ ë°ì´í„°ëŠ” ì¤‘ë¦½ì (50) ì ìš© í›„ ê°€ì¤‘ì¹˜ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„
        - ê°€ì¤‘ì¹˜ ì¬ì •ê·œí™”ë¡œ ì´í•©ì´ 100ì´ ë˜ë„ë¡ ì¡°ì •
        - ì´ëŠ” ì¤‘ë¦½ í¸í–¥ ì „ëµìœ¼ë¡œ ì•ˆì •ì ì¸ ì ìˆ˜ ì‚°ì¶œì„ ë³´ì¥
        """
        score = 0.0
        breakdown = {}
        
        # ê° ë¶„ì„ ìš”ì†Œë³„ ì ìˆ˜ ê³„ì‚° (None = ë°ì´í„° ì—†ìŒ)
        def _use(score, key):
            if score is None:
                return 50.0, self.config.weights.get(key, 0) * 0.5
            return score, self.config.weights.get(key, 0)
        
        opinion_score, w_op = _use(self._calculate_opinion_score(data.get('opinion_analysis', {})), 'opinion_analysis')
        estimate_score, w_est = _use(self._calculate_estimate_score(data.get('estimate_analysis', {})), 'estimate_analysis')
        financial_score, w_fin = _use(self._calculate_financial_score(data.get('financial_data', {})), 'financial_ratios')
        growth_score, w_gro = _use(self._calculate_growth_score(data.get('financial_data', {})), 'growth_analysis')
        scale_score, w_sca = _use(self._calculate_scale_score(data.get('market_cap', 0)), 'scale_analysis')
        
        # 52ì£¼ ìœ„ì¹˜ ì ìˆ˜ ê³„ì‚° (missing data half weight ê·œì¹™ ì¼ê´€ì„±)
        pp_raw = data.get('price_position')
        pp_score = self._calculate_price_position_score(pp_raw) if pp_raw is not None else None
        price_position_score, w_pp = _use(pp_score, 'price_position')
        
        # ì ìˆ˜ í´ë¨í•‘ (ê·¹ë‹¨ì¹˜/ì˜¤ë²„ìŠ¤ì¼€ì¼ ë°©ì§€)
        def _clamp01(x): 
            return max(0.0, min(100.0, x if x is not None else 50.0))
        
        opinion_score = _clamp01(opinion_score)
        estimate_score = _clamp01(estimate_score)
        financial_score = _clamp01(financial_score)
        growth_score = _clamp01(growth_score)
        scale_score = _clamp01(scale_score)
        price_position_score = _clamp01(price_position_score)
        
        # ê°€ì¤‘ì¹˜ ì¬ì •ê·œí™” (ê²°ì¸¡ ë°ì´í„°ëŠ” 50ì  + half-weightë¡œ í•­ìƒ í¬í•¨)
        valid_scores = []
        weights_for_norm = []
        for s, w in [
            (opinion_score, w_op),
            (estimate_score, w_est),
            (financial_score, w_fin),
            (growth_score, w_gro),
            (scale_score, w_sca),
            (price_position_score, w_pp),
        ]:
            # _use() already returned (score_or_50, adjusted_weight)
            # So at this point s is never None; keep as-is for clarity.
            valid_scores.append((s, w))
            weights_for_norm.append(w)
        
        total_weight = sum(weights_for_norm)
        if total_weight > 0:
            score = sum(s * (w / total_weight) for s, w in valid_scores)
        else:
            score = 50.0
        
        if total_weight > 0:
            breakdown = {
                'íˆ¬ìì˜ê²¬': opinion_score * (w_op / total_weight) if opinion_score is not None else 0,
                'ì¶”ì •ì‹¤ì ': estimate_score * (w_est / total_weight) if estimate_score is not None else 0,
                'ì¬ë¬´ë¹„ìœ¨': financial_score * (w_fin / total_weight) if financial_score is not None else 0,
                'ì„±ì¥ì„±': growth_score * (w_gro / total_weight) if growth_score is not None else 0,
                'ê·œëª¨': scale_score * (w_sca / total_weight) if scale_score is not None else 0,
                'ê°€ê²©ìœ„ì¹˜': price_position_score * (w_pp / total_weight) if price_position_score is not None else 0
            }
        else:
            breakdown = {
                'íˆ¬ìì˜ê²¬': 0, 'ì¶”ì •ì‹¤ì ': 0, 'ì¬ë¬´ë¹„ìœ¨': 0,
                'ì„±ì¥ì„±': 0, 'ê·œëª¨': 0, 'ê°€ê²©ìœ„ì¹˜': 0
            }
        
        # ì›ì ìˆ˜ breakdown ì¶”ê°€ (0~100 ìŠ¤ì¼€ì¼, ê°€ì¤‘ì¹˜ ë¯¸ì ìš©)
        raw_breakdown = {
            'opinion_raw': opinion_score,
            'estimate_raw': estimate_score,
            'financial_raw': financial_score,
            'growth_raw': growth_score,
            'scale_raw': scale_score,
            'price_position_raw': price_position_score,
        }
        
        return min(100, max(0, score)), {**breakdown, **raw_breakdown}
    
    def _calculate_opinion_score(self, opinion_data: Dict[str, Any]) -> Optional[float]:
        """íˆ¬ìì˜ê²¬ ì ìˆ˜ ê³„ì‚° (ë°ì´í„° ì—†ìœ¼ë©´ None ë°˜í™˜)"""
        # consensus_scoreë¥¼ ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°
        consensus_score = None
        if 'consensus_score' in opinion_data:
            consensus_score = opinion_data.get('consensus_score')
        elif 'consensus_analysis' in opinion_data:
            consensus_score = opinion_data.get('consensus_analysis', {}).get('consensus_score')
        
        if consensus_score is not None:
            try:
                cs = max(-1.0, min(1.0, float(consensus_score)))
                return (cs + 1.0) * 50.0  # -1~1 â†’ 0~100
            except Exception:
                pass
        return None  # ë°ì´í„° ì—†ìŒ
    
    def _calculate_estimate_score(self, estimate_data: Dict[str, Any]) -> Optional[float]:
        """ì¶”ì •ì‹¤ì  ì ìˆ˜ ê³„ì‚° (ë°ì´í„° ì—†ìœ¼ë©´ None ë°˜í™˜)"""
        if not estimate_data:
            return None  # ë°ì´í„° ì—†ìŒ
        
        w = self.config.estimate_analysis_weights
        fh = DataValidator.safe_float(estimate_data.get('financial_health_score', 0))  # 0~15
        val = DataValidator.safe_float(estimate_data.get('valuation_score', 0))        # 0~15
        
        # ë‘˜ ë‹¤ 0ì´ë©´ ë°ì´í„° ì—†ìŒìœ¼ë¡œ ê°„ì£¼
        if fh == 0 and val == 0:
            return None
        
        total_weight = w['financial_health'] + w['valuation']
        # 0~15ë¥¼ ê°€ì¤‘ í‰ê·  â†’ 0~15 â†’ 0~100
        weighted_raw = (fh * w['financial_health'] + val * w['valuation']) / total_weight  # 0~15
        return (weighted_raw / 15.0) * 100.0
    
    def _calculate_financial_score(self, financial_data: Dict[str, Any]) -> Optional[float]:
        """ì¬ë¬´ë¹„ìœ¨ ì ìˆ˜ ê³„ì‚° (ì¡´ì¬í•˜ëŠ” ì§€í‘œë§Œ ê°€ì¤‘í•©, ëª¨ë‘ ê²°ì¸¡ì´ë©´ None ë°˜í™˜)
        
        **ì´ì¤‘ ìŠ¤ì¼€ì¼ ê¸ˆì§€**: ì´ í•¨ìˆ˜ëŠ” % ì…ë ¥ì„ ì „ì œë¡œ í•¨ (DataConverter.standardize_financial_units()ì—ì„œ ë³€í™˜ë¨)
        """
        if not financial_data:
            return None
        
        # âœ… Percent canonicalization ë³´í˜¸ ì²´í¬ (resilience ê°œì„ )
        if financial_data.get("_percent_canonicalized") is not True:
            logging.warning("WARNING: financial_data not canonicalized! Re-scaling detected. Applying on-the-fly canonicalization.")
            financial_data = DataConverter.standardize_financial_units(financial_data)
            financial_data["_percent_canonicalized"] = True
        
        # NOTE: ì…ë ¥ì€ canonical % (DataConverter.standardize_financial_units ì´í›„)
        # ì¬ìŠ¤ì¼€ì¼ ê¸ˆì§€: ìˆ«ì ë²”ìœ„ë§Œ ê²€ì¦ (ë¡œì»¬ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ë¶€ìˆ˜íš¨ê³¼ ë°©ì§€)
        _roe = DataValidator.safe_float_optional(financial_data.get('roe'))
        _roa = DataValidator.safe_float_optional(financial_data.get('roa'))
        _debt = DataValidator.safe_float_optional(financial_data.get('debt_ratio'))
        _npm = DataValidator.safe_float_optional(financial_data.get('net_profit_margin'))
        _cr = DataValidator.safe_float_optional(financial_data.get('current_ratio'))

        w = self.config.financial_ratio_weights
        roe_w = w.get('roe_score', 8)
        roa_w = w.get('roa_score', 5)
        debt_w = w.get('debt_ratio_score', 7)
        npm_w = w.get('net_profit_margin_score', 5)
        cr_w = w.get('current_ratio_score', 3)

        # ë¡œì»¬ ìŠ¤ëƒ…ìƒ· ì‚¬ìš© (financial_data ìˆ˜ì • ê¸ˆì§€)
        roe = _roe
        roa = _roa
        debt_ratio = _debt
        npm = _npm
        cr = _cr
        # Current ratio units: now fully canonicalized in standardize_financial_units

        acc = 0.0
        wsum = 0.0

        if roe is not None:
            roe_point = 1.0 if roe >= 20 else 0.75 if roe >= 15 else 0.5 if roe >= 10 else 0.25 if roe >= 5 else 0.0
            acc += roe_point * roe_w; wsum += roe_w
        if roa is not None:
            roa_point = 1.0 if roa >= 10 else 0.8 if roa >= 7 else 0.6 if roa >= 5 else 0.4 if roa >= 3 else 0.0
            acc += roa_point * roa_w; wsum += roa_w
        if debt_ratio is not None:
            debt_point = 1.0 if debt_ratio <= 30 else 0.75 if debt_ratio <= 50 else 0.5 if debt_ratio <= 70 else 0.25 if debt_ratio <= 100 else 0.0
            acc += debt_point * debt_w; wsum += debt_w
        if npm is not None:
            npm_point = 1.0 if npm >= 15 else 0.8 if npm >= 10 else 0.6 if npm >= 5 else 0.4 if npm >= 2 else 0.0
            acc += npm_point * npm_w; wsum += npm_w
        if cr is not None:
            cr_point = 1.0 if cr >= 200 else 0.67 if cr >= 150 else 0.33 if cr >= 100 else 0.0
            acc += cr_point * cr_w; wsum += cr_w

        if wsum == 0:
            return None  # ëª¨ë‘ ê²°ì¸¡ â†’ ìƒìœ„ì—ì„œ half-weight + 50ì  ì²˜ë¦¬
        return (acc / wsum) * 100.0
    
    def _calculate_growth_score(self, financial_data: Dict[str, Any]) -> Optional[float]:
        """ì„±ì¥ì„± ì ìˆ˜ ê³„ì‚° (ë°ì´í„° ì—†ìœ¼ë©´ None ë°˜í™˜)"""
        if not financial_data:
            return None  # ë°ì´í„° ì—†ìŒ
        
        revenue_growth = DataValidator.safe_float_optional(financial_data.get('revenue_growth_rate'))
        
        # ê²°ì¸¡ì¹˜ë§Œ None ë°˜í™˜, 0%ëŠ” ì¤‘ë¦½ ì ìˆ˜ë¡œ ì²˜ë¦¬
        if revenue_growth is None:
            return None
        
        # ì…ë ¥ í´ë¦½ìœ¼ë¡œ ê·¹ë‹¨ì¹˜ ë°©ì§€ (-100~+100%)
        revenue_growth = max(-100.0, min(100.0, revenue_growth))
        
        thresholds = self.config.growth_score_thresholds
        
        if revenue_growth >= thresholds.get('excellent', 20):
            return 100.0
        elif revenue_growth >= thresholds.get('good', 10):
            return 80.0
        elif revenue_growth >= thresholds.get('average', 0):
            return 50.0  # 0%ëŠ” ì¤‘ë¦½ ì ìˆ˜
        elif revenue_growth >= thresholds.get('poor', -10):
            return 30.0
        elif revenue_growth >= thresholds.get('very_poor', -100):
            return 10.0
        else:
            return 0.0
    
    def _calculate_scale_score(self, market_cap: Optional[float]) -> float:
        """ê·œëª¨ ì ìˆ˜ ê³„ì‚° (ì„¤ì •ê°’ ì‚¬ìš©)"""
        if market_cap is None:
            return 50.0  # default for unknown market cap
        t = self.config.scale_score_thresholds
        if market_cap >= t.get('mega_cap', 100000):
            return 100
        elif market_cap >= t.get('large_cap', 50000):
            return 80
        elif market_cap >= t.get('mid_large_cap', 10000):
            return 60
        elif market_cap >= t.get('mid_cap', 5000):
            return 40
        elif market_cap >= t.get('small_cap', 1000):
            return 20
        else:
            return 0
    
    def _calculate_price_position_score(self, price_position: Optional[float]) -> float:
        """
        52ì£¼ ìœ„ì¹˜ì— ë”°ë¥¸ ì ìˆ˜ ê³„ì‚° (ì„ í˜•í™”)
        
        ì „ëµì  ì˜ë„:
        - ê³ ìœ„ì¹˜(90%+) ë²Œì : ìƒë‹¨ì¼ìˆ˜ë¡ ë‚®ì€ ì ìˆ˜ (100 - position)
        - ì €ìœ„ì¹˜(10%-) ê°€ì : í•˜ë‹¨ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        - ì¶”ì²œ í•„í„°ì—ì„œ >=85% ê³ ìœ„ì¹˜ ì°¨ë‹¨ê³¼ ì¤‘ë³µìœ¼ë¡œ ì´ì¤‘ ì•ˆì „ì¥ì¹˜ ì—­í• 
        
        Note: ì¶”ì²œ ë‹¨ê³„ì—ì„œ ì´ë¯¸ ê³ ìœ„ì¹˜ í•„í„°ë§ì´ ìˆìœ¼ë¯€ë¡œ, 
        ì ìˆ˜ì™€ í•„í„°ê°€ ì¤‘ë³µìœ¼ë¡œ ê³ ìœ„ì¹˜ ë²Œì ì„ ì£¼ëŠ” ì˜ë„ì  ì„¤ê³„ì…ë‹ˆë‹¤.
        """
        if price_position is None:
            return 50.0  # ì¤‘ë¦½ì 
        
        # ì„ í˜• ë§¤í•‘: ê³ ìœ„ì¹˜ ë²Œì (ìƒë‹¨ì¼ìˆ˜ë¡ ë‚®ì€ ì ìˆ˜), ì €ìœ„ì¹˜ ê°€ì 
        # 0~100 â†’ 0~100ìœ¼ë¡œ ë§¤ë„ëŸ½ê²Œ (100 - position)
        linear_score = 100.0 - price_position
        
        # ê²½ê³„ê°’ í´ë¨í•‘
        return max(0.0, min(100.0, linear_score))
    
    def _calculate_price_position_penalty(self, price_position: Optional[float]) -> float:
        """52ì£¼ ìœ„ì¹˜ì— ë”°ë¥¸ í˜ë„í‹° ê³„ì‚° (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
        # ìƒˆë¡œìš´ ì •ê·œí™”ëœ ì ìˆ˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜
        return self._calculate_price_position_score(price_position)

# =============================================================================
# 5. ë©”ì¸ ë¶„ì„ í´ë˜ìŠ¤
# =============================================================================

class EnhancedIntegratedAnalyzer:
    """
    ë¦¬íŒ©í† ë§ëœ í–¥ìƒëœ í†µí•© ë¶„ì„ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
    - ë‹¨ì¼ ì¢…ëª© ë¶„ì„ (íˆ¬ìì˜ê²¬, ì¶”ì •ì‹¤ì , ì¬ë¬´ë¹„ìœ¨ í†µí•©)
    - ì „ì²´ ì‹œì¥ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)
    - ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ë¶„ì„
    - ì—…ì¢…ë³„ ë¶„í¬ ë¶„ì„
    - í–¥ìƒëœ ì ìˆ˜ ê³„ì‚° ë° ë“±ê¸‰ í‰ê°€
    
    ì£¼ìš” íŠ¹ì§•:
    - ì•ˆì „í•œ ë°ì´í„° ì ‘ê·¼ (ê°ì²´/ë”•ì…”ë„ˆë¦¬ í˜¼ìš© ëŒ€ì‘)
    - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    - í¬ê´„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬
    - TTL ìºì‹± ì‹œìŠ¤í…œ
    - ì‹¤ì‹œê°„ ë°ì´í„° í†µí•©
    """
    
    def __init__(self, config_file: str = "config.yaml", include_realtime: bool = True, include_external: bool = True):
        # ë¡œê¹…/í™˜ê²½ ìºì‹œ ì¤€ë¹„
        _refresh_env_cache()
        self.config_manager = ConfigManager(config_file)
        self.rate_limiter = TPSRateLimiter()
        self.include_realtime = include_realtime
        self.include_external = include_external
        
        # âœ… í™˜ê²½ë³€ìˆ˜ ìºì‹± (í•«íŒ¨ìŠ¤ ìµœì í™”)
        self.env_cache = {
            'current_ratio_ambiguous_strategy': os.getenv("CURRENT_RATIO_AMBIGUOUS_STRATEGY", "as_is"),
            'current_ratio_force_percent': os.getenv("CURRENT_RATIO_FORCE_PERCENT", "false"),
            'market_cap_strict_mode': os.getenv("MARKET_CAP_STRICT_MODE", "true"),
            'sector_target_good': safe_env_int("SECTOR_TARGET_GOOD", 60, 10),
            'max_sector_peers_base': safe_env_int("MAX_SECTOR_PEERS_BASE", 40, 5),
            'max_sector_peers_full': safe_env_int("MAX_SECTOR_PEERS_FULL", 200, 20),
            'max_sector_cache_entries': safe_env_int("MAX_SECTOR_CACHE_ENTRIES", 64, 1),
            'max_sector_api_boost': safe_env_int("MAX_SECTOR_API_BOOST", 10, 0),
        }
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        self.metrics = MetricsCollector()
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.opinion_analyzer = InvestmentOpinionAnalyzer()
        self.estimate_analyzer = EstimatePerformanceAnalyzer()
        self.provider = KISDataProvider()
        self.data_provider = FinancialDataProvider(self.provider, self.rate_limiter, metrics=self.metrics)
        # í”Œë˜ê·¸ ì „ë‹¬
        self.data_provider.include_realtime = self.include_realtime
        
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_analysis_config()
        self.score_calculator = EnhancedScoreCalculator(self.config)
        self._validate_config()
        
        # âœ… ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½ ì¶”ê°€
        self._sector_warned_lock = RLock()
        self._sector_warned: Set[str] = set()
        
        # KOSPI ë°ì´í„° ë¡œë“œ
        self.kospi_data = None
        self._load_kospi_data()
        
        # ì„¹í„° ë²¡í„° ìºì‹œ (TTL 10ë¶„)
        self._sector_cache = OrderedDict()
        self._sector_cache_ttl = 600  # 10ë¶„
        self._sector_cache_lock = RLock()
        
        # ì„¹í„° íŠ¹ì„± ìºì‹œ (TTL 30ë¶„)
        self._sector_char_cache = OrderedDict()
        self._sector_char_cache_ttl = 1800  # 30ë¶„
        self._sector_char_cache_lock = RLock()
        
        # ì™¸ë¶€ ë¶„ì„ê¸° ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½ (ë¶„ë¦¬)
        self._opinion_lock = RLock()
        self._estimate_lock = RLock()
    
    def _result_to_dict(self, r: AnalysisResult) -> Dict[str, Any]:
        """Convert AnalysisResult to serializable dict for JSON export"""
        pdict = r.price_data or {}
        
        # ëŒ€ì‹œë³´ë“œìš© ìš”ì•½ í•„ë“œ ìƒì„±
        sector_summary = ""
        if r.sector_analysis and r.sector_analysis.get('total_score') is not None:
            score = r.sector_analysis.get('total_score', 0)
            grade = r.sector_analysis.get('grade', 'N/A')
            sector_summary = f"{grade}({score:.1f})"
        
        d = {
            "symbol": r.symbol,
            "name": r.name,
            "enhanced_score": r.enhanced_score,
            "enhanced_grade": r.enhanced_grade,
            "market_cap": r.market_cap,
            "current_price": pdict.get("current_price"),
            "price_position": r.price_position,
            "w52_high": pdict.get("w52_high"),
            "w52_low": pdict.get("w52_low"),
            "per": pdict.get("per"),
            "pbr": pdict.get("pbr"),
            "score_breakdown": r.score_breakdown,
            "financial_data": r.financial_data,
            "sector_analysis": r.sector_analysis,
            # ëŒ€ì‹œë³´ë“œìš© ìš”ì•½ í•„ë“œ
            "sector_valuation": sector_summary,
            "opinion_summary": r.opinion_analysis.get('summary', '') if r.opinion_analysis else '',
            "estimate_summary": r.estimate_analysis.get('summary', '') if r.estimate_analysis else '',
        }
        # âœ… ì§ë ¬í™” ì•ˆì „ì„± ê°•í™”: ë„˜íŒŒì´ ìŠ¤ì¹¼ë¼ ë“± ì²˜ë¦¬
        return serialize_for_json(d)
    
    def _load_analysis_config(self) -> AnalysisConfig:
        """ë¶„ì„ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        config = self.config_manager.load_config()
        enhanced_config = config.get('enhanced_integrated_analysis', {})
        
        return AnalysisConfig(
            weights=enhanced_config.get('weights', {
                'opinion_analysis': 25,
                'estimate_analysis': 30,
                'financial_ratios': 30,
                'growth_analysis': 10,
                'scale_analysis': 5,
                'price_position': 5
            }),
            financial_ratio_weights=enhanced_config.get('financial_ratio_weights', {
                'roe_score': 8,
                'roa_score': 5,
                'debt_ratio_score': 7,
                'net_profit_margin_score': 5,
                'current_ratio_score': 3,
                'growth_score': 2
            }),
            estimate_analysis_weights=enhanced_config.get('estimate_analysis_weights', {
                'financial_health': 15,
                'valuation': 15
            }),
            grade_thresholds=enhanced_config.get('grade_thresholds', {
                'A_plus': 80,
                'A': 70,
                'B_plus': 60,
                'B': 50,
                'C_plus': 40,
                'C': 30,
                'D_plus': 20,
                'D': 10,
                'F': 0
            }),
            growth_score_thresholds=enhanced_config.get('growth_score_thresholds', {
                'excellent': 20,
                'good': 10,
                'average': 0,
                'poor': -10,
                'very_poor': -100
            }),
            scale_score_thresholds=enhanced_config.get('scale_score_thresholds', {
                'mega_cap': 100000,
                'large_cap': 50000,
                'mid_large_cap': 10000,
                'mid_cap': 5000,
                'small_cap': 1000,
                'micro_cap': 0
            }),
        )
    
    def _validate_config(self) -> None:
        """ì„¤ì • ê°€ì¤‘ì¹˜/ì„ê³„ê°’ sanity-check (ê²½ê³ ë§Œ)"""
        try:
            w = self.config.weights
            total = sum(float(w.get(k,0)) for k in w)
            if total <= 0:
                logging.warning("[config] weights í•©ì´ 0 ì´í•˜ì…ë‹ˆë‹¤. ê¸°ë³¸ ê°€ì¤‘ì¹˜ ê¶Œì¥")
            for name, thr in self.config.scale_score_thresholds.items():
                if not isinstance(thr, (int,float)):
                    logging.warning(f"[config] scale threshold '{name}'ì´ ìˆ«ìê°€ ì•„ë‹˜")
        except Exception as e:
            logging.debug(f"[config] validate ì‹¤íŒ¨: {e}")
    
    def _load_kospi_data(self):
        """KOSPI ë§ˆìŠ¤í„° ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤ (xlsx/csv ì§€ì›)."""
        try:
            # âœ… CSV ì§€ì› ì˜µì…˜ ì¶”ê°€ (I/O ê°ì†Œ)
            kospi_csv = 'kospi_code.csv'
            kospi_xlsx = 'kospi_code.xlsx'
            
            if os.path.exists(kospi_csv):
                # CSV ìš°ì„  ë¡œë“œ (ë” ë¹ ë¥¸ I/O)
                try:
                    self.kospi_data = pd.read_csv(kospi_csv, encoding='utf-8-sig')
                    logging.info(f"KOSPI ë°ì´í„° ë¡œë“œ ì™„ë£Œ (CSV): {kospi_csv}")
                except Exception as e:
                    logging.warning(f"CSV ì½ê¸° ì‹¤íŒ¨: {e}")
                    self.kospi_data = pd.DataFrame()
                    return
            elif os.path.exists(kospi_xlsx):
                try:
                    self.kospi_data = pd.read_excel(kospi_xlsx, engine="openpyxl")
                    logging.info(f"KOSPI ë°ì´í„° ë¡œë“œ ì™„ë£Œ (Excel): {kospi_xlsx}")
                except ImportError:
                    try:
                        self.kospi_data = pd.read_excel(kospi_xlsx)  # íŒë‹¤ìŠ¤ ê¸°ë³¸ ì—”ì§„ ì‹œë„
                    except Exception as e:
                        logging.warning(f"xlsx ì½ê¸° ì‹¤íŒ¨: openpyxl ì„¤ì¹˜ ê¶Œì¥. ì›ì¸: {e}")
                        self.kospi_data = pd.DataFrame()
                        return
            else:
                logging.warning("KOSPI ë§ˆìŠ¤í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (kospi_code.csv ë˜ëŠ” kospi_code.xlsx)")
                self.kospi_data = pd.DataFrame()
                return
            
            # ê³µí†µ ë°ì´í„° ì²˜ë¦¬ (CSV/Excel ê³µí†µ)
            if not self.kospi_data.empty:
                # âœ… KOSPI ìŠ¤í‚¤ë§ˆ ë³„ì¹­ ì§€ì› (ë‹¤ì–‘í•œ í™˜ê²½ ëŒ€ì‘)
                column_aliases = {
                    'ì¢…ëª©ëª…': 'í•œê¸€ëª…',
                    'ì¢…ëª©ì½”ë“œ': 'ë‹¨ì¶•ì½”ë“œ',
                    'ì½”ë“œ': 'ë‹¨ì¶•ì½”ë“œ',
                    'ì‹œì´': 'ì‹œê°€ì´ì•¡',
                    'market_cap': 'ì‹œê°€ì´ì•¡',
                    'name': 'í•œê¸€ëª…',
                    'symbol': 'ë‹¨ì¶•ì½”ë“œ'
                }
                
                # ë³„ì¹­ ì ìš©
                for alias, standard in column_aliases.items():
                    if alias in self.kospi_data.columns and standard not in self.kospi_data.columns:
                        self.kospi_data[standard] = self.kospi_data[alias]
                        logging.info(f"ì»¬ëŸ¼ ë³„ì¹­ ì ìš©: '{alias}' â†’ '{standard}'")
                
                self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] = (
                    self.kospi_data['ë‹¨ì¶•ì½”ë“œ']
                        .astype(str)
                        .str.replace(r'\.0$', '', regex=True)
                        .str.zfill(6)
                )
                
                # ìŠ¤í‚¤ë§ˆ ê²€ì¦
                required_cols = {"ë‹¨ì¶•ì½”ë“œ", "í•œê¸€ëª…", "ì‹œê°€ì´ì•¡"}
                if not required_cols.issubset(self.kospi_data.columns):
                    # ìŠ¤í‚¤ë§ˆ ì •ë³´ ë¡œê¹… (ìš´ì˜ ì§€ì›)
                    detected_cols = list(self.kospi_data.columns)[:10]  # ì²˜ìŒ 10ê°œ ì»¬ëŸ¼ë§Œ
                    logging.error(f"KOSPI ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜: í•„ìš”ì»¬ëŸ¼ {required_cols}, ê°ì§€ëœ ì»¬ëŸ¼ {detected_cols}")
                    raise ValueError(f"KOSPI ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜: í•„ìš”ì»¬ëŸ¼ {required_cols}, ì‹¤ì œ {set(self.kospi_data.columns)}")
                
                # ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì •ë¦¬ (í˜¼í•© íƒ€ì… ì²˜ë¦¬)
                if 'ì‹œê°€ì´ì•¡' in self.kospi_data.columns:
                    self.kospi_data['ì‹œê°€ì´ì•¡'] = pd.to_numeric(
                        self.kospi_data['ì‹œê°€ì´ì•¡'].astype(str).str.replace(',', ''), errors='coerce'
                    )  # no fillna - keep NaN for unknown market caps
                
                # ìœ íš¨í•œ 6ìë¦¬ ì¢…ëª© ì½”ë“œë§Œ í•„í„°ë§
                original_count = len(self.kospi_data)
                self.kospi_data = self.kospi_data[
                    self.kospi_data['ë‹¨ì¶•ì½”ë“œ'].str.match(r'^\d{6}$', na=False)
                ]
                filtered_count = len(self.kospi_data)
                
                logging.info(f"KOSPI ë§ˆìŠ¤í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {original_count}ê°œ â†’ {filtered_count}ê°œ ìœ íš¨ ì¢…ëª©")
                
                # âœ… pandas filtering ìµœì í™”: ì¸ë±ìŠ¤ ì„¤ì • (ì„ì‹œ ë¹„í™œì„±í™”)
                # if not self.kospi_data.empty and 'ë‹¨ì¶•ì½”ë“œ' in self.kospi_data.columns:
                #     self.kospi_data = self.kospi_data.set_index('ë‹¨ì¶•ì½”ë“œ')
                #     logging.debug("KOSPI ë°ì´í„° ì¸ë±ìŠ¤ ì„¤ì • ì™„ë£Œ (ë‹¨ì¶•ì½”ë“œ)")
        except Exception as e:
            log_error("KOSPI ë°ì´í„° ë¡œë“œ", error=e, level="error")
            self.kospi_data = pd.DataFrame()
    
    def analyze_single_stock(self, symbol: str, name: str, days_back: int = 30) -> AnalysisResult:
        """
        ë‹¨ì¼ ì¢…ëª© ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            symbol (str): ì¢…ëª© ì½”ë“œ (6ìë¦¬ ìˆ«ì)
            name (str): ì¢…ëª©ëª…
            days_back (int): íˆ¬ìì˜ê²¬ ë¶„ì„ ê¸°ê°„ (ì¼)
            
        Returns:
            AnalysisResult: ë¶„ì„ ê²°ê³¼ ê°ì²´
            
        Raises:
            ValueError: ì¢…ëª© ì½”ë“œê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
            ValueError: ì¢…ëª©ëª…ì´ ì—†ëŠ” ê²½ìš°
        """
        start_time = _monotonic()
        try:
            # ì…ë ¥ ê²€ì¦
            if not DataValidator.is_valid_symbol(symbol):
                return AnalysisResult(
                    symbol=symbol,
                    name=name,
                    status=AnalysisStatus.ERROR,
                    error=f"ìœ íš¨í•˜ì§€ ì•Šì€ ì¢…ëª© ì½”ë“œ: {symbol}"
                )
            
            if not name or not isinstance(name, str):
                return AnalysisResult(
                    symbol=symbol,
                    name=name or "Unknown",
                    status=AnalysisStatus.ERROR,
                    error="ì¢…ëª©ëª…ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ"
                )
            
            # ìš°ì„ ì£¼ í™•ì¸
            if self._is_preferred_stock(name):
                logging.info(f"ìš°ì„ ì£¼ ì œì™¸: {name} ({symbol})")
                return AnalysisResult(
                    symbol=symbol,
                    name=name,
                    status=AnalysisStatus.SKIPPED_PREF,
                    enhanced_score=0,
                    enhanced_grade='F',
                    error="preferred stock filtered"
                )
            
            # ê° ë¶„ì„ ìˆ˜í–‰
            opinion_analysis = self._analyze_opinion(symbol, days_back, name=name)
            estimate_analysis = self._analyze_estimate(symbol, name=name)
            financial_data = self.data_provider.get_financial_data(symbol)
            price_data = self.data_provider.get_price_data(symbol)
            
            # ë°ì´í„° ë¶€ì¡± ìƒíƒœ í™•ì¸
            if not financial_data and not price_data:
                return AnalysisResult(
                    symbol=symbol,
                    name=name,
                    status=AnalysisStatus.NO_DATA,
                    error="no price & financial data"
                )
            
            # ì‹œê°€ì´ì•¡ ì¡°íšŒ
            market_cap = self._get_market_cap(symbol)
            
            # ì„¹í„° ë¶„ì„ ìˆ˜í–‰ (ì¤‘ë³µ í˜ì¹˜ ë°©ì§€)
            sector_analysis = self._analyze_sector(symbol, name, price_data=price_data, financial_data=financial_data)
            
            # í†µí•© ì ìˆ˜ ê³„ì‚°
            analysis_data = {
                'opinion_analysis': opinion_analysis,
                'estimate_analysis': estimate_analysis,
                'financial_data': financial_data,
                'market_cap': market_cap,
                'current_price': price_data.get('current_price', 0),
                'price_position': self._calculate_price_position(price_data),
                'sector_info': self._get_sector_characteristics(symbol),
                'sector_analysis': sector_analysis,
                'price_data': price_data,
            }
            
            # ìŠ¤ì½”ì–´ëŸ¬ì— ëª…ì‹œì  íŒŒë¼ë¯¸í„° ì „ë‹¬ (ìˆœìˆ˜ í•¨ìˆ˜)
            enhanced_score, score_breakdown = self.score_calculator.calculate_score(
                analysis_data, 
                sector_info=analysis_data['sector_info'], 
                price_data=analysis_data['price_data']
            )
            enhanced_grade = self._get_grade(enhanced_score)
            
            # ê¸°ì¡´ í†µí•© ë¶„ì„
            integrated_analysis = create_integrated_analysis(opinion_analysis, estimate_analysis)
            
            return AnalysisResult(
                symbol=symbol,
                name=name,
                status=AnalysisStatus.SUCCESS,
                enhanced_score=enhanced_score,
                enhanced_grade=enhanced_grade,
                market_cap=market_cap,
                current_price=price_data.get('current_price', 0),
                price_position=analysis_data['price_position'],
                price_band_outside=self._is_price_outside_52w_band(price_data),  # 52ì£¼ ë°´ë“œ ë°– ì—¬ë¶€
                financial_data=financial_data,
                opinion_analysis=opinion_analysis,
                estimate_analysis=estimate_analysis,
                integrated_analysis=integrated_analysis,
                score_breakdown=score_breakdown,
                price_data=price_data,  # ê°€ê²© ë°ì´í„° ìºì‹±
                sector_analysis=sector_analysis  # ì„¹í„° ë¶„ì„ ê²°ê³¼ ì¶”ê°€
            )
            
        except Exception as e:
            log_error("ì¢…ëª© ë¶„ì„", f"{name}({symbol})", e, "error")
            return AnalysisResult(
                symbol=symbol,
                name=name,
                status=AnalysisStatus.ERROR,
                error=str(e)
            )
        finally:
            # ë¶„ì„ ì†Œìš” ì‹œê°„ ê¸°ë¡
            if hasattr(self, "metrics") and self.metrics:
                self.metrics.record_analysis_duration(_monotonic() - start_time)
    
    def _is_preferred_stock(self, name: str) -> bool:
        """ìš°ì„ ì£¼ ì—¬ë¶€ í™•ì¸"""
        return DataValidator.is_preferred_stock(name)
    
    def _analyze_opinion(self, symbol: str, days_back: int, name: str = "") -> Dict[str, Any]:
        """íˆ¬ìì˜ê²¬ ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ ë³´ê°•)"""
        if not self.include_external:
            return {}
        try:
            with self._opinion_lock:
                cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                return _with_retries(
                    lambda: self.opinion_analyzer.analyze_single_stock(symbol, days_back=days_back),
                    metrics_attempt=cb_attempt,
                    metrics_final=cb_final
                )
        except Exception as e:
            if self.metrics:
                self.metrics.record_api_call(False, ErrorType.OPINION)
            log_error("íˆ¬ìì˜ê²¬ ë¶„ì„", f"{symbol}({name})", e)
            return {}
    
    def _analyze_estimate(self, symbol: str, name: str = "") -> Dict[str, Any]:
        """ì¶”ì •ì‹¤ì  ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ ë³´ê°•)"""
        if not self.include_external:
            return {}
        try:
            with self._estimate_lock:
                cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                return _with_retries(
                    lambda: self.estimate_analyzer.analyze_single_stock(symbol),
                    metrics_attempt=cb_attempt,
                    metrics_final=cb_final
                )
        except Exception as e:
            if self.metrics:
                self.metrics.record_api_call(False, ErrorType.ESTIMATE)
            log_error("ì¶”ì •ì‹¤ì  ë¶„ì„", f"{symbol}({name})", e)
            return {}
    
    def _analyze_sector(self, symbol: str, name: str = "", *, price_data: Dict[str, Any] = None, financial_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì„¹í„° ë¶„ì„ ìˆ˜í–‰ (ì¤‘ë³µ í˜ì¹˜ ë°©ì§€)"""
        try:
            # --- ê³µìš© í—¬í¼ë¥¼ í•¨ìˆ˜ ìƒë‹¨ì— ì •ì˜ (ìŠ¤ì½”í”„ ë²„ê·¸ ë°©ì§€) ---
            def _delta(score_0_100, weight):
                # 0~100 â†’ -50~+50 ë¡œ ë°”ê¾¼ ë’¤ weight%ë¥¼ ê³±í•´ì„œ ê°€/ê°ì 
                s = 0.0 if score_0_100 is None else max(0.0, min(100.0, float(score_0_100)))
                return (s - 50.0) * (weight / 100.0)
            # --------------------------------------------------------------------

            # ê¸°ë³¸ ì„¹í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            sector_info = self._get_sector_characteristics(symbol)
            sector_name = sector_info.get('name', 'ê¸°íƒ€')
            
            # ì „ë‹¬ë°›ì€ ë°ì´í„° ì‚¬ìš© ë˜ëŠ” ìƒˆë¡œ í˜ì¹˜
            price_data = price_data or self.data_provider.get_price_data(symbol)
            financial_data = financial_data or self.data_provider.get_financial_data(symbol)
            
            if not price_data or not financial_data:
                return {'grade': 'C', 'total_score': 50.0,
                        'breakdown': {'ì¬ë¬´_ê±´ì „ì„±': 50.0, 'ì„±ì¥ì„±': 50.0, 'ì•ˆì •ì„±': 50.0}}
            
            # PER, PBR, ROE ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (ê²°ì¸¡=0ìœ¼ë¡œ ì˜¤ì—¼ ë°©ì§€: safe_float_optional ì‚¬ìš©)
            per = DataValidator.safe_float_optional(price_data.get('per'))
            pbr = DataValidator.safe_float_optional(price_data.get('pbr'))
            roe = DataValidator.safe_float_optional(financial_data.get('roe'))
            market_cap_pd = normalize_market_cap_ekwon(DataValidator.safe_float_optional(price_data.get('market_cap', 0)))
            
            # ì„¹í„° ë°±ë¶„ìœ„ ê¸°ë°˜ ìŠ¤ì½”ì–´ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ê¸°ì¡´ ì„ í˜• ë§¤í•‘ ì‚¬ìš©
            sector_val = self._evaluate_valuation_by_sector(
                symbol,
                per=per if per is not None else float('nan'),
                pbr=pbr if pbr is not None else float('nan'),
                roe=roe if roe is not None else float('nan'),
                market_cap=market_cap_pd,
                price_data=price_data,
                financial_data=financial_data
            )
            
            # ì¬ë¬´_ê±´ì „ì„± ì ìˆ˜
            if sector_val and sector_val.get('total_score') is not None:
                financial_score = float(sector_val['total_score'])
            else:
                # ì„¹í„° ë°ì´í„° ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ë°˜í™˜í•˜ì—¬ ìƒìœ„ half-weight ë¡œì§ í•œ ë²ˆë§Œ ì ìš©
                financial_score = None

            # ì„±ì¥ì„± ì ìˆ˜ (ROE ê¸°ë°˜ ê°€/ê°ì )
            growth_score = 50.0
            if roe is not None and roe > 0:
                roe_score = self._calculate_metric_score(roe, min_val=5, max_val=20, reverse=False)
                if roe_score is not None:
                    growth_score += _delta(roe_score, 25)

            # ì•ˆì •ì„± ì ìˆ˜ (ì‹œì´ ê¸°ë°˜ ê°€/ê°ì )
            stability_score = 50.0
            market_cap_file = self._get_market_cap(symbol)  # ì–µì› ë‹¨ìœ„(íŒŒì¼ ê¸°ì¤€)
            mc = market_cap_file if market_cap_file else (market_cap_pd or 0)
            if mc > 100000: stability_score += 20
            elif mc > 50000: stability_score += 10

            # ê° ìŠ¤ì½”ì–´/ìµœì¢… í´ë¨í”„ (None ì•ˆì „ ì²˜ë¦¬)
            def _clamp_0_100(x, default=50.0):
                """ê°’ì„ 0-100 ë²”ìœ„ë¡œ í´ë¨í”„í•˜ë˜, Noneì´ë©´ ê¸°ë³¸ê°’ ë°˜í™˜"""
                if x is None:
                    return default
                try:
                    return max(0.0, min(100.0, float(x)))
                except (ValueError, TypeError):
                    return default
            
            financial_score = _clamp_0_100(financial_score, 50.0)
            growth_score    = _clamp_0_100(growth_score, 50.0)
            stability_score = _clamp_0_100(stability_score, 50.0)
            total_score     = _clamp_0_100((financial_score + growth_score + stability_score) / 3.0, 50.0)
            
            # ë“±ê¸‰ ê²°ì •
            if total_score >= 80:
                grade = 'A+'
            elif total_score >= 75:
                grade = 'A'
            elif total_score >= 70:
                grade = 'B+'
            elif total_score >= 65:
                grade = 'B'
            elif total_score >= 60:
                grade = 'C+'
            elif total_score >= 55:
                grade = 'C'
            else:
                grade = 'D'
            
            # í‰ë©´ ìŠ¤í‚¤ë§ˆë¡œ ë°˜í™˜ (ì •ê·œí™” í—¬í¼ì—ì„œ ê·¸ëŒ€ë¡œ ì†Œë¹„)
            return {
                'grade': grade,
                'total_score': float(total_score),
                'breakdown': {
                    'ì¬ë¬´_ê±´ì „ì„±': float(financial_score),
                    'ì„±ì¥ì„±': float(growth_score),
                    'ì•ˆì •ì„±': float(stability_score),
                },
                'is_leader': self._is_sector_leader(symbol, sector_name)
            }
            
        except Exception as e:
            logging.debug(f"ì„¹í„° ë¶„ì„ ì‹¤íŒ¨ {symbol}: {e}")
            return {'grade': 'C', 'total_score': 50.0,
                    'breakdown': {'ì¬ë¬´_ê±´ì „ì„±': 50.0, 'ì„±ì¥ì„±': 50.0, 'ì•ˆì •ì„±': 50.0}}
    

    def _get_market_cap(self, symbol: str) -> Optional[float]:
        """ì‹œê°€ì´ì•¡ ì¡°íšŒ (ì–µì› ë‹¨ìœ„)
        
        Note: KOSPI íŒŒì¼ì˜ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ì€ ì–µì› ë‹¨ìœ„ë¡œ ê°€ì •í•©ë‹ˆë‹¤.
        ë‹¤ë¥¸ ë‹¨ìœ„(ì›/ë°±ë§Œ/ì‹­ì–µ)ì¸ ê²½ìš° ì¼ê´€ì„±ì„ ìœ„í•´ ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.
        """
        if self.kospi_data is not None and not self.kospi_data.empty:
            stock_info = self.kospi_data[self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] == str(symbol)]
            if not stock_info.empty:
                mc = stock_info.iloc[0]['ì‹œê°€ì´ì•¡']
                if pd.isna(mc):
                    return None  # unknown market cap
                return float(mc)
        return None
    
    def _calculate_price_position(self, price_data: Dict[str, Any]) -> Optional[float]:
        """52ì£¼ ìœ„ì¹˜ ê³„ì‚° (NaN/0-division ë°©ì§€, ë°´ë“œ ë°–ë„ í´ë¨í”„)"""
        cp = DataValidator.safe_float_optional(price_data.get('current_price'))
        hi = DataValidator.safe_float_optional(price_data.get('w52_high'))
        lo = DataValidator.safe_float_optional(price_data.get('w52_low'))
        
        if cp is None or hi is None or lo is None:
            logging.debug("Missing 52w inputs for price position")
            return None
        if not (cp > 0 and hi > 0 and lo > 0):
            return None
        band = hi - lo
        # âœ… 52ì£¼ ë°´ë“œ ì„ê³„ì¹˜ í™˜ê²½ë³€ìˆ˜í™” (ê¸°ë³¸ 0.1%)
        tiny_band_threshold = safe_env_float("POS_TINY_BAND_THRESHOLD", 0.001, 0.0)  # 0.1%
        
        # ìƒëŒ€Â·ì ˆëŒ€ ë™ì‹œ ì²´í¬ë¡œ float ì˜¤ì°¨ ë° ê·¹ë¯¸/í‡´í™” ì¼€ì´ìŠ¤ ë°©ì§€
        if band <= 0 or band/hi <= tiny_band_threshold or band <= 1e-6:
            logging.debug(f"Tiny/degenerate 52w band: hi={hi}, lo={lo}, cp={cp}")
            # í‡´í™” ì¼€ì´ìŠ¤ ë©”íŠ¸ë¦­ ê¸°ë¡ (ìš´ì˜ ëª¨ë‹ˆí„°ë§ìš©) â€“ API ì‹¤íŒ¨ë¡œ ì§‘ê³„í•˜ì§€ ì•ŠìŒ
            if hasattr(self, 'metrics') and self.metrics:
                self.metrics.metrics['errors_by_type'][ErrorType.INVALID_52W_BAND] = \
                    self.metrics.metrics['errors_by_type'].get(ErrorType.INVALID_52W_BAND, 0) + 1
            return None
        
        raw = (cp - lo) / band * 100.0
        return max(0.0, min(100.0, raw))
    
    def _is_price_outside_52w_band(self, price_data: Dict[str, Any]) -> bool:
        """í˜„ì¬ê°€ê°€ 52ì£¼ ë°´ë“œ ë°–ì¸ì§€ í™•ì¸ (UI ê²½ê³ ìš©)"""
        cp = DataValidator.safe_float_optional(price_data.get('current_price'))
        hi = DataValidator.safe_float_optional(price_data.get('w52_high'))
        lo = DataValidator.safe_float_optional(price_data.get('w52_low'))
        
        if cp is None or hi is None or lo is None or not (cp > 0 and hi > 0 and lo > 0):
            return False
        return cp < lo or cp > hi
    
    def _analyze_profit_trend(self, financial_data: Dict[str, Any]) -> str:
        """ì´ìµë¥  ì¶”ì„¸ ë¶„ì„ (ì¤‘ë³µ API í˜¸ì¶œ ì œê±°)"""
        try:
            if not financial_data:
                return "unknown"
            current_roe = DataValidator.safe_float(financial_data.get('roe', 0))
            if current_roe <= 0:
                return "unknown"
            return "stable"
        except Exception as e:
            log_error("ì´ìµë¥  ì¶”ì„¸ ë¶„ì„", error=e)
            return "unknown"
    
    def _get_sector_characteristics(self, symbol: str) -> Dict[str, Any]:
        """ì—…ì¢…ë³„ íŠ¹ì„± ì •ë³´ ë°˜í™˜ (ìºì‹œ ì ìš©)"""
        now = _monotonic()
        
        # ìºì‹œ í™•ì¸ (ì„¹í„°ëª… ê¸°ì¤€ ìºì‹œ ìš°ì„  ì‹œë„)
        with self._sector_char_cache_lock:
            # 1) ì‹¬ë³¼â†’ì„¹í„°ëª… ìºì‹œ (ì–•ì€ ìºì‹œ) - ì¼ê´€ì„±ì„ ìœ„í•´ str(symbol) ì‚¬ìš©
            sym_hit = self._sector_char_cache.get(f"sym:{str(symbol)}")
            if sym_hit and now - sym_hit[0] < self._sector_char_cache_ttl:
                sector = sym_hit[1]['name']
                sec_hit = self._sector_char_cache.get(f"sec:{sector}")
                if sec_hit and now - sec_hit[0] < self._sector_char_cache_ttl:
                    return sec_hit[1]
            
            # ë ˆê±°ì‹œ í‚¤ ê²½ë¡œ ì œê±°: ëª¨ë“  ìºì‹œëŠ” 'sym:'/'sec:' ì ‘ë‘ ì‚¬ìš©
        
        try:
            # í•˜ë“œì½”ë”©ëœ ì—…ì¢… ë§¤í•‘ (ìš°ì„  ì ìš©)
            sector_mapping = {
                '005930': 'ê¸°ìˆ ì—…',  # ì‚¼ì„±ì „ì
                '000660': 'ê¸°ìˆ ì—…',  # SKí•˜ì´ë‹‰ìŠ¤
                '207940': 'ë°”ì´ì˜¤/ì œì•½',  # ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤
                '000270': 'ì œì¡°ì—…',  # ê¸°ì•„
                '329180': 'ì œì¡°ì—…',  # HDí˜„ëŒ€ì¤‘ê³µì—…
                '105560': 'ê¸ˆìœµì—…',  # KBê¸ˆìœµ
                '005380': 'ì œì¡°ì—…',  # í˜„ëŒ€ì°¨
                '012330': 'ì œì¡°ì—…',  # í˜„ëŒ€ëª¨ë¹„ìŠ¤
                '035420': 'ê¸°ìˆ ì—…',  # NAVER
                '035720': 'ê¸°ìˆ ì—…',  # ì¹´ì¹´ì˜¤
            }
            
            result = None
            
            # í•˜ë“œì½”ë”©ëœ ë§¤í•‘ì—ì„œ ë¨¼ì € ì°¾ê¸°
            if str(symbol) in sector_mapping:
                sector = sector_mapping[str(symbol)]
                result = self._get_sector_benchmarks(sector)
            else:
                # KOSPI ë°ì´í„°ì—ì„œ ì—…ì¢… ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì—¬ëŸ¬ ì»¬ëŸ¼ í›„ë³´ í™•ì¸)
                if hasattr(self, 'kospi_data') and not self.kospi_data.empty:
                    stock_info = self.kospi_data[self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] == str(symbol)]
                    if not stock_info.empty:
                        for col in ('ì—…ì¢…', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì—…ì¢…ëª…', 'ì„¹í„°'):
                            if col in stock_info.columns:
                                sector = str(stock_info.iloc[0].get(col) or 'ê¸°íƒ€')
                                if sector and sector != 'ê¸°íƒ€':
                                    result = self._get_sector_benchmarks(sector)
                                    break
                
                if result is None:
                    # ìš´ì˜ ì•ˆì „ì„ ìœ„í•œ ê°•ì œ í´ë°± ì˜µì…˜
                    force_fallback = os.getenv("SECTOR_FORCE_FALLBACK", "false").lower() == "true"
                    if force_fallback:
                        logging.warning(f"ì„¹í„° ì •ë³´ ì—†ìŒ, ê°•ì œ í´ë°± ì ìš©: {symbol}")
                    result = self._get_sector_benchmarks('ê¸°íƒ€')
            
            # ìºì‹œì— ì €ì¥ (ì„¹í„°ëª… ê¸°ì¤€ ìºì‹œ + ì‹¬ë³¼â†’ì„¹í„°ëª… ë§¤í•‘)
            with self._sector_char_cache_lock:
                sector = result.get('name', 'ê¸°íƒ€')
                sym_key = str(symbol)  # âœ… ì‹¬ë³¼ í‚¤ ë¬¸ìì—´í™”: íƒ€ì… ì•ˆì „ì„± ë³´ì¥ (sym:, sec: í‚¤ë§Œ ì‚¬ìš©)
                self._sector_char_cache[f"sym:{sym_key}"] = (now, {"name": sector})
                self._sector_char_cache[f"sec:{sector}"] = (now, result)
                # âœ… ë ˆê±°ì‹œ í‚¤ ì œê±°: ì¶©ëŒ ë°©ì§€ ë° ìºì‹œ í¬ê¸° ìµœì í™”
                # ìºì‹œ í¬ê¸° ì œí•œ (LRU ë°©ì‹) - sym:/sec: ìŒ ì‚½ì… ê³ ë ¤í•˜ì—¬ 2íšŒ pop
                while len(self._sector_char_cache) > 512:
                    self._sector_char_cache.popitem(last=False)
                    # ìŒìœ¼ë¡œ ì‚½ì…ë˜ë¯€ë¡œ í•œ ë²ˆ ë” pop
                    if len(self._sector_char_cache) > 512:
                        self._sector_char_cache.popitem(last=False)
            
            return result
            
        except Exception as e:
            log_error("ì—…ì¢… íŠ¹ì„± ë¶„ì„", symbol, e)
            result = self._get_sector_benchmarks('ê¸°íƒ€')
            # ì—ëŸ¬ ì¼€ì´ìŠ¤ë„ ìºì‹œì— ì €ì¥ (ì§§ì€ TTL ìœ ì‚¬ íš¨ê³¼ë¥¼ ìœ„í•´ 'now' ë³´ì •)
            now = _monotonic()
            with self._sector_char_cache_lock:
                sector = result.get('name', 'ê¸°íƒ€')
                sym_key = str(symbol)  # âœ… ì‹¬ë³¼ í‚¤ ë¬¸ìì—´í™”: íƒ€ì… ì•ˆì „ì„± ë³´ì¥ (sym:, sec: í‚¤ë§Œ ì‚¬ìš©)
                self._sector_char_cache[f"sym:{sym_key}"] = (now, {"name": sector})
                self._sector_char_cache[f"sec:{sector}"] = (now, result)
                # âœ… ë ˆê±°ì‹œ í‚¤ ì œê±°: ì¶©ëŒ ë°©ì§€ ë° ìºì‹œ í¬ê¸° ìµœì í™”
            return result
    
    def _sanitize_leaders(self, leaders):
        """ì„¹í„° ë¦¬ë” ëª©ë¡ ì •í•©ì„± ê²€ì¦ (KOSPI ë°ì´í„° ê¸°ì¤€)"""
        if self.kospi_data is None or self.kospi_data.empty:
            return leaders
        codes = set(self.kospi_data['ë‹¨ì¶•ì½”ë“œ'].astype(str))
        return [c for c in leaders if c in codes]
    
    def _get_sector_benchmarks(self, sector: str) -> Dict[str, Any]:
        """ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€ ë°˜í™˜"""
        # ì„¹í„°ëª… ë™ì˜ì–´ ë§¤í•‘
        SECTOR_ALIASES = {
            'it': 'ê¸°ìˆ ì—…', 'ì •ë³´ê¸°ìˆ ': 'ê¸°ìˆ ì—…', 'ì†Œí”„íŠ¸ì›¨ì–´': 'ê¸°ìˆ ì—…',
            'ë°”ì´ì˜¤': 'ë°”ì´ì˜¤/ì œì•½', 'ì œì•½': 'ë°”ì´ì˜¤/ì œì•½', 'ìƒëª…ê³¼í•™': 'ë°”ì´ì˜¤/ì œì•½',
            'ìë™ì°¨': 'ì œì¡°ì—…', 'ì „ì': 'ì œì¡°ì—…', 'í™”í•™': 'ì œì¡°ì—…',
            'ì€í–‰': 'ê¸ˆìœµì—…', 'ì¦ê¶Œ': 'ê¸ˆìœµì—…', 'ë³´í—˜': 'ê¸ˆìœµì—…',
            'ê±´ì„¤': 'ê±´ì„¤ì—…', 'ë¶€ë™ì‚°': 'ê±´ì„¤ì—…',
            'ìœ í†µ': 'ì†Œë¹„ì¬', 'ì‹í’ˆ': 'ì†Œë¹„ì¬', 'ì˜ë¥˜': 'ì†Œë¹„ì¬',
            'ì—ë„ˆì§€': 'ì—ë„ˆì§€/í™”í•™', 'ì„ìœ ': 'ì—ë„ˆì§€/í™”í•™',
            'í†µì‹ ': 'í†µì‹ ì—…', 'ë¯¸ë””ì–´': 'í†µì‹ ì—…'
        }
        
        # âœ… ì„¹í„° ë™ì˜ì–´ ì²˜ë¦¬ ê°€ë“œ ê°•í™” (None/ë¹„ë¬¸ì ì²˜ë¦¬)
        normalized_sector = SECTOR_ALIASES.get(str(sector).lower(), str(sector)) if sector else "ê¸°íƒ€"
        
        benchmarks = {
            'ê¸ˆìœµì—…': {
                'per_range': (5, 15),
                'pbr_range': (0.5, 2.0),
                'roe_range': (8, 20),
                'description': 'ì•ˆì •ì  ìˆ˜ìµì„±, ë‚®ì€ PBR',
                'leaders': ['105560', '055550', '086790']  # KBê¸ˆìœµ, ì‹ í•œì§€ì£¼, í•˜ë‚˜ê¸ˆìœµ
            },
            'ê¸°ìˆ ì—…': {
                'per_range': (15, 50),
                'pbr_range': (1.5, 8.0),
                'roe_range': (10, 30),
                'description': 'ë†’ì€ ì„±ì¥ì„±, ë†’ì€ PER',
                'leaders': ['005930', '000660', '035420', '035720']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, NAVER, ì¹´ì¹´ì˜¤
            },
            'ì œì¡°ì—…': {
                'per_range': (8, 25),
                'pbr_range': (0.8, 3.0),
                'roe_range': (8, 20),
                'description': 'ì•ˆì •ì  ìˆ˜ìµì„±, ì ì • PER',
                'leaders': ['005380', '000270', '012330', '329180']  # í˜„ëŒ€ì°¨, ê¸°ì•„, í˜„ëŒ€ëª¨ë¹„ìŠ¤, HDí˜„ëŒ€ì¤‘ê³µì—…
            },
            'ë°”ì´ì˜¤/ì œì•½': {
                'per_range': (20, 100),
                'pbr_range': (2.0, 10.0),
                'roe_range': (5, 25),
                'description': 'ë†’ì€ ë¶ˆí™•ì‹¤ì„±, ë†’ì€ PER',
                'leaders': ['207940', '068270', '006280']  # ë³´ìˆ˜ì ìœ¼ë¡œ ìœ ì§€: ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤, ì…€íŠ¸ë¦¬ì˜¨, ë…¹ì‹­ì
            },
            'ì—ë„ˆì§€/í™”í•™': {
                'per_range': (5, 20),
                'pbr_range': (0.5, 2.5),
                'roe_range': (5, 15),
                'description': 'ì‚¬ì´í´ íŠ¹ì„±, ë³€ë™ì„± í° ìˆ˜ìµ',
                'leaders': ['034020', '010140']  # ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°(ì—ë„ˆì§€), ì‚¼ì„±ì¤‘ê³µì—…(ì¡°ì„ /ì œì¡°) í¬í•¨: ì°¸ê³ ìš©
            },
            'ì†Œë¹„ì¬': {
                'per_range': (10, 30),
                'pbr_range': (1.0, 4.0),
                'roe_range': (8, 18),
                'description': 'ì•ˆì •ì  ìˆ˜ìš”, ì ì • ìˆ˜ìµì„±',
                'leaders': []  # ì—…ì¢…ê³¼ ì•ˆ ë§ëŠ” í•­ëª© ì œê±° (SKí…”ë ˆì½¤ì€ í†µì‹ ì—…, í˜„ëŒ€ê±´ì„¤ì€ ê±´ì„¤ì—…)
            },
            'í†µì‹ ì—…': {
                'per_range': (8, 20),
                'pbr_range': (0.8, 3.0),
                'roe_range': (6, 15),
                'description': 'í˜„ê¸ˆíë¦„ ì•ˆì •',
                'leaders': ['017670']  # SKí…”ë ˆì½¤ ë“± í†µì‹ ì—… ë¦¬ë”
            },
            'ê±´ì„¤ì—…': {
                'per_range': (5, 15),
                'pbr_range': (0.5, 2.0),
                'roe_range': (5, 12),
                'description': 'í”„ë¡œì íŠ¸ ì‚¬ì´í´ ì˜í–¥',
                'leaders': ['000720']  # í˜„ëŒ€ê±´ì„¤ ë“± ê±´ì„¤ì—… ë¦¬ë”
            },
            'ê¸°íƒ€': {
                'per_range': (8, 25),
                'pbr_range': (0.8, 3.0),
                'roe_range': (8, 20),
                'description': 'ì¼ë°˜ì  ê¸°ì¤€',
                'leaders': []
            }
        }
        
        # ì •ê·œí™”ëœ ì„¹í„°ëª…ìœ¼ë¡œ ë§¤ì¹­
        sector_key = 'ê¸°íƒ€'
        s = str(normalized_sector).strip().lower()
        for key in benchmarks.keys():
            if s == key.lower():
                sector_key = key
                break
        else:
            for key in benchmarks.keys():
                if key.lower() in s or s in key.lower():
                    sector_key = key
                    break
        
        ret = benchmarks.get(sector_key, benchmarks['ê¸°íƒ€']).copy()
        ret['name'] = sector_key
        ret['leaders'] = self._sanitize_leaders(ret.get('leaders', []))
        return ret
    
    def _is_sector_leader(self, symbol: str, sector: str) -> bool:
        """ì—…ì¢…ë³„ ëŒ€ì¥ì£¼ ì—¬ë¶€ í™•ì¸"""
        try:
            sector_info = self._get_sector_benchmarks(sector)
            leaders = sector_info.get('leaders', [])
            return str(symbol) in leaders
        except Exception:
            return False
    
    def _calculate_leader_bonus(self, symbol: str, sector: str, market_cap: float,
                                price_data: Dict[str, Any] = None, financial_data: Dict[str, Any] = None) -> float:
        """ì—…ì¢…ë³„ ëŒ€ì¥ì£¼ ê°€ì‚°ì  ê³„ì‚°
        
        Args:
            symbol: ì¢…ëª© ì½”ë“œ
            sector: ì—…ì¢…ëª…
            market_cap: ì‹œê°€ì´ì•¡ (ì–µì› ë‹¨ìœ„)
            price_data: ê°€ê²© ë°ì´í„°
            financial_data: ì¬ë¬´ ë°ì´í„°
            
        Returns:
            ëŒ€ì¥ì£¼ ê°€ì‚°ì  (0.0 ~ 10.0)
        """
        try:
            # ì„¹í„° ì •ë³´ ê²€ì¦ - ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ë³´ë„ˆìŠ¤ 0
            sector_info = self._get_sector_benchmarks(sector)
            if not sector_info or sector_info.get('name') == 'ê¸°íƒ€':
                return 0.0
            
            # ëŒ€ì¥ì£¼ ì—¬ë¶€ í™•ì¸
            is_leader = self._is_sector_leader(symbol, sector)
            if not is_leader:
                return 0.0
            
            # í’ˆì§ˆ ì¡°ê±´ ì¶”ê°€: ROE >= 8 & PBR <= ì„¹í„° ìƒë‹¨
            price = price_data or self.data_provider.get_price_data(symbol)
            fin = financial_data or self.data_provider.get_financial_data(symbol)
            pbr = DataValidator.safe_float_optional(price.get('pbr'))
            roe = DataValidator.safe_float_optional(fin.get('roe'))
            
            # ê²°ì¸¡ê°’ì€ ë³´ë„ˆìŠ¤ 0ìœ¼ë¡œ ì—„ê²© ì²˜ë¦¬
            if pbr is None or roe is None:
                return 0.0
            
            # í’ˆì§ˆ ì»·: ROE < 8 ë˜ëŠ” PBR > ì„¹í„° ìƒë‹¨ ì‹œ ë³´ë„ˆìŠ¤ ì—†ìŒ (PBR ìœ ì—°í™”)
            pbr_upper = sector_info['pbr_range'][1] * safe_env_float("LEADER_PBR_TOL", 1.1, 1.0)
            if roe < 8 or pbr > pbr_upper:
                return 0.0
            
            # ê°•ë„ ì¶•ì†Œ: ìº¡ 5ì  (ì–µì› ê¸°ì¤€)
            if market_cap >= 1_000_000:  # 100ì¡°ì› ì´ìƒ
                return 5.0
            elif market_cap >= 500_000:  # 50ì¡°ì› ì´ìƒ
                return 4.0
            elif market_cap >= 100_000:  # 10ì¡°ì› ì´ìƒ
                return 3.5
            elif market_cap >= 50_000:   # 5ì¡°ì› ì´ìƒ
                return 3.0
            else:  # 5ì¡°ì› ë¯¸ë§Œ
                return 2.5
                
        except Exception as e:
            log_error("ëŒ€ì¥ì£¼ ê°€ì‚°ì  ê³„ì‚°", symbol, e)
            return 0.0
    
    def _evaluate_valuation_by_sector(self, symbol: str, per: float, pbr: float, roe: float, market_cap: float = 0,
                                      price_data: Dict[str, Any] = None, financial_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì„¹í„° ë‚´ë¶€ ë°±ë¶„ìœ„ ê¸°ë°˜ ë°¸ë¥˜ì—ì´ì…˜ í‰ê°€"""
        start_time = _monotonic()
        try:
            
            sector_info = self._get_sector_characteristics(symbol)
            sector_name = sector_info.get('name', 'ê¸°íƒ€')
            
            # ì„¹í„° ë™ì¢…êµ° ìƒ˜í”Œë§ + ìºì‹œ ì‚¬ìš©
            vals = self._get_sector_peers_snapshot(sector_name)
            
            # ë°±ë¶„ìœ„ ê³„ì‚°
            if len(vals) == 0:
                return {
                    'total_score': None,   # â† Noneìœ¼ë¡œ ì˜¬ë ¤ half-weight ê·œì¹™ ì ìš© ê°€ëŠ¥
                    'base_score': None,
                    'leader_bonus': 0.0,
                    'is_leader': False,
                    'grade': 'N/A',
                    'description': 'ë°ì´í„° ë¶€ì¡±',
                    'per_score': None, 'pbr_score': None, 'roe_score': None,
                    'sector_info': sector_info,
                    'notes': ['insufficient_peers']
                }
            
            arr = np.array(vals, dtype=float)
            if arr.ndim == 1:  # 1ì°¨ì› ë°°ì—´ì¸ ê²½ìš° 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜
                arr = arr.reshape(-1, 3)
            
            notes = []
            
            def pct_rank(x, col):
                if x is None or not isinstance(x, (int, float)) or not math.isfinite(x):
                    return None  # ê²°ì¸¡ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ ê°€ì¤‘ì¹˜ ì œì™¸
                if arr.shape[1] <= col:
                    return None
                colv = np.asarray(arr[:, col], dtype=float)
                colv = colv[~np.isnan(colv)]
                if colv.size == 0:
                    return None
                if len(colv) < 10:
                    # âœ… í‘œë³¸ ë¶€ì¡± ì‹œ í•´ë‹¹ ì§€í‘œ ê°€ì¤‘ì¹˜ ì œì™¸ (None ë°˜í™˜) + ë©”íŠ¸ë¦­ ê¸°ë¡
                    if self.metrics:
                        self.metrics.record_sector_sample_insufficient(sector_name)
                    col_names = ['per', 'pbr', 'roe']
                    col_name = col_names[col] if col < len(col_names) else f'col_{col}'
                    notes.append(f"insufficient_peers_{col_name}")
                    
                    # âœ… ìŠ¤ë ˆë“œ ì•ˆì „í•œ ìŠ¤ë¡œí‹€ë§ëœ ë¡œê¹…: ì²« ë²ˆì§¸ëŠ” WARN, ì´í›„ëŠ” DEBUG
                    key = f"{sector_name}:{col_name}"
                    with self._sector_warned_lock:
                        if key not in self._sector_warned:
                            logging.warning(f"[sector-percentile] insufficient peers for {col_name} in sector='{sector_name}' (<10 samples)")
                            self._sector_warned.add(key)
                        else:
                            logging.debug(f"[sector-percentile] insufficient peers for {col_name} in sector='{sector_name}' (<10 samples)")
                    logging.debug(f"Sector percentile skipped (insufficient peers<10) col={col} sector={sector_name}")
                    return None
                # guard: if all values are identical, avoid 0/0 weirdness later
                if np.all(colv == colv[0]):
                    # ëª¨ë“  í”¼ì–´ ë™ì¼ê°’: ë°±ë¶„ìœ„ ì¤‘ë¦½ 0.5ë¡œ ì²˜ë¦¬ (ì €/ê³  ì„ í˜¸ ì§€í‘œ ëª¨ë‘ ì¤‘ë¦½)
                    return 0.5
                return float((colv < x).mean())
            
            per_p = pct_rank(per, 0)   # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ score = 1 - per_p
            pbr_p = pct_rank(pbr, 1)   # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ score = 1 - pbr_p
            roe_p = pct_rank(roe, 2)   # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ score = roe_p
            
            # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° (ì¡´ì¬í•˜ëŠ” ì§€í‘œë§Œ ê°€ì¤‘í•©)
            scores = []
            if per_p is not None:
                scores.append(1 - per_p)  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            if pbr_p is not None:
                scores.append(1 - pbr_p)  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            if roe_p is not None:
                scores.append(roe_p)      # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            
            if not scores:
                # ëª¨ë“  ì§€í‘œê°€ ê²°ì¸¡ì¸ ê²½ìš° ì¤‘ë¦½ ì ìˆ˜
                base_score = 50.0
                notes.append('all_metrics_skipped')
                # âœ… ë©”íŠ¸ë¦­ ì´ì¤‘ ì§‘ê³„ ë°©ì§€: ì»¬ëŸ¼ë³„ë¡œ ì´ë¯¸ ê¸°ë¡í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œì™¸
            else:
                base_score = sum(scores) / len(scores) * 100.0
            
            # ë¦¬ë” ë³´ë„ˆìŠ¤(ì¶•ì†Œ í›„) ì ìš© (ì–µì› ë‹¨ìœ„ë¡œ ì •ê·œí™”)
            market_cap_ek = normalize_market_cap_ekwon(market_cap)
            leader_bonus = self._calculate_leader_bonus(symbol, sector_name, market_cap_ek or 0.0, 
                                                       price_data, financial_data)
            
            # ì„¹í„° í‘œë³¸ ë¶€ì¡± ì‹œ ë¦¬ë” ë³´ë„ˆìŠ¤ ìº¡ ì ìš© (ì ìˆ˜ ë¶€í’€ë¦¼ ë°©ì§€)
            if not scores:
                # ëª¨ë“  ì§€í‘œê°€ ì œì™¸ëœ ê²½ìš° leader_bonusë¥¼ 0ìœ¼ë¡œ ê³ ì • (ê³¼ë³´ì • ë°©ì§€)
                leader_bonus = 0.0
                logging.debug(f"[sector] All metrics excluded, leader_bonus set to 0.0 to prevent over-correction")
            
            # ì„¹í„° ì´ í‘œë³¸ ìˆ˜ì— ë”°ë¥¸ ì—°ì† ê°ì‡  (ê³¼ì‰ ë³´ì • ë°©ì§€)
            sector_sample_count = len(vals) if 'vals' in locals() else 0
            if sector_sample_count < 30:
                # í‘œë³¸ í¬ê¸°ì— ë”°ë¥¸ ì—°ì† ê°ì‡  (0.5~1.0 ì‚¬ì´)
                factor = max(0.5, sector_sample_count / 30.0)
                leader_bonus *= factor
                logging.debug(f"[sector] Sample size ({sector_sample_count}), leader bonus factor: {factor:.2f}")
            
            total_score = min(100, max(0, base_score + leader_bonus))
            
            # ë“±ê¸‰ ê²°ì •
            grade = "A+" if total_score>=80 else "A" if total_score>=70 else "B+" if total_score>=60 else "B" if total_score>=50 else "C" if total_score>=40 else "D"
            
            # ëŒ€ì¥ì£¼ ì—¬ë¶€ í™•ì¸
            is_leader = self._is_sector_leader(symbol, sector_name)
            
            # ê°œë³„ ì§€í‘œ ì ìˆ˜ ê³„ì‚° (None ê°€ë“œ)
            per_score = (100*(1-per_p)) if per_p is not None else None
            pbr_score = (100*(1-pbr_p)) if pbr_p is not None else None
            roe_score = (100*roe_p) if roe_p is not None else None
            
            return {
                'total_score': float(total_score),
                'base_score': float(base_score),
                'leader_bonus': float(leader_bonus),
                'is_leader': is_leader,
                'grade': grade,
                'description': 'ì„¹í„° ë°±ë¶„ìœ„ ê¸°ë°˜ ì ìˆ˜',
                'per_score': per_score,
                'pbr_score': pbr_score,
                'roe_score': roe_score,
                'sector_info': sector_info,
                'notes': list(set(notes)) if notes else []
            }
            
        except Exception as e:
            log_error("ì—…ì¢…ë³„ ë°¸ë¥˜ì—ì´ì…˜ í‰ê°€", symbol, e)
            return {
                'total_score': 50.0, 'base_score': 50.0, 'leader_bonus': 0.0,
                'is_leader': False, 'grade': 'C', 'description': 'í‰ê°€ ë¶ˆê°€',
                'per_score': 50.0, 'pbr_score': 50.0, 'roe_score': 50.0,
                'sector_info': {'description': 'ê¸°íƒ€'}
            }
        finally:
            # ì„¹í„° í‰ê°€ ì†Œìš” ì‹œê°„ ê¸°ë¡
            duration = _monotonic() - start_time
            if self.metrics:
                self.metrics.record_sector_evaluation(duration)
    
    def _calculate_metric_score(self, value: float, min_val: float, max_val: float, reverse: bool = False) -> Optional[float]:
        """ì§€í‘œë³„ ì ìˆ˜ ê³„ì‚° (PER/PBR/ROE ë“± ì„ í˜• ë§¤í•‘ í—¬í¼)"""
        # âœ… _calculate_metric_score ê°€ë“œ ê°•í™”: NaN ë° ë¬´í•œê°’ ì²˜ë¦¬
        if value is None or not math.isfinite(value) or value <= 0:
            return None  # ìƒìœ„ì—ì„œ half-weight+50ì ìœ¼ë¡œ ì²˜ë¦¬
        
        if max_val <= min_val:
            return 50.0  # ì•ˆì „í•œ ì¤‘ë¦½ê°’ ë°˜í™˜
        
        # ì •ê·œí™” (0-100ì )
        if reverse:
            # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ (PER, PBR)
            if value <= min_val:
                return 100
            elif value >= max_val:
                return 0
            else:
                return 100 - ((value - min_val) / (max_val - min_val)) * 100
        else:
            # ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ (ROE)
            if value >= max_val:
                return 100
            elif value <= min_val:
                return 0
            else:
                return ((value - min_val) / (max_val - min_val)) * 100
    
    def _get_grade(self, score: float) -> str:
        """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        thresholds = self.config.grade_thresholds
        
        if score >= thresholds.get('A_plus', 80):
            return 'A+'
        elif score >= thresholds.get('A', 70):
            return 'A'
        elif score >= thresholds.get('B_plus', 60):
            return 'B+'
        elif score >= thresholds.get('B', 50):
            return 'B'
        elif score >= thresholds.get('C_plus', 40):
            return 'C+'
        elif score >= thresholds.get('C', 30):
            return 'C'
        elif score >= thresholds.get('D_plus', 20):
            return 'D+'
        elif score >= thresholds.get('D', 10):
            return 'D'
        else:
            return 'F'
    
    def _resolve_price_and_position(self, stock_dict):
        """ê°€ê²©Â·52ì£¼ ì •ë³´ ê³„ì‚° ê²½ë¡œ í†µí•© í—¬í¼"""
        def _pick_price(d):
            if not d:
                return {}
            # dictì´ë©´ ê·¸ëŒ€ë¡œ, ê°ì²´ì´ë©´ price_data ìš°ì„  ì ‘ê·¼
            if isinstance(d, dict):
                return d.get('price_data', d) or {}
            return getattr(d, 'price_data', {}) or {}
        
        # 1) enhanced(price_data) -> 2) basic(price_data) -> 3) (í•„ìš” ì‹œ) ì‹¤ì‹œê°„/ì—‘ì…€
        p = _pick_price(stock_dict.get('enhanced_result') or {}) \
            or _pick_price(stock_dict.get('basic_result') or {})  # legacy
        current = p.get('current_price')
        w52h, w52l = p.get('w52_high'), p.get('w52_low')
        
        # í˜„ì¬ê°€ê°€ ì—†ìœ¼ë©´ (ì˜µì…˜ í—ˆìš© ì‹œ) ì¤‘ì•™í™”ëœ í”„ë¡œë°”ì´ë” ì‚¬ìš©
        if current is None and self.include_realtime:
            try:
                # prefer centralized provider (uses TTL cache + retries)
                p2 = self.data_provider.get_price_data(stock_dict.get('symbol'))
                current = p2.get('current_price') or current
                w52h = w52h or p2.get('w52_high')
                w52l = w52l or p2.get('w52_low')
            except Exception:
                pass
        
        # 52ì£¼ ê³ ê°€/ì €ê°€ê°€ ì—†ìœ¼ë©´ (ì˜µì…˜ í—ˆìš© ì‹œ) ì‹¤ì‹œê°„ ì¡°íšŒ (KIS + ì¬ì‹œë„ + ë ˆì´íŠ¸ë¦¬ë¯¸í„°)
        if (w52h is None or w52l is None) and self.include_realtime:
            try:
                symbol = stock_dict.get('symbol')
                if symbol:
                    self.rate_limiter.acquire()
                    cb_final = (lambda ok, et=None: self.metrics.record_api_call(ok, et)) if self.metrics else None
                    cb_attempt = (lambda et=None: self.metrics.record_api_attempt_error(et)) if self.metrics else None
                    price_info = _with_retries(
                        lambda: self.provider.get_stock_price_info(symbol),
                        metrics_attempt=cb_attempt,
                        metrics_final=cb_final
                    )
                    if price_info:
                        w52h = price_info.get('w52_high') or w52h
                        w52l = price_info.get('w52_low') or w52l
            except Exception as e:
                if self.metrics:
                    self.metrics.record_api_call(False, ErrorType.PRICE_DATA)
                logging.debug(f"52ì£¼ ê³ ê°€/ì €ê°€ ì¡°íšŒ ì‹¤íŒ¨ {stock_dict.get('symbol')}: {e}")
        
        # ì—¬ì „íˆ 52ì£¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ KOSPI íŒŒì¼ì—ì„œ ì‹œë„
        if (w52h is None or w52l is None) and self.kospi_data is not None and not self.kospi_data.empty:
            try:
                code = stock_dict.get('symbol')
                row = self.kospi_data[self.kospi_data['ë‹¨ì¶•ì½”ë“œ'] == str(code)]
                if not row.empty:
                    # KOSPI íŒŒì¼ì—ì„œ 52ì£¼ ì •ë³´ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
                    if '52ì£¼ìµœê³ ê°€' in row.columns:
                        w52h = row.iloc[0].get('52ì£¼ìµœê³ ê°€') or w52h
                    if '52ì£¼ìµœì €ê°€' in row.columns:
                        w52l = row.iloc[0].get('52ì£¼ìµœì €ê°€') or w52l
            except Exception as e:
                logging.debug(f"KOSPI íŒŒì¼ 52ì£¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ {stock_dict.get('symbol')}: {e}")
        
        # ìœ„ì¹˜ ê³„ì‚°ì€ ë‹¨ì¼ ì§„ì…ì  í•¨ìˆ˜ë¡œ í†µì¼
        position = self._calculate_price_position({'current_price': current, 'w52_high': w52h, 'w52_low': w52l})
        return current, position
    
    def _position_label(self, pos: Optional[float], is_outside_band: bool = False) -> str:
        """52ì£¼ ìœ„ì¹˜ì— ë”°ë¥¸ ë¼ë²¨ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # âœ… ê°€ë“œ 3: NaN/ë¹„ì •ìƒ ê°’ ì•ˆì „ ì²˜ë¦¬
        try:
            if pos is None:
                return "N/A"
            v = float(pos)
            if not math.isfinite(v):
                return "N/A"
            pos = max(0.0, min(100.0, v))
        except Exception:
            return "N/A"
        base_text = fmt(pos, '%')
        warning = " âš ï¸ ë°´ë“œë°–" if is_outside_band else ""
        
        if pos >= 95:
            return f"{base_text} ğŸ”´ ê³¼ì—´/ì¶”ì„¸{warning}"
        if pos >= 85:
            return f"{base_text} ğŸŸ¡ ìƒë‹¨{warning}"
        if pos <= 30:
            return f"{base_text} ğŸŸ¢ ì €ê°€êµ¬ê°„(í• ì¸){warning}"
        return f"{base_text} ì¤‘ë¦½{warning}"
    
    def _classify_bucket(self, pos: Optional[float]) -> str:
        """52ì£¼ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°”ìŠ¤ì¼“ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
        if pos is None:
            return "ë°¸ë¥˜/ë¦¬ìŠ¤í¬ê´€ë¦¬"
        return "ëª¨ë©˜í…€/ë¸Œë ˆì´í¬ì•„ì›ƒ" if pos >= 85 else "ë°¸ë¥˜/ë¦¬ìŠ¤í¬ê´€ë¦¬"
    
    def _get_position_sizing(self, pos: Optional[float], bucket_type: str) -> float:
        """í¬ì§€ì…˜ ì‚¬ì´ì§•ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if pos is None:
            return 1.0
        
        if bucket_type == "ë°¸ë¥˜/ë¦¬ìŠ¤í¬ê´€ë¦¬":
            if pos <= 30:  # ë”¥ë°¸ë¥˜
                return 1.2
            elif pos <= 70:  # ì¤‘ë¦½
                return 1.0
            else:
                return 0.8
        else:  # ëª¨ë©˜í…€/ë¸Œë ˆì´í¬ì•„ì›ƒ
            if pos >= 95:
                return 0.5
            else:
                return 0.7
    
    def _get_risk_reward_ratio(self, pos: Optional[float], bucket_type: str) -> str:
        """ì†ìµë¹„ ê¸°ì¤€ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if bucket_type == "ëª¨ë©˜í…€/ë¸Œë ˆì´í¬ì•„ì›ƒ" and pos is not None:
            if pos >= 95:
                return "ì†ì ˆ7% ëª©í‘œ1.8R"
            elif pos >= 85:
                return "ì†ì ˆ8% ëª©í‘œ1.8R"
            else:
                return "ì†ì ˆ8% ëª©í‘œ1.8R"
        else:
            return "N/A"
    
    def _extract_sector_valuation_text(self, stock: dict) -> str:
        """dict â†’ AnalysisResult(enhanced_result) â†’ sector_analysisì—ì„œ ì„¹í„° ë°¸ë¥˜ ì ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            # dict â†’ AnalysisResult(enhanced_result) â†’ sector_analysis
            ar = stock.get("enhanced_result")
            raw = {}
            if isinstance(ar, AnalysisResult):
                raw = ar.sector_analysis or {}
            if not raw:
                raw = stock.get("sector_analysis", {})
            norm = self._normalize_sector_analysis(raw)
            if norm['grade'] == 'N/A' or norm['total_score'] is None:
                return "N/A"
            return f"{norm['grade']}({norm['total_score']:.1f})"
        except Exception:
            return "N/A"

    def _get_sector_valuation_score(self, stock: Dict[str, Any]) -> str:
        """ì„¹í„° ìƒëŒ€ ë°¸ë¥˜ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            norm = self._normalize_sector_analysis(stock.get('sector_analysis', {}))
            if norm['total_score'] is None:
                return "N/A"
            return f"{norm['grade']}({norm['total_score']:.1f})"
        except Exception as e:
            logging.debug(f"ì„¹í„° ë°¸ë¥˜ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨ {stock.get('symbol')}: {e}")
            return "N/A"
    
    def _get_basket_type(self, stock: Dict[str, Any]) -> str:
        """ì¢…ëª©ì˜ 52ì£¼ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°”ìŠ¤ì¼“ íƒ€ì…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            # ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš© (ì¶”ê°€ API í˜¸ì¶œ ê¸ˆì§€)
            price_position = stock.get("price_position")
            if price_position is None:
                current_price = stock.get("current_price")
                w52h = stock.get("w52_high")
                w52l = stock.get("w52_low")
                if current_price is not None and w52h is not None and w52l is not None:
                    price_position = self._calculate_price_position({
                        'current_price': current_price,
                        'w52_high': w52h,
                        'w52_low': w52l
                    })
            return self._classify_bucket(price_position)
        except Exception as e:
            logging.debug(f"ë°”ìŠ¤ì¼“ ë¶„ë¥˜ ì‹¤íŒ¨ {stock.get('symbol')}: {e}")
            return "ë¶„ë¥˜ë¶ˆê°€"
    
    # --- ì„¹í„° ë¶„ì„ ìŠ¤í‚¤ë§ˆ ì •ê·œí™” í—¬í¼ ---
    def _normalize_sector_analysis(self, node: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë‹¤ì–‘í•œ í˜•íƒœ(ì¤‘ì²©/í‰ë©´)ì˜ ì„¹í„° ë¶„ì„ ê²°ê³¼ë¥¼ í‰ë©´ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”.
        ë°˜í™˜ ìŠ¤í‚¤ë§ˆ: {'grade': str, 'total_score': float}
        """
        if not node:
            return {'grade': 'N/A', 'total_score': None}
        # ì¤‘ì²©ëœ {'sector_analysis': {...}} í˜•íƒœ ìˆ˜ìš©
        if 'sector_analysis' in node and isinstance(node['sector_analysis'], dict):
            node = node['sector_analysis']
        # í‚¤ ë³€í˜• ìˆ˜ìš©
        grade = node.get('grade') or node.get('sector_grade') or 'N/A'
        total = node.get('total_score')
        try:
            total = float(total) if total is not None else None
        except Exception:
            total = None
        return {'grade': grade, 'total_score': total}
    
    def _nan_if_nonpos(self, x, zero_is_nan: bool = True):
        """
        0 ì´ìƒì´ê³  ìœ í•œí•œ ê°’ë§Œ ë°˜í™˜, ê·¸ ì™¸ëŠ” NaN
        
        ì •ì±…:
        - PER/PBR: 0 ì´ìƒë§Œ í†µê³¼ (ìŒìˆ˜ëŠ” ì˜ì—…ì ìë¡œ ì œì™¸)
        - ROE: 0 ì´ìƒë§Œ í†µê³¼ (ìŒìˆ˜ëŠ” ì†ì‹¤ë¡œ ì œì™¸, 0ì€ í¬í•¨)
        - zero_is_nan=True: 0ë„ NaNìœ¼ë¡œ ì²˜ë¦¬ (ë” ì—„ê²©í•œ í•„í„°ë§)
        """
        v = DataValidator.safe_float(x, float('nan'))
        if not (isinstance(v, (int, float, np.floating)) and math.isfinite(float(v))):
            return float('nan')
        if v < 0: 
            return float('nan')
        if zero_is_nan and v == 0: 
            return float('nan')
        return float(v)
    
    def _nan_if_negative(self, x):
        """
        ìŒìˆ˜ë§Œ NaNìœ¼ë¡œ ì²˜ë¦¬, 0ê³¼ ì–‘ìˆ˜ëŠ” ìœ ì§€ (ROE=0 ì¼€ì´ìŠ¤ í¬í•¨)
        """
        x = DataValidator.safe_float(x, float('nan'))
        if isinstance(x, (int, float, np.floating)) and math.isfinite(float(x)) and float(x) >= 0:
            return float(x)
        return float('nan')

    def _get_sector_peers_snapshot(self, sector_name: str) -> List[PeerTriple]:
        """
        ì£¼ì–´ì§„ ì„¹í„°ì˜ í”¼ì–´ë“¤ì— ëŒ€í•œ (PER, PBR, ROE) ìŠ¤ëƒ…ìƒ·ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        - ë°˜í™˜: [(per, pbr, roe), ...]  (ëª¨ë‘ ìœ íš¨í•œ ë¹„ìŒìˆ˜ê°€ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ ì±„íƒ)
        - 10ë¶„ TTL ìºì‹œ(_sector_cache) ì ìš©
        """
        now = _monotonic()

        # 1) ìºì‹œ ì¡°íšŒ
        with self._sector_cache_lock:
            hit = self._sector_cache.get(sector_name)
            if hit and now - hit[0] < self._sector_cache_ttl:
                return hit[1]

        # 2) KOSPI ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        if self.kospi_data is None or self.kospi_data.empty:
            with self._sector_cache_lock:
                self._sector_cache[sector_name] = (now, [])
            return []

        # 3) ì„¹í„° ì»¬ëŸ¼ í›„ë³´ì—ì„œ ë™ì¢…êµ° ì¶”ì¶œ
        sector_cols = ('ì—…ì¢…', 'ì§€ìˆ˜ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì—…ì¢…ëª…', 'ì„¹í„°')
        df = self.kospi_data
        peers_df = None
        s_lower = str(sector_name).strip().lower()

        for col in sector_cols:
            if col in df.columns:
                tmp = df[df[col].astype(str).str.strip().str.lower() == s_lower]
                if not tmp.empty:
                    peers_df = tmp
                    break
        if peers_df is None or peers_df.empty:
            # ì„¹í„°ëª…ì´ ì• ë§¤í•˜ë©´ ë¶€ë¶„ë§¤ì¹­(contains)ë¡œ í•œ ë²ˆ ë” ì‹œë„
            for col in sector_cols:
                if col in df.columns:
                    tmp = df[df[col].astype(str).str.strip().str.lower().str.contains(s_lower, na=False)]
                    if not tmp.empty:
                        peers_df = tmp
                        break

        if peers_df is None or peers_df.empty:
            with self._sector_cache_lock:
                self._sector_cache[sector_name] = (now, [])
            return []

        # 4) ë™ì¢…êµ° ì½”ë“œ ìˆ˜ì§‘ (ë¬¸ì 6ìë¦¬)
        codes = (
            peers_df.get('ë‹¨ì¶•ì½”ë“œ', pd.Series(dtype=str))
            .astype(str)
            .str.replace(r'\.0$', '', regex=True)
            .str.zfill(6)
            .tolist()
        )

        # 5) í‘œë³¸ ìˆ˜ ì œí•œ: base/full
        max_full = self.env_cache.get('max_sector_peers_full', 200)
        if len(codes) > max_full:
            # ëœë¤ ìƒ˜í”Œë§(ì„¹í„° í‰ê· ì„ ì™œê³¡í•˜ì§€ ì•Šë„ë¡ ë„“ê²Œ ê³ ë¥´ê²Œ)
            random.shuffle(codes)
            codes = codes[:max_full]

        # 6) ë™ì‹œ ìˆ˜ì§‘
        results: List[PeerTriple] = []
        max_workers = safe_env_int("MAX_WORKERS", 0, min_val=None) or min(32, max(4, os.cpu_count() or 8))

        def fetch_tuple(code: str) -> Optional[PeerTriple]:
            try:
                # ìºì‹œëœ í”„ë¡œë°”ì´ë” ì‚¬ìš©: ë‚´ë¶€ TTL + ì¬ì‹œë„ ì²˜ë¦¬
                pdict = self.data_provider.get_price_data(code) or {}
                fdict = self.data_provider.get_financial_data(code) or {}

                per = self._nan_if_nonpos(pdict.get('per'), zero_is_nan=True)
                pbr = self._nan_if_nonpos(pdict.get('pbr'), zero_is_nan=True)
                roe = self._nan_if_negative(fdict.get('roe'))  # ROEëŠ” 0 í—ˆìš©, ìŒìˆ˜ ì œì™¸

                if not (math.isfinite(per) and math.isfinite(pbr) and math.isfinite(roe)):
                    return None
                return (per, pbr, roe)
            except Exception:
                return None

        with ThreadPoolExecutor(max_workers=max_workers) as ex:
            for tup in ex.map(fetch_tuple, codes):
                if tup is not None:
                    results.append(tup)

        # 7) ê²°ê³¼ ìºì‹œ + LRU ì¶•ì†Œ
        with self._sector_cache_lock:
            self._sector_cache[sector_name] = (now, results)
            # LRU: ì˜¤ë˜ëœ ì„¹í„° ì œê±°
            while len(self._sector_cache) > self.env_cache.get('max_sector_cache_entries', 64):
                try:
                    self._sector_cache.popitem(last=False)
                except Exception:
                    break

        return results
    
    def _analyze_stocks_parallel(self, stocks_data, max_workers: int = None) -> List[AnalysisResult]:
        """ì¢…ëª©ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ëŠ” ê³µí†µ ë©”ì„œë“œ (API TPS ìµœì í™”)"""
        results = []
        if max_workers is None:
            # âœ… ì›Œì»¤ ìˆ˜ ìë™ ì¶”ì • ê°œì„ : TPS, ì½”ì–´ ìˆ˜, ì™¸ë¶€ ë¶„ì„ ì‚¬ìš© ì—¬ë¶€ ê³ ë ¤
            cpu_cores = os.cpu_count() or 1
            max_tps = safe_env_int("KIS_MAX_TPS", 8, 1)
            
            # âœ… MAX_WORKERS=0 ì˜ë¯¸ ë¶ˆì¼ì¹˜ ìˆ˜ì •: 0ì´ë©´ ìë™ ì¶”ì •
            env_mw_raw = os.getenv("MAX_WORKERS", "")
            env_mw = None
            try:
                env_mw = int(env_mw_raw)
            except Exception:
                env_mw = None

            auto_guess = (int(1.5 * max_tps) if self.include_external else int(2.0 * max_tps))
            # I/O ë°”ìš´ë“œ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ ì½”ì–´*4ê¹Œì§€ ì—¬ìœ ë¥¼ ë‘  (í™˜ê²½ì— ë”°ë¼ íŠœë‹ ê°€ëŠ¥)
            auto_cap   = (cpu_cores * 3 if self.include_external else cpu_cores * 4)
            auto_val   = min(auto_guess, auto_cap)

            if env_mw is None or env_mw == 0:
                max_workers = max(1, auto_val)
            else:
                # ì‚¬ìš©ìê°€ ê°•ì œ ì§€ì •í•œ ê²½ìš°, ê³¼ë„í•œ ê°’ì€ ìº¡
                max_workers = max(1, min(env_mw, auto_cap))
        
        # Guard against negative/zero workers
        max_workers = max(1, max_workers or 1)

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ì‘ì—… ì œì¶œ
            futures = []
            for _, stock in stocks_data.iterrows():
                symbol = str(stock['ë‹¨ì¶•ì½”ë“œ'])
                name = stock['í•œê¸€ëª…']
                future = executor.submit(self.analyze_single_stock, symbol, name)
                futures.append((future, symbol, name))

            # ê²°ê³¼ ìˆ˜ì§‘ (as_completed ì‚¬ìš©ìœ¼ë¡œ ì™„ë£Œëœ ì‘ì—…ë¶€í„° ì²˜ë¦¬)
            future_map = {f: (symbol, name) for f, symbol, name in futures}
            for f in as_completed(future_map):
                symbol, name = future_map[f]
                try:
                    result = f.result()
                    if result.status == AnalysisStatus.SUCCESS:
                        results.append(result)
                    elif result.status == AnalysisStatus.SKIPPED_PREF:
                        logging.debug(f"ìš°ì„ ì£¼ ì œì™¸: {name} ({symbol})")
                    else:
                        logging.debug(f"ë¶„ì„ ì‹¤íŒ¨: {name} ({symbol}) - {result.error}")
                except Exception as e:
                    log_error("ì¢…ëª© ë¶„ì„", f"{name}({symbol})", e, LogLevel.ERROR)
                    continue

        # ë¶„ì„ëœ ì¢…ëª© ìˆ˜ ê¸°ë¡
        if hasattr(self, "metrics") and self.metrics:
            self.metrics.record_stocks_analyzed(len(results))
        
        return results

    # -----------------------------
    # ì‹¤í–‰ ìœ í‹¸/ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ ë³´ê°•
    # -----------------------------
    def run_universe(self, limit: int = 100) -> List[AnalysisResult]:
        """
        KOSPI ë§ˆìŠ¤í„°ì—ì„œ ìš°ì„ ì£¼ ì œì™¸ í›„ ì‹œì´ ìƒìœ„ limitê°œë¥¼ ë³‘ë ¬ ë¶„ì„.
        """
        if self.kospi_data is None or self.kospi_data.empty:
            logging.error("KOSPI ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. kospi_code.csv/xlsxë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return []

        df = self.kospi_data.copy()

        # ìš°ì„ ì£¼ ì œì™¸
        if "í•œê¸€ëª…" in df.columns:
            df = df[~df["í•œê¸€ëª…"].astype(str).apply(DataValidator.is_preferred_stock)]

        # ì‹œì´ ì •ë ¬ í›„ ìƒìœ„ limit
        if "ì‹œê°€ì´ì•¡" in df.columns:
            df = df.sort_values("ì‹œê°€ì´ì•¡", ascending=False)
        if limit and limit > 0:
            df = df.head(limit)

        results = self._analyze_stocks_parallel(df)
        
        # íˆ¬ì ë§¤ë ¥ë„(ì¢…í•©ì ìˆ˜) ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x.enhanced_score, reverse=True)
        
        return results

    def export_json(self, results: List[AnalysisResult], path: str) -> None:
        """ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        payload = [self._result_to_dict(r) for r in results]
        with open(path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        logging.info(f"JSON ì €ì¥ ì™„ë£Œ: {path}")

    def export_csv(self, results: List[AnalysisResult], path: str) -> None:
        """ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (ì£¼ìš” í•„ë“œ ì¤‘ì‹¬)"""
        rows = []
        for r in results:
            d = self._result_to_dict(r)
            rows.append({
                "symbol": d.get("symbol"),
                "name": d.get("name"),
                "grade": d.get("enhanced_grade"),
                "score": d.get("enhanced_score"),
                "market_cap_ì–µ": d.get("market_cap"),
                "current_price": d.get("current_price"),
                "price_position": d.get("price_position"),
                "per": d.get("per"),
                "pbr": d.get("pbr"),
                "sector_valuation": d.get("sector_valuation"),
            })
        pd.DataFrame(rows).to_csv(path, index=False, encoding="utf-8-sig")
        logging.info(f"CSV ì €ì¥ ì™„ë£Œ: {path}")
    
    def analyze_full_market_enhanced(self, max_stocks: int = 100, min_score: float = 20.0, 
                                   include_realtime: bool = True, include_external: bool = True,
                                   max_workers: Optional[int] = None) -> Dict[str, Any]:
        """
        í–¥ìƒëœ ì „ì²´ ì‹œì¥ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª©ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ì—¬ ì €í‰ê°€ ì¢…ëª©ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Note: include_realtime, include_external íŒŒë¼ë¯¸í„°ëŠ” ë©”íƒ€ë°ì´í„° í‘œì‹œìš©ì…ë‹ˆë‹¤.
              ì‹¤ì œ ë¡œì§ì€ ì¸ìŠ¤í„´ìŠ¤ í”Œë˜ê·¸(self.include_realtime, self.include_external)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            max_stocks (int): ìµœëŒ€ ë¶„ì„ ì¢…ëª© ìˆ˜ (ê¸°ë³¸ê°’: 100)
            min_score (float): ìµœì†Œ ì ìˆ˜ í•„í„° (ê¸°ë³¸ê°’: 20.0)
            include_realtime (bool): ì‹¤ì‹œê°„ ë°ì´í„° í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            include_external (bool): ì™¸ë¶€ ë°ì´í„° í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            Dict[str, Any]: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
                - metadata: ë¶„ì„ ë©”íƒ€ë°ì´í„°
                - top_recommendations: ìƒìœ„ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
                - sector_analysis: ì—…ì¢…ë³„ ë¶„ì„ ê²°ê³¼
                - market_statistics: ì‹œì¥ í†µê³„
                
        Note:
            ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
            CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì›Œì»¤ ìˆ˜ë¥¼ ìë™ ì¡°ì •í•©ë‹ˆë‹¤.
        """
        try:
            # âœ… ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œ ë¡œê·¸ ì´ˆê¸°í™”
            _setup_logging_if_needed()
            
            start_time = _monotonic()
            
            # KOSPI ë°ì´í„° í™•ì¸
            if self.kospi_data is None or self.kospi_data.empty:
                raise ValueError("KOSPI ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì„ ë³„
            top_stocks = self.kospi_data.nlargest(max_stocks, 'ì‹œê°€ì´ì•¡')
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
            results = self._analyze_stocks_parallel(top_stocks, max_workers=max_workers)
            
            # ê²°ê³¼ ì •ë ¬ ë° í•„í„°ë§
            filtered_results = [
                r for r in results 
                if r.enhanced_score >= min_score
            ]
            filtered_results.sort(key=lambda x: x.enhanced_score, reverse=True)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            analysis_time = _monotonic() - start_time
            metadata = {
                'analysis_version': '2.0_enhanced',
                'analysis_date': datetime.now().isoformat(),
                'analysis_time_seconds': analysis_time,
                'total_analyzed': len(results),
                'total_stocks_analyzed': len(results),
                'undervalued_count': len(filtered_results),
                'features_enabled': {
                    'realtime_data': self.include_realtime,
                    'external_data': self.include_external,
                    'enhanced_scoring': True
                }
            }
            
            return {
                'metadata': metadata,
                'top_recommendations': [self._result_to_dict(r) for r in filtered_results[:20]],
                'sector_analysis': self._analyze_sector_distribution_enhanced(results),
                'market_statistics': self._calculate_enhanced_market_statistics(results)
            }
            
        except Exception as e:
            log_error("ì „ì²´ ì‹œì¥ ë¶„ì„", error=e, level="error")
            return {
                'metadata': {'error': str(e)},
                'top_recommendations': [],
                'sector_analysis': {},
                'market_statistics': {}
            }
        finally:
            try:
                summ = self.metrics.get_summary() if hasattr(self, "metrics") and self.metrics else {}
                # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ ê²¹ì¹¨ ë°©ì§€
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                metrics_filename = f"metrics_summary_{timestamp}.json"
                with open(metrics_filename, "w", encoding="utf-8") as f:
                    json.dump(serialize_for_json(summ), f, ensure_ascii=False, indent=2)
                logging.info(f"ë©”íŠ¸ë¦­ ìš”ì•½ ì €ì¥: {metrics_filename}")
            except Exception as _e:
                logging.warning(f"ë©”íŠ¸ë¦­ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {_e}")
    
    def analyze_top_market_cap_stocks_enhanced(self, count: int = 50, min_score: float = 20.0, 
                                             max_workers: Optional[int] = None) -> Dict[str, Any]:
        """
        ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© í–¥ìƒëœ ë¶„ì„
        
        Note: ì‹¤ì œ ë¡œì§ì€ ì¸ìŠ¤í„´ìŠ¤ í”Œë˜ê·¸(self.include_realtime, self.include_external)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        try:
            start_time = _monotonic()
            
            if self.kospi_data is None or self.kospi_data.empty:
                raise ValueError("KOSPI ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì„ ë³„
            top_stocks = self.kospi_data.nlargest(count, 'ì‹œê°€ì´ì•¡')
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
            results = self._analyze_stocks_parallel(top_stocks, max_workers=max_workers)
            
            # ê²°ê³¼ í•„í„°ë§ ë° ì •ë ¬
            filtered_results = [
                r for r in results 
                if r.enhanced_score >= min_score
            ]
            filtered_results.sort(key=lambda x: x.enhanced_score, reverse=True)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            analysis_time = _monotonic() - start_time
            metadata = {
                'analysis_version': '2.0_enhanced',
                'analysis_date': datetime.now().isoformat(),
                'analysis_time_seconds': analysis_time,
                'total_analyzed': len(results),
                'total_stocks_analyzed': len(results),
                'undervalued_count': len(filtered_results),
                'features_enabled': {
                    'realtime_data': self.include_realtime,
                    'external_data': self.include_external,
                    'enhanced_scoring': True
                }
            }
            
            return {
                'metadata': metadata,
                'top_recommendations': [self._result_to_dict(r) for r in filtered_results[:15]],
                'sector_analysis': self._analyze_sector_distribution_enhanced(results),
                'market_statistics': self._calculate_enhanced_market_statistics(results)
            }
            
        except Exception as e:
            log_error("ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ë¶„ì„", error=e, level="error")
            return {
                'metadata': {'error': str(e)},
                'top_recommendations': [],
                'sector_analysis': {},
                'market_statistics': {}
            }
    
    def _analyze_sector_distribution_enhanced(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """í–¥ìƒëœ ì—…ì¢…ë³„ ë¶„í¬ ë¶„ì„ (ì¤‘ë³µ ì„¹í„°ì¡°íšŒ ì œê±°)"""
        try:
            sector_distribution = {}
            
            # ì‹¬ë³¼â†’ì„¹í„° ë§¤í•‘ì„ í•œ ë²ˆë§Œ êµ¬í•˜ì—¬ ì¤‘ë³µ ì¡°íšŒ ì œê±°
            sector_map = {}
            for result in results:
                sym = result.symbol
                if sym not in sector_map:
                    sector_map[sym] = self._get_sector_characteristics(sym).get('name', 'ê¸°íƒ€')
                sector = sector_map[sym]
                
                if sector not in sector_distribution:
                    sector_distribution[sector] = {
                        'count': 0,
                        'total_score': 0,
                        'avg_score': 0,
                        'recommendations': {'BUY': 0, 'HOLD': 0, 'SELL': 0}
                    }
                
                sector_distribution[sector]['count'] += 1
                sector_distribution[sector]['total_score'] += result.enhanced_score
                
                # íˆ¬ì ì¶”ì²œ ë¶„í¬ (ì•ˆì „ ì ‘ê·¼)
                recommendation = DataValidator._getattr_or_get(result, 'investment_recommendation', 'HOLD')
                if recommendation in sector_distribution[sector]['recommendations']:
                    sector_distribution[sector]['recommendations'][recommendation] += 1
            
            # í‰ê·  ì ìˆ˜ ê³„ì‚°
            for sector in sector_distribution:
                if sector_distribution[sector]['count'] > 0:
                    sector_distribution[sector]['avg_score'] = (
                        sector_distribution[sector]['total_score'] / sector_distribution[sector]['count']
                    )
            
            return sector_distribution
            
        except Exception as e:
            log_error("ì—…ì¢…ë³„ ë¶„í¬ ë¶„ì„", error=e, level="error")
            return {}
    
    def _calculate_enhanced_market_statistics(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """í–¥ìƒëœ ì‹œì¥ í†µê³„ ê³„ì‚°"""
        try:
            if not results:
                return {}
            
            scores = [r.enhanced_score for r in results if r.enhanced_score > 0]
            market_caps = [r.market_cap for r in results if r.market_cap > 0]
            
            if not scores:
                return {}
            
            return {
                'total_analyzed': len(results),
                'avg_score': sum(scores) / len(scores),
                'max_score': max(scores),
                'min_score': min(scores),
                'score_distribution': {
                    'A+': len([s for s in scores if s >= 80]),
                    'A': len([s for s in scores if 70 <= s < 80]),
                    'B+': len([s for s in scores if 60 <= s < 70]),
                    'B': len([s for s in scores if 50 <= s < 60]),
                    'C': len([s for s in scores if 40 <= s < 50]),
                    'D': len([s for s in scores if 20 <= s < 40]),
                    'F': len([s for s in scores if s < 20])
                },
                'market_cap_stats': {
                    'total_market_cap': sum(market_caps),
                    'avg_market_cap': sum(market_caps) / len(market_caps) if market_caps else 0,
                    'max_market_cap': max(market_caps) if market_caps else 0,
                    'min_market_cap': min(market_caps) if market_caps else 0
                }
            }
            
        except Exception as e:
            log_error("ì‹œì¥ í†µê³„ ê³„ì‚°", error=e, level="error")
            return {}
    
    def _display_enhanced_results_table(self, results: Dict[str, Any]):
        """í–¥ìƒëœ ë¶„ì„ ê²°ê³¼ë¥¼ í‘œ í˜•íƒœë¡œ ì¶œë ¥"""
        try:
            metadata = results.get('metadata', {})
            print(f"\nğŸš€ í–¥ìƒëœ í†µí•© ë¶„ì„ ê²°ê³¼ v{metadata.get('analysis_version', '2.0_enhanced')}")
            print(f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {metadata.get('analysis_date', 'Unknown')}")
            print(f"â±ï¸ ë¶„ì„ ì‹œê°„: {metadata.get('analysis_time_seconds', 0):.1f}ì´ˆ")
            total = metadata.get('total_analyzed', metadata.get('total_stocks_analyzed', 0))
            print(f"ğŸ“Š ì´ ë¶„ì„ ì¢…ëª©: {total}ê°œ")
            print(f"ğŸ¯ ì¶”ì²œ ì¢…ëª©: {metadata.get('undervalued_count', 0)}ê°œ")
            
            # ìƒìœ„ ì¶”ì²œ ì¢…ëª© í‘œ
            top_recommendations = results.get('top_recommendations', [])
            if top_recommendations:
                print("\nğŸ† í–¥ìƒëœ ì¢…ëª© ì¶”ì²œ ê²°ê³¼")
                print("=" * 100)
                print(f"{'ìˆœìœ„':<4} {'ì¢…ëª©ì½”ë“œ':<8} {'ì¢…ëª©ëª…':<15} {'í˜„ì¬ê°€':<10} {'52ì£¼ìœ„ì¹˜':<8} {'ì¢…í•©ì ìˆ˜':<8} {'ë“±ê¸‰':<6} {'ì‹œê°€ì´ì•¡':<12}")
                print("-" * 100)
                
                for i, stock in enumerate(top_recommendations[:10], 1):
                    # stockì´ ë”•ì…”ë„ˆë¦¬ì¸ì§€ ê°ì²´ì¸ì§€ í™•ì¸
                    if isinstance(stock, dict):
                        symbol = stock.get('symbol', 'N/A')
                        name = stock.get('name', 'N/A')
                        enhanced_score = stock.get('enhanced_score', 0)
                        market_cap = stock.get('market_cap', 0)
                        current_price = stock.get('current_price', 0)
                        grade = stock.get('enhanced_grade', 'F')
                        w52_high = stock.get('w52_high', 0)
                        w52_low = stock.get('w52_low', 0)
                    else:
                        symbol = getattr(stock, 'symbol', 'N/A')
                        name = getattr(stock, 'name', 'N/A')
                        enhanced_score = getattr(stock, 'enhanced_score', 0)
                        market_cap = getattr(stock, 'market_cap', 0)
                        current_price = getattr(stock, 'current_price', 0)
                        grade = getattr(stock, 'enhanced_grade', 'F')
                        w52_high = getattr(stock, 'w52_high', 0)
                        w52_low = getattr(stock, 'w52_low', 0)
                    
                    # í˜„ì¬ê°€ í‘œì‹œ
                    current_price_display = f"{current_price:,.0f}ì›" if current_price is not None else "N/A"
                    
                    # 52ì£¼ ìœ„ì¹˜ ê³„ì‚° ë° í‘œì‹œ
                    if current_price and w52_high and w52_low and w52_high > w52_low:
                        position = ((current_price - w52_low) / (w52_high - w52_low)) * 100
                        position_display = f"{position:.0f}%"
                    else:
                        position_display = "N/A"
                    
                    # ì‹œê°€ì´ì•¡ í‘œì‹œ
                    market_cap_display = f"{market_cap:,.0f}ì–µ" if market_cap else "N/A"
                    
                    # ì¢…ëª©ëª… ê¸¸ì´ ì œí•œ
                    name_display = name[:12] + ('...' if len(name) > 12 else '')
                    
                    print(f"{i:<4} {symbol:<8} {name_display:<15} {current_price_display:<10} {position_display:<8} {enhanced_score:<8.1f} {grade:<6} {market_cap_display:<12}")
                
                print("=" * 100)
            
            # ì—…ì¢…ë³„ ë¶„ì„ ê²°ê³¼
            sector_analysis = results.get('sector_analysis', {})
            if sector_analysis:
                print(f"\nğŸ“Š ì—…ì¢…ë³„ ë¶„ì„ ê²°ê³¼")
                for sector, data in sector_analysis.items():
                    print(f"  {sector}: {data['count']}ê°œ ì¢…ëª©, í‰ê· ì ìˆ˜ {data['avg_score']:.1f}")
            
            # ì‹œì¥ í†µê³„
            market_stats = results.get('market_statistics', {})
            if market_stats:
                print(f"\nğŸ“ˆ ì‹œì¥ í†µê³„")
                print(f"  í‰ê·  ì ìˆ˜: {market_stats.get('avg_score', 0):.1f}")
                print(f"  ìµœê³  ì ìˆ˜: {market_stats.get('max_score', 0):.1f}")
                print(f"  ìµœì € ì ìˆ˜: {market_stats.get('min_score', 0):.1f}")
                
                score_dist = market_stats.get('score_distribution', {})
                if score_dist:
                    print(f"  ì ìˆ˜ ë¶„í¬: A+({score_dist.get('A+', 0)}) A({score_dist.get('A', 0)}) B+({score_dist.get('B+', 0)}) B({score_dist.get('B', 0)})")
            
        except Exception as e:
            log_error("ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥", error=e, level="error")
            pass

# =============================================================================
# 6. CLI ì¸í„°í˜ì´ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼)
# =============================================================================

# Typer CLI ì•± ìƒì„±
app = typer.Typer(help="Enhanced Integrated Analyzer")

@app.command()
def test_enhanced_analysis(
    count: int = typer.Option(15, help="ë¶„ì„í•  ì¢…ëª© ìˆ˜"),
    min_score: float = typer.Option(20.0, help="ìµœì†Œ ì ìˆ˜"),
    max_workers: int = typer.Option(safe_env_int("MAX_WORKERS", 0, min_val=None), help="ì›Œì»¤ ìˆ˜(0=ìë™)"),
    realtime: bool = typer.Option(True, help="ì‹¤ì‹œê°„ ë°ì´í„° í¬í•¨"),
    external: bool = typer.Option(True, help="ì™¸ë¶€ ë¶„ì„ í¬í•¨(ì˜ê²¬/ì¶”ì •)"),
):
    """
    ê°„ë‹¨ ì‹¤í–‰: ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª©ì„ ë¶„ì„í•˜ì—¬ í‘œ ì¶œë ¥
    """
    # âœ… ë¡œê¹… ë¶€íŠ¸ìŠ¤íŠ¸ë© í˜¸ì¶œ
    _setup_logging_if_needed()
    
    analyzer = EnhancedIntegratedAnalyzer(include_realtime=realtime, include_external=external)
    
    # âœ… ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • (ë©”íŠ¸ë¦­ ë¤í”„ìš©)
    global _global_analyzer_instance
    _global_analyzer_instance = analyzer
    
    results = analyzer.analyze_top_market_cap_stocks_enhanced(
        count=count,
        min_score=min_score,
        max_workers=(None if max_workers == 0 else max_workers),
    )
    analyzer._display_enhanced_results_table(results)

@app.command()
def full_market(
    max_stocks: int = typer.Option(100, help="ì‹œì´ ìƒìœ„ Nê°œ ë¶„ì„"),
    min_score: float = typer.Option(20.0, help="ìµœì†Œ ì ìˆ˜"),
    max_workers: int = typer.Option(safe_env_int("MAX_WORKERS", 0, min_val=None), help="ì›Œì»¤ ìˆ˜(0=ìë™)"),
    realtime: bool = typer.Option(True, help="ì‹¤ì‹œê°„ ë°ì´í„° í¬í•¨"),
    external: bool = typer.Option(True, help="ì™¸ë¶€ ë¶„ì„ í¬í•¨(ì˜ê²¬/ì¶”ì •)"),
):
    """
    ì „ì²´ ì‹œì¥(ì‹œì´ ìƒìœ„ max_stocks) ë¶„ì„ ì‹¤í–‰
    """
    # âœ… ë¡œê¹… ë¶€íŠ¸ìŠ¤íŠ¸ë© í˜¸ì¶œ
    _setup_logging_if_needed()
    
    analyzer = EnhancedIntegratedAnalyzer(include_realtime=realtime, include_external=external)
    
    # âœ… ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • (ë©”íŠ¸ë¦­ ë¤í”„ìš©)
    global _global_analyzer_instance
    _global_analyzer_instance = analyzer
    
    results = analyzer.analyze_full_market_enhanced(
        max_stocks=max_stocks,
        min_score=min_score,
        include_realtime=realtime,
        include_external=external,
        max_workers=(None if max_workers == 0 else max_workers),
    )
    analyzer._display_enhanced_results_table(results)

@app.command()
def analyze(
    symbol: str,
    name: str = "",
    days_back: int = 30,
    realtime: bool = True,
    external: bool = True,
):
    """ë‹¨ì¼ ì¢…ëª© ë¶„ì„"""
    # âœ… ë¡œê¹… ë¶€íŠ¸ìŠ¤íŠ¸ë© í˜¸ì¶œ
    _setup_logging_if_needed()
    
    ai = EnhancedIntegratedAnalyzer(include_realtime=realtime, include_external=external)
    
    # âœ… ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • (ë©”íŠ¸ë¦­ ë¤í”„ìš©)
    global _global_analyzer_instance
    _global_analyzer_instance = ai
    
    try:
        res = ai.analyze_single_stock(symbol, name, days_back)
        # JSON ì¶œë ¥ (CLI ì¹œí™”ì )
        import json
        result_dict = ai._result_to_dict(res)
        typer.echo(json.dumps(result_dict, ensure_ascii=False, indent=2))
    except Exception as e:
        typer.echo(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}", err=True)

@app.command()
def scan(
    max_stocks: int = 100,
    min_score: float = 20.0,
    realtime: bool = True,
    external: bool = True,
):
    """ê°„ë‹¨í•œ ì „ì²´ ì‹œì¥ ìŠ¤ìº”"""
    a = EnhancedIntegratedAnalyzer(include_realtime=realtime, include_external=external)
    
    # âœ… ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • (ë©”íŠ¸ë¦­ ë¤í”„ìš©)
    global _global_analyzer_instance
    _global_analyzer_instance = a
    
    res = a.analyze_full_market_enhanced(max_stocks=max_stocks, min_score=min_score)
    a._display_enhanced_results_table(res)

@app.command(help="KOSPI ì‹œì´ ìƒìœ„ Nê°œ ì¢…ëª©ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
def run(
    limit: int = typer.Option(50, help="ë¶„ì„í•  ì‹œì´ ìƒìœ„ ì¢…ëª© ìˆ˜"),
    config: str = typer.Option("config.yaml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"),
    include_realtime: bool = typer.Option(True, help="ì‹¤ì‹œê°„/ì¶”ê°€ ê°€ê²© ì •ë³´ í¬í•¨"),
    include_external: bool = typer.Option(True, help="ì™¸ë¶€(ì˜ê²¬/ì¶”ì •) ë¶„ì„ í¬í•¨"),
    out_json: str = typer.Option("results.json", help="JSON ê²°ê³¼ íŒŒì¼"),
    out_csv: str = typer.Option("results.csv", help="CSV ê²°ê³¼ íŒŒì¼"),
    log_level: str = typer.Option(os.getenv("LOG_LEVEL", "INFO"), help="ë¡œê·¸ ë ˆë²¨ (DEBUG/INFO/WARN/ERROR)"),
):
    """KOSPI ì‹œì´ ìƒìœ„ Nê°œ ì¢…ëª©ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    _setup_logging_if_needed()
    logging.getLogger().setLevel(getattr(logging, log_level.upper(), logging.INFO))

    analyzer = EnhancedIntegratedAnalyzer(
        include_realtime=include_realtime,
        include_external=include_external,
    )

    # âœ… ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • (ë©”íŠ¸ë¦­ ë¤í”„ìš©)
    global _global_analyzer_instance
    _global_analyzer_instance = analyzer

    start = _monotonic()
    results = analyzer.run_universe(limit=limit)
    elapsed = _monotonic() - start

    # ì €ì¥
    analyzer.export_json(results, out_json)
    analyzer.export_csv(results, out_csv)

    # ê²°ê³¼ í‘œ ì¶œë ¥ (Rich í…Œì´ë¸”)
    if results:
        console = Console()
        console.print(f"\nğŸš€ [bold blue]ì¢…ëª© ë¶„ì„ ê²°ê³¼ (ìƒìœ„ {len(results)}ê°œ)[/bold blue]")
        
        # Rich í…Œì´ë¸” ìƒì„±
        table = Table(title="ğŸ† ì¢…ëª© ë¶„ì„ ê²°ê³¼", box=ROUNDED)
        
        # ì»¬ëŸ¼ ì¶”ê°€
        table.add_column("ìˆœìœ„", style="cyan", width=4, justify="center")
        table.add_column("ì¢…ëª©ì½”ë“œ", style="magenta", width=8)
        table.add_column("ì¢…ëª©ëª…", style="green", width=15)
        table.add_column("í˜„ì¬ê°€", style="white", width=12)
        table.add_column("52ì£¼ìœ„ì¹˜", style="bright_magenta", width=8, justify="center")
        table.add_column("ì¢…í•©ì ìˆ˜", style="yellow", width=8, justify="center")
        table.add_column("ë“±ê¸‰", style="red", width=6, justify="center")
        table.add_column("ì‹œê°€ì´ì•¡", style="blue", width=12)
        
        for i, result in enumerate(results[:10], 1):
            # í˜„ì¬ê°€ í‘œì‹œ
            current_price_display = f"{result.current_price:,.0f}ì›" if result.current_price else "N/A"
            
            # 52ì£¼ ìœ„ì¹˜ í‘œì‹œ (ìƒ‰ìƒ ì½”ë”©)
            if result.price_position is not None:
                if result.price_position >= 90:
                    position_display = f"[red]{result.price_position:.0f}%[/red]"
                elif result.price_position >= 70:
                    position_display = f"[yellow]{result.price_position:.0f}%[/yellow]"
                elif result.price_position <= 30:
                    position_display = f"[green]{result.price_position:.0f}%[/green]"
                else:
                    position_display = f"{result.price_position:.0f}%"
            else:
                position_display = "N/A"
            
            # ì‹œê°€ì´ì•¡ í‘œì‹œ
            market_cap_display = f"{result.market_cap:,.0f}ì–µ" if result.market_cap else "N/A"
            
            # ì¢…ëª©ëª… ê¸¸ì´ ì œí•œ
            name_display = result.name[:12] + ('...' if len(result.name) > 12 else '')
            
            # ë“±ê¸‰ ìƒ‰ìƒ ì½”ë”©
            if result.enhanced_grade in ['A+', 'A']:
                grade_display = f"[green]{result.enhanced_grade}[/green]"
            elif result.enhanced_grade in ['B+', 'B']:
                grade_display = f"[yellow]{result.enhanced_grade}[/yellow]"
            else:
                grade_display = f"[red]{result.enhanced_grade}[/red]"
            
            # í–‰ ì¶”ê°€
            table.add_row(
                str(i),
                result.symbol,
                name_display,
                current_price_display,
                position_display,
                f"{result.enhanced_score:.1f}",
                grade_display,
                market_cap_display
            )
        
        console.print(table)
        
        # ìš”ì•½ í†µê³„
        if len(results) > 1:
            avg_score = sum(r.enhanced_score for r in results) / len(results)
            max_score = max(r.enhanced_score for r in results)
            min_score = min(r.enhanced_score for r in results)
            console.print(f"\nğŸ“ˆ [bold green]ë¶„ì„ ìš”ì•½:[/bold green]")
            console.print(f"â€¢ ì´ ë¶„ì„ ì¢…ëª©: {len(results)}ê°œ")
            console.print(f"â€¢ í‰ê·  ì ìˆ˜: {avg_score:.1f}ì ")
            console.print(f"â€¢ ìµœê³  ì ìˆ˜: {max_score:.1f}ì ")
            console.print(f"â€¢ ìµœì € ì ìˆ˜: {min_score:.1f}ì ")

    # ë©”íŠ¸ë¦­ ìš”ì•½ ì¶œë ¥
    summary = analyzer.metrics.get_summary()
    logging.info(f"ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ, {elapsed:.2f}s")
    logging.info(f"API ì„±ê³µë¥ : {summary['api_success_rate']:.1f}% / ê°€ê²© ìºì‹œ íˆíŠ¸: {summary['cache_hit_rates']['price']:.1f}%")

# =============================================================================
# Graceful Shutdown & Metrics Dump
# =============================================================================

_global_analyzer_instance = None

def _dump_metrics_on_exit():
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ë©”íŠ¸ë¦­ ë¤í”„ (ê°„ì†Œí™”)"""
    try:
        if _global_analyzer_instance and getattr(_global_analyzer_instance, "metrics", None):
            m = _global_analyzer_instance.metrics.get_summary()
            logging.info(
                "[METRICS] api_succ_rate=%.1f%% price_hit=%.1f%% fin_hit=%.1f%% sector_hit=%.1f%% "
                "avg_analysis=%.2fs avg_sector=%.2fs errors=%s",
                m.get('api_success_rate', 0.0),
                m['cache_hit_rates'].get('price', 0.0),
                m['cache_hit_rates'].get('financial', 0.0),
                m['cache_hit_rates'].get('sector', 0.0),
                m.get('avg_analysis_duration', 0.0),
                m.get('avg_sector_evaluation', 0.0),
                m.get('errors_by_type', {})
            )
    except Exception:
        pass

# ì „ì—­ ë©”íŠ¸ë¦­ ë¤í”„ í›… ë“±ë¡
atexit.register(_dump_metrics_on_exit)

def _install_signals():
    """ê¹”ë”í•œ ì¢…ë£Œ(ë©”íŠ¸ë¦­ ì§‘ê³„ í›„)ë¥¼ ìœ„í•œ ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ì„¤ì¹˜"""
    def _graceful_exit(signum, frame):
        logging.info("ì‹ í˜¸ ìˆ˜ì‹ : ì¢…ë£Œí•©ë‹ˆë‹¤.")
        raise SystemExit(0)
    try:
        signal.signal(signal.SIGINT, _graceful_exit)
        signal.signal(signal.SIGTERM, _graceful_exit)
    except Exception:
        pass

def show_help():
    """ë„ì›€ë§ í‘œì‹œ"""
    print("""
ğŸš€ í–¥ìƒëœ í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ v2.0

ì‚¬ìš©ë²•:
  python enhanced_integrated_analyzer_refactored.py [ì˜µì…˜]

ì˜µì…˜:
  --help, -h           ì´ ë„ì›€ë§ í‘œì‹œ
  --count N            ë¶„ì„í•  ì¢…ëª© ìˆ˜ (ê¸°ë³¸ê°’: 10)
  --min-score N        ìµœì†Œ ì ìˆ˜ í•„í„° (ê¸°ë³¸ê°’: 15.0)
  --max-workers N      ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 0=ìë™)
  --no-external        ì™¸ë¶€ ë°ì´í„°(íˆ¬ìì˜ê²¬/ì¶”ì •ì‹¤ì ) ë¹„í™œì„±í™”
  --no-realtime        ì‹¤ì‹œê°„ ë°ì´í„°(ê°€ê²©/52ì£¼) ë¹„í™œì„±í™”
  --dump PATH          ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

ì˜ˆì‹œ:
  python enhanced_integrated_analyzer_refactored.py --count 20 --min-score 25
  python enhanced_integrated_analyzer_refactored.py --no-external --dump results.json
  python enhanced_integrated_analyzer_refactored.py --count 5 --min-score 30 --max-workers 4
    """)

def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    import sys
    
    # ê¸°ë³¸ê°’
    count = 10
    min_score = 15.0
    max_workers = 0
    include_external = True
    include_realtime = True
    dump_path = None
    
    i = 1
    while i < len(sys.argv):
        arg = sys.argv[i]
        
        if arg in ['--help', '-h', 'help']:
            show_help()
            sys.exit(0)
        elif arg == '--count' and i + 1 < len(sys.argv):
            count = int(sys.argv[i + 1])
            i += 2
        elif arg == '--min-score' and i + 1 < len(sys.argv):
            min_score = float(sys.argv[i + 1])
            i += 2
        elif arg == '--max-workers' and i + 1 < len(sys.argv):
            max_workers = int(sys.argv[i + 1])
            i += 2
        elif arg == '--no-external':
            include_external = False
            i += 1
        elif arg == '--no-realtime':
            include_realtime = False
            i += 1
        elif arg == '--dump' and i + 1 < len(sys.argv):
            dump_path = sys.argv[i + 1]
            i += 2
        else:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: {arg}")
            print("ğŸ’¡ --helpë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ì„¸ìš”.")
            sys.exit(1)
    
    return {
        'count': count,
        'min_score': min_score,
        'max_workers': max_workers if max_workers > 0 else None,
        'include_external': include_external,
        'include_realtime': include_realtime,
        'dump_path': dump_path
    }

if __name__ == "__main__":
    # âœ… ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ì—ì„œ ë¡œê¹… ë¶€íŠ¸ìŠ¤íŠ¸ë© í˜¸ì¶œ
    _setup_logging_if_needed()
    try:
        app()
    except KeyboardInterrupt:
        logging.warning("ì‚¬ìš©ì ì¤‘ë‹¨(CTRL+C)")
