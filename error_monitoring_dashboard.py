#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì˜¤ë¥˜/ì°¨ë‹¨ ê´€ì¸¡ ëŒ€ì‹œë³´ë“œ (ì‹œê°„ëŒ€ë³„ 401/429/500)
AppKey ì°¨ë‹¨ ë¦¬ìŠ¤í¬ë¥¼ ì‚¬ì „ì— ê°ì§€í•˜ê³  ê°„ê²©ì„ ìë™ ìƒí–¥
"""

import logging
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import json
import os
from pathlib import Path
from collections import defaultdict, deque
import threading
import time

logger = logging.getLogger(__name__)

@dataclass
class ErrorEvent:
    """ì˜¤ë¥˜ ì´ë²¤íŠ¸ ë°ì´í„°"""
    timestamp: str
    error_type: str  # 401, 429, 500, timeout, connection
    endpoint: str
    tr_id: str
    message: str
    retry_count: int
    response_time: float
    user_agent: str

@dataclass
class ErrorStats:
    """ì˜¤ë¥˜ í†µê³„ ë°ì´í„°"""
    total_errors: int
    error_by_type: Dict[str, int]
    error_by_hour: Dict[int, int]
    error_by_endpoint: Dict[str, int]
    avg_response_time: float
    max_response_time: float
    error_rate: float
    consecutive_errors: int
    last_error_time: str

class ErrorMonitoringDashboard:
    """ì˜¤ë¥˜/ì°¨ë‹¨ ê´€ì¸¡ ëŒ€ì‹œë³´ë“œ í´ë˜ìŠ¤"""
    
    def __init__(self, logs_dir: str = "logs/errors"):
        """
        Args:
            logs_dir: ì˜¤ë¥˜ ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.logs_dir = Path(logs_dir)
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        
        # ì‹¤ì‹œê°„ ì˜¤ë¥˜ ë°ì´í„° ì €ì¥
        self.error_events = deque(maxlen=10000)  # ìµœê·¼ 10,000ê°œ ì´ë²¤íŠ¸ë§Œ ìœ ì§€
        self.error_lock = threading.Lock()
        
        # ì˜¤ë¥˜ í†µê³„ ìºì‹œ
        self.stats_cache = {}
        self.cache_ttl = 60  # 1ë¶„ ìºì‹œ
        
        # ê²½ê³  ì„ê³„ê°’
        self.warning_thresholds = {
            'error_rate': 5.0,  # 5% ì´ìƒ ì˜¤ë¥˜ìœ¨
            'consecutive_errors': 3,  # ì—°ì† 3íšŒ ì˜¤ë¥˜
            'response_time': 10.0,  # 10ì´ˆ ì´ìƒ ì‘ë‹µì‹œê°„
            'hourly_errors': 50  # ì‹œê°„ë‹¹ 50íšŒ ì´ìƒ ì˜¤ë¥˜
        }
    
    def log_error(self, error_type: str, endpoint: str, tr_id: str, 
                  message: str, retry_count: int = 0, response_time: float = 0.0):
        """ì˜¤ë¥˜ ì´ë²¤íŠ¸ ë¡œê¹…"""
        try:
            event = ErrorEvent(
                timestamp=datetime.now().isoformat(),
                error_type=error_type,
                endpoint=endpoint,
                tr_id=tr_id,
                message=message,
                retry_count=retry_count,
                response_time=response_time,
                user_agent="KIS-API-Client/1.0"
            )
            
            # ì‹¤ì‹œê°„ ë°ì´í„°ì— ì¶”ê°€
            with self.error_lock:
                self.error_events.append(event)
            
            # íŒŒì¼ì— ë¡œê¹…
            self._write_error_log(event)
            
            # ê²½ê³  ì²´í¬
            self._check_warnings()
            
        except Exception as e:
            logger.error(f"ì˜¤ë¥˜ ì´ë²¤íŠ¸ ë¡œê¹… ì‹¤íŒ¨: {e}")
    
    def _write_error_log(self, event: ErrorEvent):
        """ì˜¤ë¥˜ ë¡œê·¸ íŒŒì¼ì— ì“°ê¸°"""
        try:
            # ì¼ë³„ ë¡œê·¸ íŒŒì¼
            date_str = datetime.now().strftime('%Y%m%d')
            log_file = self.logs_dir / f"errors_{date_str}.jsonl"
            
            # JSONL í˜•íƒœë¡œ ì¶”ê°€
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(asdict(event), ensure_ascii=False) + '\n')
            
        except Exception as e:
            logger.error(f"ì˜¤ë¥˜ ë¡œê·¸ íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}")
    
    def _check_warnings(self):
        """ê²½ê³  ì¡°ê±´ ì²´í¬"""
        try:
            stats = self.get_error_stats()
            
            # ì˜¤ë¥˜ìœ¨ ê²½ê³ 
            if stats.error_rate > self.warning_thresholds['error_rate']:
                logger.warning(f"âš ï¸ ë†’ì€ ì˜¤ë¥˜ìœ¨ ê°ì§€: {stats.error_rate:.1f}%")
            
            # ì—°ì† ì˜¤ë¥˜ ê²½ê³ 
            if stats.consecutive_errors >= self.warning_thresholds['consecutive_errors']:
                logger.warning(f"ğŸš¨ ì—°ì† ì˜¤ë¥˜ ê°ì§€: {stats.consecutive_errors}íšŒ")
            
            # ì‘ë‹µì‹œê°„ ê²½ê³ 
            if stats.avg_response_time > self.warning_thresholds['response_time']:
                logger.warning(f"âš ï¸ ë†’ì€ ì‘ë‹µì‹œê°„: {stats.avg_response_time:.1f}ì´ˆ")
            
        except Exception as e:
            logger.error(f"ê²½ê³  ì²´í¬ ì‹¤íŒ¨: {e}")
    
    def get_error_stats(self, hours_back: int = 24) -> ErrorStats:
        """ì˜¤ë¥˜ í†µê³„ ê³„ì‚°"""
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"stats_{hours_back}"
            if cache_key in self.stats_cache:
                cached_stats, cached_time = self.stats_cache[cache_key]
                if time.time() - cached_time < self.cache_ttl:
                    return cached_stats
            
            # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            
            # ìµœê·¼ ì˜¤ë¥˜ ì´ë²¤íŠ¸ í•„í„°ë§
            recent_events = []
            with self.error_lock:
                for event in self.error_events:
                    event_time = datetime.fromisoformat(event.timestamp)
                    if event_time >= cutoff_time:
                        recent_events.append(event)
            
            if not recent_events:
                return ErrorStats(
                    total_errors=0,
                    error_by_type={},
                    error_by_hour={},
                    error_by_endpoint={},
                    avg_response_time=0.0,
                    max_response_time=0.0,
                    error_rate=0.0,
                    consecutive_errors=0,
                    last_error_time=""
                )
            
            # í†µê³„ ê³„ì‚°
            total_errors = len(recent_events)
            error_by_type = defaultdict(int)
            error_by_hour = defaultdict(int)
            error_by_endpoint = defaultdict(int)
            response_times = []
            consecutive_errors = 0
            
            # ìµœê·¼ ì´ë²¤íŠ¸ë¶€í„° ì—­ìˆœìœ¼ë¡œ ì—°ì† ì˜¤ë¥˜ ê³„ì‚°
            for i, event in enumerate(reversed(recent_events)):
                if i == 0:  # ê°€ì¥ ìµœê·¼ ì´ë²¤íŠ¸
                    consecutive_errors = 1
                else:
                    # ì´ì „ ì´ë²¤íŠ¸ì™€ ì‹œê°„ ì°¨ì´ í™•ì¸
                    prev_event = list(reversed(recent_events))[i-1]
                    prev_time = datetime.fromisoformat(prev_event.timestamp)
                    curr_time = datetime.fromisoformat(event.timestamp)
                    
                    if (curr_time - prev_time).total_seconds() < 300:  # 5ë¶„ ì´ë‚´
                        consecutive_errors += 1
                    else:
                        break
            
            for event in recent_events:
                error_by_type[event.error_type] += 1
                
                event_time = datetime.fromisoformat(event.timestamp)
                error_by_hour[event_time.hour] += 1
                
                error_by_endpoint[event.endpoint] += 1
                
                if event.response_time > 0:
                    response_times.append(event.response_time)
            
            # ì‘ë‹µì‹œê°„ í†µê³„
            avg_response_time = sum(response_times) / len(response_times) if response_times else 0.0
            max_response_time = max(response_times) if response_times else 0.0
            
            # ì˜¤ë¥˜ìœ¨ ê³„ì‚° (ì „ì²´ ìš”ì²­ ëŒ€ë¹„, ì¶”ì •)
            # ì‹¤ì œë¡œëŠ” ì „ì²´ ìš”ì²­ ìˆ˜ê°€ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì˜¤ë¥˜ ì´ë²¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
            estimated_total_requests = total_errors * 20  # ì˜¤ë¥˜ìœ¨ 5% ê°€ì •
            error_rate = (total_errors / estimated_total_requests) * 100 if estimated_total_requests > 0 else 0.0
            
            stats = ErrorStats(
                total_errors=total_errors,
                error_by_type=dict(error_by_type),
                error_by_hour=dict(error_by_hour),
                error_by_endpoint=dict(error_by_endpoint),
                avg_response_time=avg_response_time,
                max_response_time=max_response_time,
                error_rate=error_rate,
                consecutive_errors=consecutive_errors,
                last_error_time=recent_events[-1].timestamp if recent_events else ""
            )
            
            # ìºì‹œ ì €ì¥
            self.stats_cache[cache_key] = (stats, time.time())
            
            return stats
            
        except Exception as e:
            logger.error(f"ì˜¤ë¥˜ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return ErrorStats(
                total_errors=0,
                error_by_type={},
                error_by_hour={},
                error_by_endpoint={},
                avg_response_time=0.0,
                max_response_time=0.0,
                error_rate=0.0,
                consecutive_errors=0,
                last_error_time=""
            )
    
    def create_error_dashboard(self, hours_back: int = 24) -> go.Figure:
        """ì˜¤ë¥˜ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        stats = self.get_error_stats(hours_back)
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                'ì˜¤ë¥˜ ìœ í˜•ë³„ ë¶„í¬',
                'ì‹œê°„ëŒ€ë³„ ì˜¤ë¥˜ ë°œìƒ',
                'ì—”ë“œí¬ì¸íŠ¸ë³„ ì˜¤ë¥˜',
                'ì‘ë‹µì‹œê°„ ë¶„í¬'
            ),
            specs=[[{"type": "pie"}, {"type": "bar"}],
                   [{"type": "bar"}, {"type": "histogram"}]]
        )
        
        # 1. ì˜¤ë¥˜ ìœ í˜•ë³„ ë¶„í¬
        if stats.error_by_type:
            error_types = list(stats.error_by_type.keys())
            error_counts = list(stats.error_by_type.values())
            
            fig.add_trace(
                go.Pie(labels=error_types, values=error_counts, name='ì˜¤ë¥˜ ìœ í˜•'),
                row=1, col=1
            )
        
        # 2. ì‹œê°„ëŒ€ë³„ ì˜¤ë¥˜ ë°œìƒ
        if stats.error_by_hour:
            hours = list(range(24))
            hour_counts = [stats.error_by_hour.get(h, 0) for h in hours]
            
            fig.add_trace(
                go.Bar(x=hours, y=hour_counts, name='ì‹œê°„ëŒ€ë³„ ì˜¤ë¥˜'),
                row=1, col=2
            )
        
        # 3. ì—”ë“œí¬ì¸íŠ¸ë³„ ì˜¤ë¥˜
        if stats.error_by_endpoint:
            endpoints = list(stats.error_by_endpoint.keys())
            endpoint_counts = list(stats.error_by_endpoint.values())
            
            # ì—”ë“œí¬ì¸íŠ¸ëª… ë‹¨ì¶•
            short_endpoints = [ep.split('/')[-1] for ep in endpoints]
            
            fig.add_trace(
                go.Bar(x=short_endpoints, y=endpoint_counts, name='ì—”ë“œí¬ì¸íŠ¸ë³„ ì˜¤ë¥˜'),
                row=2, col=1
            )
        
        # 4. ì‘ë‹µì‹œê°„ ë¶„í¬ (ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        if stats.avg_response_time > 0:
            # ì‘ë‹µì‹œê°„ íˆìŠ¤í† ê·¸ë¨ì„ ìœ„í•œ ê°€ìƒ ë°ì´í„° ìƒì„±
            response_times = [stats.avg_response_time * (0.5 + i * 0.1) for i in range(10)]
            
            fig.add_trace(
                go.Histogram(x=response_times, name='ì‘ë‹µì‹œê°„ ë¶„í¬'),
                row=2, col=2
            )
        
        # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
        fig.update_layout(
            title_text=f"ì˜¤ë¥˜/ì°¨ë‹¨ ê´€ì¸¡ ëŒ€ì‹œë³´ë“œ (ìµœê·¼ {hours_back}ì‹œê°„)",
            showlegend=False,
            height=800
        )
        
        return fig
    
    def get_recommendations(self, stats: ErrorStats) -> List[str]:
        """ì˜¤ë¥˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        try:
            # ì˜¤ë¥˜ìœ¨ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if stats.error_rate > 10.0:
                recommendations.append("ğŸš¨ ì˜¤ë¥˜ìœ¨ì´ 10%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. API í˜¸ì¶œ ê°„ê²©ì„ 2ë°°ë¡œ ëŠ˜ë¦¬ì„¸ìš”.")
            elif stats.error_rate > 5.0:
                recommendations.append("âš ï¸ ì˜¤ë¥˜ìœ¨ì´ 5%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. API í˜¸ì¶œ ê°„ê²©ì„ 1.5ë°°ë¡œ ëŠ˜ë¦¬ì„¸ìš”.")
            elif stats.error_rate < 1.0:
                recommendations.append("âœ… ì˜¤ë¥˜ìœ¨ì´ 1% ë¯¸ë§Œìœ¼ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
            
            # ì—°ì† ì˜¤ë¥˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if stats.consecutive_errors >= 5:
                recommendations.append("ğŸš¨ ì—°ì† 5íšŒ ì´ìƒ ì˜¤ë¥˜ ë°œìƒ. ì¦‰ì‹œ API í˜¸ì¶œì„ ì¤‘ë‹¨í•˜ê³  10ë¶„ ëŒ€ê¸°í•˜ì„¸ìš”.")
            elif stats.consecutive_errors >= 3:
                recommendations.append("âš ï¸ ì—°ì† 3íšŒ ì´ìƒ ì˜¤ë¥˜ ë°œìƒ. API í˜¸ì¶œ ê°„ê²©ì„ 3ë°°ë¡œ ëŠ˜ë¦¬ì„¸ìš”.")
            
            # ì‘ë‹µì‹œê°„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if stats.avg_response_time > 15.0:
                recommendations.append("âš ï¸ í‰ê·  ì‘ë‹µì‹œê°„ì´ 15ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. íƒ€ì„ì•„ì›ƒ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            elif stats.avg_response_time > 10.0:
                recommendations.append("âš ï¸ í‰ê·  ì‘ë‹µì‹œê°„ì´ 10ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            # ì˜¤ë¥˜ ìœ í˜• ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            if stats.error_by_type.get('401', 0) > 0:
                recommendations.append("ğŸ”‘ 401 ì˜¤ë¥˜ ë°œìƒ. í† í° ê°±ì‹ ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            if stats.error_by_type.get('429', 0) > 0:
                recommendations.append("â±ï¸ 429 ì˜¤ë¥˜ ë°œìƒ. API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê°„ê²©ì„ ëŠ˜ë¦¬ì„¸ìš”.")
            
            if stats.error_by_type.get('500', 0) > 5:
                recommendations.append("ğŸ”¥ 500 ì˜¤ë¥˜ê°€ ë¹ˆë²ˆíˆ ë°œìƒí•©ë‹ˆë‹¤. ì„œë²„ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            peak_hour = max(stats.error_by_hour.items(), key=lambda x: x[1])[0] if stats.error_by_hour else None
            if peak_hour is not None and stats.error_by_hour[peak_hour] > 20:
                recommendations.append(f"ğŸ“Š {peak_hour}ì‹œì— ì˜¤ë¥˜ê°€ ì§‘ì¤‘ ë°œìƒí•©ë‹ˆë‹¤. í•´ë‹¹ ì‹œê°„ëŒ€ ê°„ê²©ì„ ëŠ˜ë¦¬ì„¸ìš”.")
            
            # ê¸°ë³¸ ê¶Œì¥ì‚¬í•­
            if not recommendations:
                recommendations.append("âœ… í˜„ì¬ ì˜¤ë¥˜ ìƒí™©ì´ ì•ˆì •ì ì…ë‹ˆë‹¤.")
            
            return recommendations
            
        except Exception as e:
            logger.error(f"ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
            return ["âŒ ê¶Œì¥ì‚¬í•­ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    def generate_error_report(self, hours_back: int = 24) -> str:
        """ì˜¤ë¥˜ ë³´ê³ ì„œ ìƒì„±"""
        stats = self.get_error_stats(hours_back)
        recommendations = self.get_recommendations(stats)
        
        report = []
        
        report.append(f"ğŸ“Š ì˜¤ë¥˜/ì°¨ë‹¨ ê´€ì¸¡ ë³´ê³ ì„œ (ìµœê·¼ {hours_back}ì‹œê°„)")
        report.append("=" * 50)
        
        # ê¸°ë³¸ í†µê³„
        report.append(f"ğŸ“ˆ ê¸°ë³¸ í†µê³„:")
        report.append(f"  â€¢ ì´ ì˜¤ë¥˜ ìˆ˜: {stats.total_errors}ê°œ")
        report.append(f"  â€¢ ì˜¤ë¥˜ìœ¨: {stats.error_rate:.2f}%")
        report.append(f"  â€¢ ì—°ì† ì˜¤ë¥˜: {stats.consecutive_errors}íšŒ")
        report.append(f"  â€¢ í‰ê·  ì‘ë‹µì‹œê°„: {stats.avg_response_time:.2f}ì´ˆ")
        report.append(f"  â€¢ ìµœëŒ€ ì‘ë‹µì‹œê°„: {stats.max_response_time:.2f}ì´ˆ")
        
        if stats.last_error_time:
            last_error = datetime.fromisoformat(stats.last_error_time)
            report.append(f"  â€¢ ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ì˜¤ë¥˜ ìœ í˜•ë³„ í†µê³„
        if stats.error_by_type:
            report.append(f"\nğŸ” ì˜¤ë¥˜ ìœ í˜•ë³„ ë¶„í¬:")
            for error_type, count in sorted(stats.error_by_type.items(), key=lambda x: x[1], reverse=True):
                report.append(f"  â€¢ {error_type}: {count}ê°œ")
        
        # ì‹œê°„ëŒ€ë³„ í†µê³„
        if stats.error_by_hour:
            report.append(f"\nâ° ì‹œê°„ëŒ€ë³„ ì˜¤ë¥˜ ë°œìƒ:")
            peak_hour = max(stats.error_by_hour.items(), key=lambda x: x[1])
            report.append(f"  â€¢ ìµœë‹¤ ë°œìƒ ì‹œê°„: {peak_hour[0]}ì‹œ ({peak_hour[1]}ê°œ)")
            
            # ìƒìœ„ 3ê°œ ì‹œê°„ëŒ€
            top_hours = sorted(stats.error_by_hour.items(), key=lambda x: x[1], reverse=True)[:3]
            for hour, count in top_hours:
                report.append(f"  â€¢ {hour}ì‹œ: {count}ê°œ")
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ í†µê³„
        if stats.error_by_endpoint:
            report.append(f"\nğŸŒ ì—”ë“œí¬ì¸íŠ¸ë³„ ì˜¤ë¥˜:")
            top_endpoints = sorted(stats.error_by_endpoint.items(), key=lambda x: x[1], reverse=True)[:5]
            for endpoint, count in top_endpoints:
                short_name = endpoint.split('/')[-1]
                report.append(f"  â€¢ {short_name}: {count}ê°œ")
        
        # ê¶Œì¥ì‚¬í•­
        report.append(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(recommendations, 1):
            report.append(f"  {i}. {rec}")
        
        return "\n".join(report)
    
    def export_error_data(self, hours_back: int = 24) -> pd.DataFrame:
        """ì˜¤ë¥˜ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            
            # ìµœê·¼ ì˜¤ë¥˜ ì´ë²¤íŠ¸ ìˆ˜ì§‘
            recent_events = []
            with self.error_lock:
                for event in self.error_events:
                    event_time = datetime.fromisoformat(event.timestamp)
                    if event_time >= cutoff_time:
                        recent_events.append(asdict(event))
            
            if not recent_events:
                return pd.DataFrame()
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(recent_events)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values('timestamp', ascending=False)
            
            return df
            
        except Exception as e:
            logger.error(f"ì˜¤ë¥˜ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return pd.DataFrame()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    dashboard = ErrorMonitoringDashboard()
    
    # í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ ì´ë²¤íŠ¸ ìƒì„±
    dashboard.log_error("429", "quotations/inquire-price", "FHKST01010100", "Rate limit exceeded", 1, 2.5)
    dashboard.log_error("500", "quotations/inquire-daily-itemchartprice", "FHKST03010100", "Internal server error", 2, 5.0)
    dashboard.log_error("401", "quotations/inquire-price", "FHKST01010100", "Unauthorized", 0, 1.0)
    
    # í†µê³„ ì¡°íšŒ
    stats = dashboard.get_error_stats(24)
    print(f"ì´ ì˜¤ë¥˜ ìˆ˜: {stats.total_errors}")
    print(f"ì˜¤ë¥˜ìœ¨: {stats.error_rate:.2f}%")
    
    # ë³´ê³ ì„œ ìƒì„±
    report = dashboard.generate_error_report(24)
    print(report)
