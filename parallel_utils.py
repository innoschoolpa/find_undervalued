#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë³‘ë ¬ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
KIS OpenAPI TPS ì œí•œì„ ê³ ë ¤í•œ ì•ˆì „í•œ ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
"""

import time
import queue
from threading import Lock
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Callable, Optional
from rich.console import Console
from rich.progress import Progress

console = Console()

class TPSRateLimiter:
    """KIS OpenAPI TPS ì œí•œ(ì´ˆë‹¹ 10ê±´)ì„ ê³ ë ¤í•œ ë ˆì´íŠ¸ë¦¬ë¯¸í„°"""
    
    def __init__(self, max_tps: int = 8):  # ì•ˆì „ ë§ˆì§„ì„ ìœ„í•´ 8ë¡œ ì„¤ì •
        self.max_tps = max_tps
        self.requests = queue.Queue()
        self.lock = Lock()
    
    def acquire(self):
        """ìš”ì²­ í—ˆê°€ë¥¼ ë°›ìŠµë‹ˆë‹¤."""
        with self.lock:
            now = time.time()
            
            # 1ì´ˆ ì´ì „ì˜ ìš”ì²­ë“¤ì„ ì œê±°
            while not self.requests.empty():
                try:
                    request_time = self.requests.get_nowait()
                    if now - request_time < 1.0:
                        self.requests.put(request_time)
                        break
                except queue.Empty:
                    break
            
            # TPS ì œí•œ í™•ì¸
            if self.requests.qsize() >= self.max_tps:
                # ê°€ì¥ ì˜¤ë˜ëœ ìš”ì²­ì´ 1ì´ˆê°€ ì§€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
                oldest_request = self.requests.get()
                sleep_time = 1.0 - (now - oldest_request)
                if sleep_time > 0:
                    time.sleep(sleep_time)
            
            # í˜„ì¬ ìš”ì²­ ê¸°ë¡
            self.requests.put(time.time())

# ì „ì—­ ë ˆì´íŠ¸ë¦¬ë¯¸í„° ì¸ìŠ¤í„´ìŠ¤
rate_limiter = TPSRateLimiter(max_tps=8)

def parallel_analyze_stocks(
    stocks_data: List[Dict[str, Any]], 
    analysis_func: Callable,
    max_workers: int = 3,
    show_progress: bool = True,
    progress_description: str = "ë³‘ë ¬ ë¶„ì„ ì§„í–‰ ì¤‘..."
) -> List[Dict[str, Any]]:
    """
    ì¢…ëª©ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        stocks_data: ë¶„ì„í•  ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        analysis_func: ë¶„ì„ í•¨ìˆ˜ (stock_data, *args) -> result
        max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜
        show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€
        progress_description: ì§„í–‰ë¥  ì„¤ëª…
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    results = []
    start_time = time.time()
    
    if show_progress:
        with Progress() as progress:
            task = progress.add_task(progress_description, total=len(stocks_data))
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # ê° ì¢…ëª©ì— ëŒ€í•œ Future ìƒì„±
                future_to_stock = {}
                for i, stock_data in enumerate(stocks_data):
                    future = executor.submit(analysis_func, stock_data)
                    future_to_stock[future] = (i, stock_data)
                
                # ì™„ë£Œëœ ì‘ì—…ë“¤ì„ ì²˜ë¦¬
                for future in as_completed(future_to_stock):
                    i, stock_data = future_to_stock[future]
                    try:
                        result = future.result()
                        results.append(result)
                        progress.update(task, advance=1)
                    except Exception as e:
                        console.print(f"âŒ {stock_data.get('name', 'Unknown')} ë¶„ì„ ì‹¤íŒ¨: {e}")
                        results.append({
                            'error': str(e),
                            'stock_data': stock_data
                        })
                        progress.update(task, advance=1)
    else:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ê° ì¢…ëª©ì— ëŒ€í•œ Future ìƒì„±
            future_to_stock = {}
            for i, stock_data in enumerate(stocks_data):
                future = executor.submit(analysis_func, stock_data)
                future_to_stock[future] = (i, stock_data)
            
            # ì™„ë£Œëœ ì‘ì—…ë“¤ì„ ì²˜ë¦¬
            for future in as_completed(future_to_stock):
                i, stock_data = future_to_stock[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    console.print(f"âŒ {stock_data.get('name', 'Unknown')} ë¶„ì„ ì‹¤íŒ¨: {e}")
                    results.append({
                        'error': str(e),
                        'stock_data': stock_data
                    })
    
    end_time = time.time()
    total_time = end_time - start_time
    
    # ì„±ëŠ¥ í†µê³„
    success_count = len([r for r in results if 'error' not in r])
    error_count = len(results) - success_count
    
    console.print(f"âœ… ë³‘ë ¬ ë¶„ì„ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {error_count}ê°œ")
    console.print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")
    console.print(f"âš¡ í‰ê·  ì²˜ë¦¬ì†ë„: {len(results)/total_time:.2f}ì¢…ëª©/ì´ˆ")
    
    return results

def parallel_analyze_with_retry(
    stocks_data: List[Dict[str, Any]], 
    analysis_func: Callable,
    max_workers: int = 3,
    max_retries: int = 2,
    retry_delay: float = 1.0,
    show_progress: bool = True,
    progress_description: str = "ë³‘ë ¬ ë¶„ì„ ì§„í–‰ ì¤‘..."
) -> List[Dict[str, Any]]:
    """
    ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë³‘ë ¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        stocks_data: ë¶„ì„í•  ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        analysis_func: ë¶„ì„ í•¨ìˆ˜ (stock_data, *args) -> result
        max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        retry_delay: ì¬ì‹œë„ ê°„ ì§€ì—° ì‹œê°„
        show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€
        progress_description: ì§„í–‰ë¥  ì„¤ëª…
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    def analyze_with_retry(stock_data):
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë¶„ì„ í•¨ìˆ˜"""
        for attempt in range(max_retries + 1):
            try:
                # TPS ì œí•œ ì ìš©
                rate_limiter.acquire()
                result = analysis_func(stock_data)
                return result
            except Exception as e:
                if attempt < max_retries:
                    console.print(f"âš ï¸ {stock_data.get('name', 'Unknown')} ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                    time.sleep(retry_delay)
                else:
                    raise e
    
    return parallel_analyze_stocks(
        stocks_data, 
        analyze_with_retry, 
        max_workers, 
        show_progress, 
        progress_description
    )

def batch_parallel_analyze(
    stocks_data: List[Dict[str, Any]], 
    analysis_func: Callable,
    batch_size: int = 10,
    max_workers: int = 3,
    show_progress: bool = True,
    progress_description: str = "ë°°ì¹˜ ë³‘ë ¬ ë¶„ì„ ì§„í–‰ ì¤‘..."
) -> List[Dict[str, Any]]:
    """
    ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        stocks_data: ë¶„ì„í•  ì¢…ëª© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        analysis_func: ë¶„ì„ í•¨ìˆ˜ (stock_data, *args) -> result
        batch_size: ë°°ì¹˜ í¬ê¸°
        max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜
        show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€
        progress_description: ì§„í–‰ë¥  ì„¤ëª…
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    all_results = []
    total_batches = (len(stocks_data) + batch_size - 1) // batch_size
    
    console.print(f"ğŸ“¦ ë°°ì¹˜ ë³‘ë ¬ ë¶„ì„ ì‹œì‘: {total_batches}ê°œ ë°°ì¹˜, ë°°ì¹˜ë‹¹ {batch_size}ê°œ ì¢…ëª©")
    
    for batch_idx in range(0, len(stocks_data), batch_size):
        batch_data = stocks_data[batch_idx:batch_idx + batch_size]
        batch_num = batch_idx // batch_size + 1
        
        console.print(f"\nğŸ”„ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_data)}ê°œ ì¢…ëª©)")
        
        batch_results = parallel_analyze_stocks(
            batch_data,
            analysis_func,
            max_workers,
            show_progress,
            f"ë°°ì¹˜ {batch_num}/{total_batches} - {progress_description}"
        )
        
        all_results.extend(batch_results)
        
        # ë°°ì¹˜ ê°„ ëŒ€ê¸° (API ì„œë²„ ë¶€í•˜ ë°©ì§€)
        if batch_idx + batch_size < len(stocks_data):
            console.print(f"â³ ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ ëŒ€ê¸° ì¤‘...")
            time.sleep(2.0)
    
    console.print(f"\nâœ… ì „ì²´ ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {len(all_results)}ê°œ ì¢…ëª©")
    return all_results

def get_optimal_worker_count(total_tasks: int, max_workers: int = 5) -> int:
    """
    ì‘ì—… ìˆ˜ì— ë”°ë¥¸ ìµœì  ì›Œì»¤ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        total_tasks: ì „ì²´ ì‘ì—… ìˆ˜
        max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜
    
    Returns:
        ìµœì  ì›Œì»¤ ìˆ˜
    """
    # TPS ì œí•œ(ì´ˆë‹¹ 8ê±´)ì„ ê³ ë ¤í•œ ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°
    if total_tasks <= 5:
        return min(2, max_workers)
    elif total_tasks <= 20:
        return min(3, max_workers)
    elif total_tasks <= 50:
        return min(4, max_workers)
    else:
        return min(5, max_workers)

def analyze_performance_metrics(
    results: List[Dict[str, Any]], 
    expected_sequential_time: float = None
) -> Dict[str, Any]:
    """
    ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        results: ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        expected_sequential_time: ì˜ˆìƒ ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„
    
    Returns:
        ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    success_count = len([r for r in results if 'error' not in r])
    error_count = len(results) - success_count
    
    metrics = {
        'total_tasks': len(results),
        'success_count': success_count,
        'error_count': error_count,
        'success_rate': success_count / len(results) if results else 0,
        'error_rate': error_count / len(results) if results else 0
    }
    
    if expected_sequential_time:
        # ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ì€ í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ì¸¡ì •í•´ì•¼ í•¨
        metrics['expected_sequential_time'] = expected_sequential_time
    
    return metrics
